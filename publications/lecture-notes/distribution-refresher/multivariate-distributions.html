<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>2 Multivariate distributions | Distribution Refresher</title>
<meta name="author" content="Korbinian Strimmer">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="2 Multivariate distributions | Distribution Refresher">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="2 Multivariate distributions | Distribution Refresher">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<meta name="description" content="2.1 Categorical distribution The categorical distribution is a generalisation of the Bernoulli distribution from two classes to \(K\) classes. The categorical distribution \(\text{Cat}(\boldsymbol...">
<meta property="og:description" content="2.1 Categorical distribution The categorical distribution is a generalisation of the Bernoulli distribution from two classes to \(K\) classes. The categorical distribution \(\text{Cat}(\boldsymbol...">
<meta name="twitter:description" content="2.1 Categorical distribution The categorical distribution is a generalisation of the Bernoulli distribution from two classes to \(K\) classes. The categorical distribution \(\text{Cat}(\boldsymbol...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Distribution Refresher</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="univariate-distributions.html"><span class="header-section-number">1</span> Univariate distributions</a></li>
<li><a class="active" href="multivariate-distributions.html"><span class="header-section-number">2</span> Multivariate distributions</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="multivariate-distributions" class="section level1" number="2">
<h1>
<span class="header-section-number">2</span> Multivariate distributions<a class="anchor" aria-label="anchor" href="#multivariate-distributions"><i class="fas fa-link"></i></a>
</h1>
<div id="categorical-distribution" class="section level2" number="2.1">
<h2>
<span class="header-section-number">2.1</span> Categorical distribution<a class="anchor" aria-label="anchor" href="#categorical-distribution"><i class="fas fa-link"></i></a>
</h2>
<p>The <strong>categorical distribution</strong> is a generalisation of the Bernoulli distribution from
two classes to <span class="math inline">\(K\)</span> classes.</p>
<p>The categorical distribution <span class="math inline">\(\text{Cat}(\boldsymbol \pi)\)</span> describes
a discrete random variable with <span class="math inline">\(K\)</span> states (“categories”, “classes”, “bins”) where
the parameter vector
<span class="math inline">\(\boldsymbol \pi= (\pi_1, \ldots, \pi_K)^T\)</span> specifies
the probability of each of class so that
<span class="math inline">\(\text{Pr}(\text{"class k"}) = \pi_k\)</span>.
The parameters satisfy <span class="math inline">\(\pi_k \in [0,1]\)</span> and
<span class="math inline">\(\sum_{k=1}^K \pi_k = 1\)</span>, hence there are <span class="math inline">\(K-1\)</span> independent parameters in a categorical distribution (and not <span class="math inline">\(K\)</span>).</p>
<p>There are two main ways to numerically represent “class k”:</p>
<ol style="list-style-type: lower-roman">
<li>by “integer encoding”, i.e. by the corresponding integer <span class="math inline">\(k\)</span>.</li>
<li>by “one hot encoding”, i.e. by an indicator vector
<span class="math inline">\(\boldsymbol x= (x_1, \ldots, x_K)^T = (0, 0, \ldots, 1, \ldots, 0)^T\)</span> containing zeros everywhere except for the element <span class="math inline">\(x_k=1\)</span> at position <span class="math inline">\(k\)</span>. Thus all <span class="math inline">\(x_k \in \{ 0, 1\}\)</span> and <span class="math inline">\(\sum_{k=1}^K x_k = 1\)</span>.</li>
</ol>
<p>In the following we use “one hot encoding”. Therefore sampling from a categorical distribution with parameters <span class="math inline">\(\boldsymbol \pi\)</span>
<span class="math display">\[
\boldsymbol x\sim \text{Cat}(\boldsymbol \pi)
\]</span>
yields a random index vector <span class="math inline">\(\boldsymbol x\)</span>.</p>
<p>The corresponding probability mass function (PMF)
can be written conveniently in terms of <span class="math inline">\(x_k\)</span> as
<span class="math display">\[
p(\boldsymbol x| \boldsymbol \pi) = \prod_{k=1}^K \pi_k^{x_k} =
\begin{cases}
   \pi_k  &amp; \text{if } x_k = 1 \\
\end{cases}
\]</span>
and the log PMF as
<span class="math display">\[
\log p(\boldsymbol x| \boldsymbol \pi) = \sum_{k=1}^K x_k \log \pi_k   =
\begin{cases}
   \log \pi_k  &amp; \text{if } x_k = 1 \\
\end{cases}
\]</span></p>
<p>In order to be more explicit that the categorical distribution has <span class="math inline">\(K-1\)</span> and not <span class="math inline">\(K\)</span> parameters
we rewrite the log-density with
<span class="math inline">\(\pi_K = 1 - \sum_{k=1}^{K-1} \pi_k\)</span> and <span class="math inline">\(x_K = 1 - \sum_{k=1}^{K-1} x_k\)</span> as
<span class="math display">\[
\begin{split}
\log p(\boldsymbol x| \boldsymbol \pi) &amp; =\sum_{k=1}^{K-1}  x_k \log \pi_k    + x_K \log \pi_K \\
&amp; =\sum_{k=1}^{K-1}  x_k \log \pi_k    + \left( 1 - \sum_{k=1}^{K-1} x_k  \right) \log \left( 1 - \sum_{k=1}^{K-1} \pi_k \right) \\
\end{split}
\]</span>
Note that there is no particular reason to choose <span class="math inline">\(\pi_K\)</span> as
dependent of the probabilities of the other classes,
in its place any other of the <span class="math inline">\(\pi_k\)</span> may be selected.</p>
<p>For <span class="math inline">\(K=2\)</span> the categorical distribution reduces to the Bernoulli <span class="math inline">\(\text{Ber}(\theta)\)</span> distribution,
with <span class="math inline">\(\pi_1=\theta\)</span> and <span class="math inline">\(\pi_2=1-\theta\)</span>.</p>
<p>The expected value is <span class="math inline">\(\text{E}(\boldsymbol x) = \boldsymbol \pi\)</span>, in component notation
<span class="math inline">\(\text{E}(x_k) = \pi_k\)</span>.
The covariance matrix is <span class="math inline">\(\text{Var}(\boldsymbol x) = \text{Diag}(\boldsymbol \pi) - \boldsymbol \pi\boldsymbol \pi^T\)</span>, which in
component notation is <span class="math inline">\(\text{Var}(x_i) = \pi_i (1-\pi_i)\)</span> and <span class="math inline">\(\text{Cov}(x_i, x_j) = -\pi_i \pi_j\)</span>.</p>
<p>The form of the categorical covariance matrix follows directly from the definition of the
variance <span class="math inline">\(\text{Var}(\boldsymbol x) = \text{E}( \boldsymbol x\boldsymbol x^T) - \text{E}( \boldsymbol x) \text{E}( \boldsymbol x)^T\)</span>
and noting that <span class="math inline">\(x_i^2 = x_i\)</span> and <span class="math inline">\(x_i x_j = 0\)</span> if <span class="math inline">\(i \neq j\)</span>.
Furthermore, the categorical covariance matrix is singular by construction, as the <span class="math inline">\(K\)</span> random variables
<span class="math inline">\(x_1, \ldots, x_K\)</span> are dependent through the constraint <span class="math inline">\(\sum_{k=1}^K x_k = 1\)</span>.</p>
</div>
<div id="multinomial-distribution" class="section level2" number="2.2">
<h2>
<span class="header-section-number">2.2</span> Multinomial distribution<a class="anchor" aria-label="anchor" href="#multinomial-distribution"><i class="fas fa-link"></i></a>
</h2>
<p>The <strong>multinomial distribution</strong> <span class="math inline">\(\text{Mult}(n, \boldsymbol \pi)\)</span> arises from repeated categorical sampling,
in the same fashion as the binomial distribution arises from repeated Bernoulli sampling. Thus, if <span class="math inline">\(\boldsymbol x_1, \ldots, \boldsymbol x_n\)</span> are <span class="math inline">\(n\)</span> independent <span class="math inline">\(\text{Cat}(\boldsymbol \pi)\)</span> random categorical variables
then <span class="math inline">\(\boldsymbol y= \sum_{i=1}^n \boldsymbol x_i\)</span> is distributed as <span class="math inline">\(\text{Mult}(n, \boldsymbol \pi)\)</span>.</p>
<p>The corresponding PMF describes the probability of a pattern <span class="math inline">\(y_1, \ldots, y_K\)</span> of
samples distributed across <span class="math inline">\(K\)</span> classes (with <span class="math inline">\(n= \sum_{k=1}^K y_k\)</span>):
<span class="math display">\[
p(\boldsymbol y| n, \theta) = \binom{n}{y_1, \ldots, y_n} \prod_{k=1}^K \pi_k^{y_k}
\]</span>
where <span class="math inline">\(\binom{n}{y_1, \ldots, y_n}\)</span> is the multinomial coefficient.</p>
<p>The expected value is <span class="math inline">\(\text{E}(\boldsymbol y) = n \boldsymbol \pi\)</span>, in component notation
<span class="math inline">\(\text{E}(y_k) = n \pi_k\)</span>.
The covariance matrix is <span class="math inline">\(\text{Var}(\boldsymbol y) = n \text{Diag}(\boldsymbol \pi) - n \boldsymbol \pi\boldsymbol \pi^T\)</span>, which in
component notation is <span class="math inline">\(\text{Var}(x_i) = n \pi_i (1-\pi_i)\)</span> and <span class="math inline">\(\text{Cov}(x_i, x_j) = -n \pi_i \pi_j\)</span>.</p>
</div>
<div id="multivariate-normal-distribution" class="section level2" number="2.3">
<h2>
<span class="header-section-number">2.3</span> Multivariate normal distribution<a class="anchor" aria-label="anchor" href="#multivariate-normal-distribution"><i class="fas fa-link"></i></a>
</h2>
<p>The univariate normal distribution for a random scalar <span class="math inline">\(x\)</span> generalises to the <strong>multivariate normal distribution</strong> for a random vector <span class="math inline">\(\boldsymbol x= (x_1, x_2,...,x_d)^T \sim N_d(\boldsymbol \mu, \boldsymbol \Sigma)\)</span> with with mean <span class="math inline">\(\text{E}(\boldsymbol x) = \boldsymbol \mu\)</span> and covariance matrix <span class="math inline">\(\text{Var}(\boldsymbol x) = \boldsymbol \Sigma\)</span>. The corresponding density is
<span class="math display">\[
p(\boldsymbol x| \boldsymbol \mu, \boldsymbol \Sigma) = (2\pi)^{-\frac{d}{2}} \det(\boldsymbol \Sigma)^{-\frac{1}{2}} \exp\left({{-\frac{1}{2}} \underbrace{\underbrace{(\boldsymbol x-\boldsymbol \mu)^T}_{1 \times d} \underbrace{\boldsymbol \Sigma^{-1}}_{d \times d} \underbrace{(\boldsymbol x-\boldsymbol \mu)}_{d \times 1} }_{1 \times 1 = \text{scalar!}}}\right)
\]</span></p>
<p>The expectation is <span class="math inline">\(\text{E}(\boldsymbol x) = \boldsymbol \mu\)</span> and the variance <span class="math inline">\(\text{Var}(\boldsymbol x) = \boldsymbol \Sigma\)</span>.</p>
<p>For <span class="math inline">\(d=1\)</span> we get <span class="math inline">\(\boldsymbol x=x\)</span>, <span class="math inline">\(\boldsymbol \mu= \mu\)</span> and <span class="math inline">\(\boldsymbol \Sigma= \sigma^2\)</span> so that the multivariate normal density reduces to the univariate normal density.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="univariate-distributions.html"><span class="header-section-number">1</span> Univariate distributions</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#multivariate-distributions"><span class="header-section-number">2</span> Multivariate distributions</a></li>
<li><a class="nav-link" href="#categorical-distribution"><span class="header-section-number">2.1</span> Categorical distribution</a></li>
<li><a class="nav-link" href="#multinomial-distribution"><span class="header-section-number">2.2</span> Multinomial distribution</a></li>
<li><a class="nav-link" href="#multivariate-normal-distribution"><span class="header-section-number">2.3</span> Multivariate normal distribution</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Distribution Refresher</strong>" was written by Korbinian Strimmer. It was last built on 12 December 2023.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
