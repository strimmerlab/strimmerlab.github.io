<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>9 Essentials of Bayesian statistics | Statistics 2: Likelihood and Bayes</title>
<meta name="author" content="Korbinian Strimmer">
<meta name="generator" content="bookdown 0.36 with bs4_book()">
<meta property="og:title" content="9 Essentials of Bayesian statistics | Statistics 2: Likelihood and Bayes">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="9 Essentials of Bayesian statistics | Statistics 2: Likelihood and Bayes">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<meta name="description" content="9.1 Principle of Bayesian learning  9.1.1 From prior to posterior distribution Bayesian statistical learning applies Bayes’ theorem to update our state of knowledge about a parameter in the light...">
<meta property="og:description" content="9.1 Principle of Bayesian learning  9.1.1 From prior to posterior distribution Bayesian statistical learning applies Bayes’ theorem to update our state of knowledge about a parameter in the light...">
<meta name="twitter:description" content="9.1 Principle of Bayesian learning  9.1.1 From prior to posterior distribution Bayesian statistical learning applies Bayes’ theorem to update our state of knowledge about a parameter in the light...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Statistics 2: Likelihood and Bayes</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li class="book-part">Likelihood estimation and inference</li>
<li><a class="" href="overview-of-statistical-learning.html"><span class="header-section-number">1</span> Overview of statistical learning</a></li>
<li><a class="" href="from-entropy-to-maximum-likelihood.html"><span class="header-section-number">2</span> From entropy to maximum likelihood</a></li>
<li><a class="" href="maximum-likelihood-estimation.html"><span class="header-section-number">3</span> Maximum likelihood estimation</a></li>
<li><a class="" href="quadratic-approximation-and-normal-asymptotics.html"><span class="header-section-number">4</span> Quadratic approximation and normal asymptotics</a></li>
<li><a class="" href="likelihood-based-confidence-interval-and-likelihood-ratio.html"><span class="header-section-number">5</span> Likelihood-based confidence interval and likelihood ratio</a></li>
<li><a class="" href="optimality-properties-and-conclusion.html"><span class="header-section-number">6</span> Optimality properties and conclusion</a></li>
<li class="book-part">Bayesian Statistics</li>
<li><a class="" href="conditioning-and-bayes-rule.html"><span class="header-section-number">7</span> Conditioning and Bayes rule</a></li>
<li><a class="" href="models-with-latent-variables-and-missing-data.html"><span class="header-section-number">8</span> Models with latent variables and missing data</a></li>
<li><a class="active" href="essentials-of-bayesian-statistics.html"><span class="header-section-number">9</span> Essentials of Bayesian statistics</a></li>
<li><a class="" href="bayesian-learning-in-practise.html"><span class="header-section-number">10</span> Bayesian learning in practise</a></li>
<li><a class="" href="bayesian-model-comparison.html"><span class="header-section-number">11</span> Bayesian model comparison</a></li>
<li><a class="" href="choosing-priors-in-bayesian-analysis.html"><span class="header-section-number">12</span> Choosing priors in Bayesian analysis</a></li>
<li><a class="" href="optimality-properties-and-summary.html"><span class="header-section-number">13</span> Optimality properties and summary</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="refresher.html"><span class="header-section-number">A</span> Refresher</a></li>
<li><a class="" href="essential-distributions.html"><span class="header-section-number">B</span> Essential distributions</a></li>
<li><a class="" href="further-distributions-used-in-bayesian-analysis.html"><span class="header-section-number">C</span> Further distributions used in Bayesian analysis</a></li>
<li><a class="" href="further-study.html"><span class="header-section-number">D</span> Further study</a></li>
<li><a class="" href="bibliography.html">Bibliography</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="essentials-of-bayesian-statistics" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Essentials of Bayesian statistics<a class="anchor" aria-label="anchor" href="#essentials-of-bayesian-statistics"><i class="fas fa-link"></i></a>
</h1>
<div id="principle-of-bayesian-learning" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Principle of Bayesian learning<a class="anchor" aria-label="anchor" href="#principle-of-bayesian-learning"><i class="fas fa-link"></i></a>
</h2>
<div id="from-prior-to-posterior-distribution" class="section level3" number="9.1.1">
<h3>
<span class="header-section-number">9.1.1</span> From prior to posterior distribution<a class="anchor" aria-label="anchor" href="#from-prior-to-posterior-distribution"><i class="fas fa-link"></i></a>
</h3>
<p>Bayesian statistical learning applies Bayes’ theorem to update our state of knowledge about a parameter in the light of data.</p>
<p>Ingredients:</p>
<ul>
<li>
<span class="math inline">\(\boldsymbol \theta\)</span> parameter(s) of interest, unknown and fixed.</li>
<li>prior distribution with density <span class="math inline">\(p(\boldsymbol \theta)\)</span> describing the <em>uncertainty</em> (not randomness!) about <span class="math inline">\(\boldsymbol \theta\)</span>
</li>
<li>data generating process <span class="math inline">\(p(x | \boldsymbol \theta)\)</span>
</li>
</ul>
<p>Note the <strong>model underlying the Bayesian approach is the joint distribution</strong>
<span class="math display">\[
p(\boldsymbol \theta, x) = p(\boldsymbol \theta) p(x | \boldsymbol \theta)
\]</span>
as both a prior distribution over the parameters as well as a data generating process have to be specified.</p>
<p>Question: new information in the form of new observation <span class="math inline">\(x\)</span> arrives - how does the uncertainty about <span class="math inline">\(\boldsymbol \theta\)</span> change?</p>
<p>Answer: use Bayes’ theorem to <strong>update the prior density to the posterior density</strong>.</p>
<p><span class="math display">\[
\underbrace{p(\boldsymbol \theta| x)}_{\text{posterior} } = \underbrace{p(\boldsymbol \theta)}_{\text{prior}} \frac{p(x | \boldsymbol \theta) }{ p(x)}
\]</span></p>
<div class="inline-figure"><img src="fig/bayes1-learning.png" width="90%" style="display: block; margin: auto;"></div>
<p>For the denominator in Bayes formula we need to compute <span class="math inline">\(p(x)\)</span>.
This is obtained by<br><span class="math display">\[
\begin{split}
p(x) &amp;= \int_{\boldsymbol \theta} p(x , \boldsymbol \theta) d\boldsymbol \theta\\
&amp;= \int_{\boldsymbol \theta} p(x | \boldsymbol \theta) p(\boldsymbol \theta) d\boldsymbol \theta\\
\end{split}
\]</span>
i.e. by marginalisation of the parameter <span class="math inline">\(\boldsymbol \theta\)</span> from the joint
distribution of <span class="math inline">\(\boldsymbol \theta\)</span> and <span class="math inline">\(x\)</span>.
(For discrete <span class="math inline">\(\boldsymbol \theta\)</span> replace the integral by a sum).
Depending on the context this quantity is either called the</p>
<ul>
<li>
<strong>normalisation constant</strong> as it ensures that the posterior density <span class="math inline">\(p(\boldsymbol \theta| x)\)</span>
integrates to one.</li>
<li>
<strong>prior predictive density</strong> of the data <span class="math inline">\(x\)</span> given the model <span class="math inline">\(M\)</span> before seeing any data. To emphasise the implicit conditioning
on a model we may write <span class="math inline">\(p(x| M)\)</span>. Since all parameters have been integrated out <span class="math inline">\(M\)</span> in fact refers to a model <em>class</em>.</li>
<li>
<strong>marginal likelihood</strong> of the underlying <strong>model</strong> (class) <span class="math inline">\(M\)</span> given data <span class="math inline">\(x\)</span>. To emphasise this may write <span class="math inline">\(L(M| x)\)</span>. Sometimes it is also called <strong>model likelihood</strong>.</li>
</ul>
</div>
<div id="zero-forcing-property" class="section level3" number="9.1.2">
<h3>
<span class="header-section-number">9.1.2</span> Zero forcing property<a class="anchor" aria-label="anchor" href="#zero-forcing-property"><i class="fas fa-link"></i></a>
</h3>
<p>It is easy to see that if in Bayes rule the prior density/probability is zero for some parameter value <span class="math inline">\(\boldsymbol \theta\)</span> then the posterior density/probability will remain at zero for that <span class="math inline">\(\boldsymbol \theta\)</span>, regardless of any data collected. This <strong>zero-forcing property</strong> of the Bayes update rule has been called <strong>Cromwell’s rule</strong> by <a href="https://en.wikipedia.org/wiki/Dennis_Lindley">Dennis Lindley (1923–2013)</a>. Therefore, assigning prior density/probability 0 to an event should be avoided.</p>
<p>Note that this implies that assigning prior probability 1 should be avoided, too.</p>
</div>
<div id="bayesian-update-and-likelihood" class="section level3" number="9.1.3">
<h3>
<span class="header-section-number">9.1.3</span> Bayesian update and likelihood<a class="anchor" aria-label="anchor" href="#bayesian-update-and-likelihood"><i class="fas fa-link"></i></a>
</h3>
<p>After independent and identically distributed data <span class="math inline">\(D = \{x_1, \ldots, x_n\}\)</span> have been observed the Bayesian posterior is computed by<br><span class="math display">\[
\underbrace{p(\boldsymbol \theta| D) }_{\text{posterior} } = \underbrace{p(\boldsymbol \theta)}_{\text{prior}} \frac{ L(\boldsymbol \theta| D) }{ p(D)}
\]</span>
involving the likelihood <span class="math inline">\(L(\boldsymbol \theta| D) = \prod_{i=1}^n p(x_i | \boldsymbol \theta)\)</span>
and the marginal likelihoood <span class="math inline">\(p(D) = \int_{\boldsymbol \theta} p(\boldsymbol \theta) L(\boldsymbol \theta| D) d\boldsymbol \theta\)</span> with <span class="math inline">\(\boldsymbol \theta\)</span> integrated out.</p>
<p>The marginal likelihood serves as a standardising factor so that the posterior density for <span class="math inline">\(\boldsymbol \theta\)</span> integrates to 1:
<span class="math display">\[
\int_{\boldsymbol \theta} p(\boldsymbol \theta| D) d\boldsymbol \theta= \frac{1}{p(D)} \int_{\boldsymbol \theta} p(\boldsymbol \theta) L(\boldsymbol \theta| D) d\boldsymbol \theta= 1
\]</span>
Unfortunately, the integral to compute the marginal likelihood is typically analytically intractable and requires
numerical integration and/or approximation.</p>
<p>Comparing likelihood and Bayes procedures note that</p>
<ul>
<li>conducting a Bayesian statistical analysis requires integration respectively averaging (to compute the marginal likelihood)</li>
<li>in contrast to a likelihood analysis that requires optimisation (to find the maximum likelihood).</li>
</ul>
</div>
<div id="sequential-updates" class="section level3" number="9.1.4">
<h3>
<span class="header-section-number">9.1.4</span> Sequential updates<a class="anchor" aria-label="anchor" href="#sequential-updates"><i class="fas fa-link"></i></a>
</h3>
<p>Note that the Bayesian update procedure can be repeated again and again: we can use the posterior as our new prior and then update it with further data. Thus, we may also update the posterior density sequentially, with the data points <span class="math inline">\(x_1, \ldots, x_n\)</span> arriving one after the other, by computing first <span class="math inline">\(p(\boldsymbol \theta| x_1)\)</span>, then <span class="math inline">\(p(\boldsymbol \theta| x_1, x_2)\)</span> and so on until we reach <span class="math inline">\(p(\boldsymbol \theta| x_1, \ldots, x_n) = p(\boldsymbol \theta| D)\)</span>.</p>
<p>For example, for the first update we have
<span class="math display">\[
p(\boldsymbol \theta| x_1) =  p(\boldsymbol \theta)   \frac{p(x_1 | \boldsymbol \theta)  }{p(x_1)}
\]</span>
with <span class="math inline">\(p(x_1) =\int_{\boldsymbol \theta} p(x_1 | \boldsymbol \theta) p(\boldsymbol \theta) d\boldsymbol \theta\)</span>.
The second update yields
<span class="math display">\[
\begin{split}
p(\boldsymbol \theta| x_1, x_2) &amp;=  p(\boldsymbol \theta| x_1)   \frac{p(x_2 | \boldsymbol \theta, x_1)  }{p(x_2| x_1)}\\
&amp;= p(\boldsymbol \theta| x_1)   \frac{p(x_2 | \boldsymbol \theta)  }{p(x_2| x_1)}\\
&amp;=  p(\boldsymbol \theta) \frac{  p(x_1 | \boldsymbol \theta)    p(x_2 | \boldsymbol \theta)  }{p(x_1) p(x_2| x_1)}\\
\end{split}
\]</span>
with <span class="math inline">\(p(x_2| x_1) = \int_{\boldsymbol \theta} p(x_2 | \boldsymbol \theta) p(\boldsymbol \theta| x_1) d\boldsymbol \theta\)</span>.
The final step is
<span class="math display">\[
\begin{split}
p(\boldsymbol \theta| D)  = p(\boldsymbol \theta| x_1, \ldots, x_n) &amp;=   p(\boldsymbol \theta) \frac{ \prod_{i=1}^n p(x_i | \boldsymbol \theta)  }{ p(D)  }\\
\end{split}
\]</span>
with the marginal likelihood factorising into
<span class="math display">\[
p(D) = \prod_{i=1}^n p(x_i| x_{&lt;i})
\]</span>
with
<span class="math display">\[
p(x_i| x_{&lt;i}) = \int_{\boldsymbol \theta} p(x_i | \boldsymbol \theta) p(\boldsymbol \theta| x_{&lt;i}) d\boldsymbol \theta
\]</span>
The last factor is the <strong>posterior predictive density</strong> of the new data <span class="math inline">\(x_i\)</span> after seeing data <span class="math inline">\(x_1, \ldots, x_{i-1}\)</span> (given the model class <span class="math inline">\(M\)</span>).
It is straightforward to understand why the probability of the new <span class="math inline">\(x_i\)</span> depends on the previously observed data points — because the uncertainty about the model parameter <span class="math inline">\(\boldsymbol \theta\)</span> depends on how much data we have already observed. Therefore the marginal likelihood <span class="math inline">\(p(D)\)</span> is <em>not</em> simply the product
of the marginal densities <span class="math inline">\(p(x_i)\)</span> at each <span class="math inline">\(x_i\)</span> but instead the product of the conditional densities <span class="math inline">\(p(x_i| x_{&lt;i})\)</span>.</p>
<p>Only when the parameter is fully known and there is no uncertainty about <span class="math inline">\(\boldsymbol \theta\)</span> the observations
<span class="math inline">\(x_i\)</span> are independent. This leads back to the standard likelihood where we condition on a particular <span class="math inline">\(\boldsymbol \theta\)</span> and the likelihood is the product <span class="math inline">\(p(D| \boldsymbol \theta) = \prod_{i=1}^n p(x_i| \boldsymbol \theta)\)</span>.</p>
</div>
<div id="summaries-of-posterior-distributions-and-credible-intervals" class="section level3" number="9.1.5">
<h3>
<span class="header-section-number">9.1.5</span> Summaries of posterior distributions and credible intervals<a class="anchor" aria-label="anchor" href="#summaries-of-posterior-distributions-and-credible-intervals"><i class="fas fa-link"></i></a>
</h3>
<p><strong>The Bayesian estimate is the full complete posterior distribution!</strong></p>
<p>However, it is useful to summarise aspects of the posterior distribution:</p>
<ul>
<li>Posterior mean <span class="math inline">\(\text{E}(\boldsymbol \theta| D)\)</span>
</li>
<li>Posterior variance <span class="math inline">\(\text{Var}(\boldsymbol \theta| D)\)</span>
</li>
<li>Posterior mode
etc.</li>
</ul>
<p>In particular the mean of the posterior distribution is often taken as a <em>Bayesian point estimate</em>.</p>
<p>The posterior distribution also allows to define <strong>credible regions</strong> or <strong>credible intervals</strong>.
These are the <strong>Bayesian equivalent to confidence intervals</strong> and are constructed by
finding the areas of highest probability mass (say 95%) in the posterior distribution.</p>
<div class="inline-figure"><img src="fig/bayes2-ci.png" width="80%" style="display: block; margin: auto;"></div>
<p>Bayesian credible intervals (unlike their frequentist confidence counterparts) are thus very easy to interpret - they simply correspond to the area in the parameter space in which the we can find the parameter with a given specified probability.
In contrast, in frequentist statistics it does not make sense to assign a
probability to a parameter value!</p>
<p>Note that there are typically many credible intervals with the given specified coverage <span class="math inline">\(\alpha\)</span> (say 95%). Therefore, we may need further criteria
to construct these intervals.</p>
<p>For univariate parameter <span class="math inline">\(\theta\)</span> a <strong>two-sided equal-tail credible interval</strong> is obtained by finding the corresponding lower <span class="math inline">\(1-\alpha/2\)</span>
and upper <span class="math inline">\(\alpha/2\)</span> quantiles. Typically this type of credible interval is easy to compute. However, note that the density values at the left and right boundary points of such an interval are typically different.
Also this does not generalise well to a multivariate parameter <span class="math inline">\(\boldsymbol \theta\)</span>.</p>
<p>As alternative, a <strong>highest posterior density (HPD)</strong> credible interval of coverage <span class="math inline">\(\alpha\)</span> is found by identifying the shortest interval (i.e. with smallest support) for the given <span class="math inline">\(\alpha\)</span>
probability mass. Any point within an HDP credible interval has higher density than a point outside the HDP credible interval. Correspondingly, the density
at the boundary of an HPD credible interval is constant taking on the same value everywhere along the boundary.</p>
<p>A Bayesian HPD credible interval is constructed in a similar fashion as a likelihood-based confidence interval, starting from the mode of the posterior density and then looking for a common threshold value for the density to define the boundary of the credible interval. When the posterior density has multiple modes the HPD interval may be disjoint. HPD intervals are also well defined for multivariate <span class="math inline">\(\boldsymbol \theta\)</span> with the boundaries given by the contour lines of the posterior density resulting from the threshold value.</p>
<p>In the Worksheet B1 examples for both types of credible intervals are given and compared visually.</p>
</div>
<div id="practical-application-of-bayes-statistics-on-the-computer" class="section level3" number="9.1.6">
<h3>
<span class="header-section-number">9.1.6</span> Practical application of Bayes statistics on the computer<a class="anchor" aria-label="anchor" href="#practical-application-of-bayes-statistics-on-the-computer"><i class="fas fa-link"></i></a>
</h3>
<p>As we have seen Bayesian learning is <em>conceptually straightforward</em>:</p>
<ol style="list-style-type: decimal">
<li>Specify prior uncertainty <span class="math inline">\(p(\boldsymbol \theta\)</span>) about the parameters of interest <span class="math inline">\(\boldsymbol \theta\)</span>.</li>
<li>Specify the data generating process for a specified parameter: <span class="math inline">\(p(x | \boldsymbol \theta)\)</span>.</li>
<li>Apply Bayes’ theorem to update prior uncertainty in the light
of the new data.</li>
</ol>
<p>In practise, however, computing the posterior distribution can be <em>computationally very demanding</em>, especially
for complex models.</p>
<p>For this reason specialised software packages have been developed for computational Bayesian modelling, for example:</p>
<ul>
<li><p>Bayesian statistics in R: <a href="https://cran.r-project.org/web/views/Bayesian.html" class="uri">https://cran.r-project.org/web/views/Bayesian.html</a></p></li>
<li><p>Stan probabilistic programming language (interfaces with R, Python, Julia and other languages) — <a href="https://mc-stan.org/" class="uri">https://mc-stan.org/</a></p></li>
<li><p>Bayesian statistics in Python:
<a href="https://github.com/pymc-devs/pymc">PyMC</a> using <a href="https://aesara.readthedocs.io">Aesara</a>/<a href="https://jax.readthedocs.io">JAX</a> as backend,
<a href="http://num.pyro.ai/">NumPyro</a> using <a href="https://jax.readthedocs.io">JAX</a> as backend,
<a href="https://www.tensorflow.org/probability/examples/TensorFlow_Probability_on_JAX">TensorFlow Probability on JAX</a> using <a href="https://jax.readthedocs.io">JAX</a> as backend,
<a href="https://docs.pymc.io/">PyMC3</a> using <a href="https://theano.readthedocs.io">Theano</a> as backend,
<a href="http://docs.pyro.ai/">Pyro</a> using <a href="https://pytorch.org/">PyTorch</a> as backend,
<a href="https://www.tensorflow.org/probability/">TensorFlow Probability</a> using <a href="https://www.tensorflow.org/">Tensorflow</a> as backend.</p></li>
<li><p>Bayesian statistics in Julia: <a href="https://github.com/TuringLang/Turing.jl">Turing.jl</a></p></li>
<li><p>Bayesian hierarchical modelling with <a href="https://www.mrc-bsu.cam.ac.uk/software/bugs/">BUGS</a>, <a href="https://mcmc-jags.sourceforge.io/">JAGS</a> and <a href="https://r-nimble.org/">NIMBLE</a>.</p></li>
</ul>
<p>In addition to numerical procedures to sample from the posterior distribution there are also many procedures aiming to approximate the Bayesian posterior, employing the <a href="https://en.wikipedia.org/wiki/Laplace%27s_method">Laplace approximation</a>, integrated nested Laplace approximation (INLA), <a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">variational Bayes</a> etc.</p>
</div>
</div>
<div id="some-background-on-bayesian-statistics" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> Some background on Bayesian statistics<a class="anchor" aria-label="anchor" href="#some-background-on-bayesian-statistics"><i class="fas fa-link"></i></a>
</h2>
<div id="bayesian-interpretation-of-probability" class="section level3" number="9.2.1">
<h3>
<span class="header-section-number">9.2.1</span> Bayesian interpretation of probability<a class="anchor" aria-label="anchor" href="#bayesian-interpretation-of-probability"><i class="fas fa-link"></i></a>
</h3>
<div id="what-makes-you-bayesian" class="section level4" number="9.2.1.1">
<h4>
<span class="header-section-number">9.2.1.1</span> What makes you “Bayesian”?<a class="anchor" aria-label="anchor" href="#what-makes-you-bayesian"><i class="fas fa-link"></i></a>
</h4>
<p>If you use Bayes’ theorem are you therefore automatically a Bayesian? No!!</p>
<p>Bayes’ theorem is a mathematical fact from probability theory.
Hence, Bayes’ theorem is valid for everyone, whichever form for
statistical learning your are subscribing (such as frequentist ideas,
likelihood methods, entropy learning, Bayesian learning).</p>
<p>As we discuss now the key difference between Bayesian and frequentist
statistical learning lies in the differences in <em>interpretation of probability</em>,
not in the mathematical formalism for probability (which includes Bayes’ theorem).</p>
</div>
<div id="mathematics-of-probability" class="section level4" number="9.2.1.2">
<h4>
<span class="header-section-number">9.2.1.2</span> Mathematics of probability<a class="anchor" aria-label="anchor" href="#mathematics-of-probability"><i class="fas fa-link"></i></a>
</h4>
<p>The mathematics of probability in its modern foundation was developed by <a href="https://en.wikipedia.org/wiki/Andrey_Kolmogorov">Andrey Kolmogorov (1903–1987)</a>. In this book <a href="https://en.wikipedia.org/wiki/Probability_axioms">Foundations of the Theory of Probability (1933)</a> he establishes probability in terms of set theory/ measure theory. This theory provides a coherent mathematical framework to work with probabilities.</p>
<p>However, Kolmogorov’s theory does <em>not</em> provide an interpretation of probability!</p>
<p><span class="math inline">\(\rightarrow\)</span> The Kolmogorov framework is the basis for both the frequentist and the Bayesian interpretation of probability.</p>
</div>
<div id="interpretations-of-probability" class="section level4" number="9.2.1.3">
<h4>
<span class="header-section-number">9.2.1.3</span> Interpretations of probability<a class="anchor" aria-label="anchor" href="#interpretations-of-probability"><i class="fas fa-link"></i></a>
</h4>
<p>Essentially, there are two major commonly used interpretation of probability in statistics - the <strong>frequentist interpretation</strong> and the <strong>Bayesian interpretation</strong>.</p>
<p><strong>A: Frequentist interpretation</strong></p>
<p>probability = frequency (of an event in a long-running series of identically repeated experiments)</p>
<p>This is the <em>ontological view</em> of probability (i.e. probability “exists” and is identical to something that can be observed.).</p>
<p>It is also a very restrictive view of probability. For example, frequentist probability
cannot be used to describe events that occur only a single time.
Frequentist probability thus can only be applied asymptotically, for large samples!</p>
<p><strong>B: Bayesian probability</strong></p>
<p>“Probability does not exist” — famous quote by <a href="https://en.wikipedia.org/wiki/Bruno_de_Finetti">Bruno de Finetti (1906–1985)</a>, a Bayesian statistician.</p>
<p>What does this mean?</p>
<p>Probability is a <strong>description of the state of knowledge</strong> and of <strong>uncertainty</strong>.</p>
<p>Probability is thus an <em>epistemological quantity</em> that is assigned and that changes rather than something that is an inherent property of an object.</p>
<p>Note that this does not require any repeated experiments.
The Bayesian interpretation of probability is valid regardless of sample size or the number or repetitions of an experiment.</p>
<p><strong>Hence, the key difference between frequentist and Bayesian approaches is not the use of Bayes’ theorem.
Rather it is whether you consider probability as ontological (frequentist) or epistemological entity (Bayesian).</strong></p>
</div>
</div>
<div id="historical-developments" class="section level3" number="9.2.2">
<h3>
<span class="header-section-number">9.2.2</span> Historical developments<a class="anchor" aria-label="anchor" href="#historical-developments"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Bayesian statistics is named after <a href="https://de.wikipedia.org/wiki/Thomas_Bayes">Thomas Bayes</a> (1701-1761). His paper <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Bayes, T. 1763. &lt;em&gt;An essay towards solving a problem in the doctrine of chances&lt;/em&gt;.
The Philosophical Transactions &lt;strong&gt;53&lt;/strong&gt;:370–418. &lt;a href="https://doi.org/10.1098/rstl.1763.0053" class="uri"&gt;https://doi.org/10.1098/rstl.1763.0053&lt;/a&gt;&lt;/p&gt;'><sup>8</sup></a> introducing the famous theorem was published only after his death (1763).</li>
</ul>
<ul>
<li>
<a href="https://de.wikipedia.org/wiki/Pierre-Simon_Laplace">Pierre-Simon Laplace</a> (1749-1827) was the first to practically use Bayes’ theorem for statistical calculations, and he also independently discovered Bayes’ theorem in 1774 <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Laplace, P.-S. 1774. &lt;em&gt;Mémoire sur la probabilité de causes par les évenements&lt;/em&gt;.
Mémoires de mathématique et de physique, présentés à l’Académie Royale des sciences par divers savants et lus dans ses assemblées. Paris, Imprimerie Royale, pp. 621–657.&lt;/p&gt;"><sup>9</sup></a>
</li>
</ul>
<ul>
<li><p>This activity was then called “<a href="https://en.wikipedia.org/wiki/Inverse_probability">inverse probability</a>” and not “Bayesian statistics”.</p></li>
<li><p>Between 1900 and 1940 classical mathematical statistics was developed and the field was heavily influenced and dominated by <a href="https://en.wikipedia.org/wiki/Ronald_Fisher">R.A. Fisher</a> (who invented likelihood theory and ANOVA, among other things - he was also working in biology and was professor of genetics). Fisher was very much opposed to Bayesian statistics.</p></li>
<li><p>1931 <a href="https://en.wikipedia.org/wiki/Bruno_de_Finetti">Bruno de Finetti</a> publishes his “<a href="https://en.wikipedia.org/wiki/De_Finetti%27s_theorem">representation theorem</a>”. This shows that the joint distribution of a sequence of exchangeable events (i.e. where the ordering can be permuted) can be represented by a mixture distribution that can be constructed via Bayes’ theorem. (Note that exchangeability is a weaker condition than i.i.d.)
This theorem is often used as a justification of Bayesian statistics (along with the so-called Dutch book argument, also by de Finetti).</p></li>
<li><p>1933 publication of <a href="https://en.wikipedia.org/wiki/Andrey_Kolmogorov">Andrey Kolmogorov</a>’s book on probability theory.</p></li>
<li><p>1946 Cox theorem by <a href="https://en.wikipedia.org/wiki/Richard_Threlkeld_Cox">Richard T. Cox (1898–1991)</a>: the aim to generalise classical logic from TRUE/FALSE statements to continuous measures of uncertainty inevitably leads to probability theory and Bayesian learning! This justification of Bayesian statistics was later popularised by <a href="https://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes">Edwin T. Jaynes (1922–1998)</a> in various books (1959, 2003).</p></li>
<li><p>1955 Stein Paradox - <a href="https://en.wikipedia.org/wiki/Charles_M._Stein">Charles M. Stein (1920–2016)</a> publishes a paper on the Stein estimator — an estimator of the mean that dominates the ML estimator (i.e. the sample average). The Stein estimator is better in terms of MSE than the ML estimator, which was very puzzling at that time but it is easy to understand from a Bayesian perspective.</p></li>
<li><p>Only from the 1950s the use of the term “Bayesian statistics” became prevalent —
see Fienberg (2006) <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Fienberg, S. E. 2006. &lt;em&gt;When did Bayesian inference become “Bayesian”?&lt;/em&gt; Bayesian Analysis &lt;strong&gt;1&lt;/strong&gt;:1–40. &lt;a href="https://doi.org/10.1214/06-BA101" class="uri"&gt;https://doi.org/10.1214/06-BA101&lt;/a&gt;&lt;/p&gt;'><sup>10</sup></a></p></li>
</ul>
<p>Due to advances in personal computing from 1970 onwards Bayesian learning has become more pervasive!</p>
<ul>
<li>Computers allow to do the complex (numerical) calculations needed in Bayesian statistics .</li>
<li>Metropolis-Hastings algorithm published in 1970 (which allows to sample from a posterior distribution without explicitly computing the marginal likelihood).</li>
<li>Development of regularised estimation techniques such as penalised likelihood in regression (e.g. ridge regression 1970).</li>
<li>penalised likelihood via KL divergence for model selection (Akaike 1973).</li>
<li>A lot of work on interpreting Stein estimators as empirical Bayes estimators (Efron and Morris 1975)</li>
<li>regularisation originally was only meant to make singular systems/matrices invertible, but then it turned out regularisation has also a Bayesian interpretation.</li>
<li>Reference priors (Bernardo 1979) proposed as default priors for models with multiple parameters.</li>
<li>The EM algorithm (published in 1977) uses Bayes theorem for imputing the distribution of the latent variables.</li>
</ul>
<p>Another boost was in the 1990/2000s when in science (e.g. genomics) many complex and high-dimensional data set were becoming the norm, not the exception.</p>
<ul>
<li>Classical statistical methods cannot be used in this setting (overfitting!) so new methods were developed for high-dimensional data analysis, many with a direct link to Bayesian statistics</li>
<li>1996 lasso (L1 regularised) regression invented by <a href="https://en.wikipedia.org/wiki/Robert_Tibshirani">Robert Tibshirani</a>.</li>
<li>Machine learning methods for non-parametric and extremely highly parametric models (neural network) require either explicit or implicit regularisation.</li>
<li>Many Bayesians in this field, many using <a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">variational Bayes techniques</a> which may be viewed as generalisation of the EM algorithm and are also linked to methods used in statistical physics.</li>
</ul>
</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="models-with-latent-variables-and-missing-data.html"><span class="header-section-number">8</span> Models with latent variables and missing data</a></div>
<div class="next"><a href="bayesian-learning-in-practise.html"><span class="header-section-number">10</span> Bayesian learning in practise</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#essentials-of-bayesian-statistics"><span class="header-section-number">9</span> Essentials of Bayesian statistics</a></li>
<li>
<a class="nav-link" href="#principle-of-bayesian-learning"><span class="header-section-number">9.1</span> Principle of Bayesian learning</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#from-prior-to-posterior-distribution"><span class="header-section-number">9.1.1</span> From prior to posterior distribution</a></li>
<li><a class="nav-link" href="#zero-forcing-property"><span class="header-section-number">9.1.2</span> Zero forcing property</a></li>
<li><a class="nav-link" href="#bayesian-update-and-likelihood"><span class="header-section-number">9.1.3</span> Bayesian update and likelihood</a></li>
<li><a class="nav-link" href="#sequential-updates"><span class="header-section-number">9.1.4</span> Sequential updates</a></li>
<li><a class="nav-link" href="#summaries-of-posterior-distributions-and-credible-intervals"><span class="header-section-number">9.1.5</span> Summaries of posterior distributions and credible intervals</a></li>
<li><a class="nav-link" href="#practical-application-of-bayes-statistics-on-the-computer"><span class="header-section-number">9.1.6</span> Practical application of Bayes statistics on the computer</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#some-background-on-bayesian-statistics"><span class="header-section-number">9.2</span> Some background on Bayesian statistics</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#bayesian-interpretation-of-probability"><span class="header-section-number">9.2.1</span> Bayesian interpretation of probability</a></li>
<li><a class="nav-link" href="#historical-developments"><span class="header-section-number">9.2.2</span> Historical developments</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Statistics 2: Likelihood and Bayes</strong>" was written by Korbinian Strimmer. It was last built on 10 December 2023.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
