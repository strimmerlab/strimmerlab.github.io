<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>D Further distributions used in Bayesian analysis | Statistics 2: Likelihood and Bayes</title>
<meta name="author" content="Korbinian Strimmer">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="D Further distributions used in Bayesian analysis | Statistics 2: Likelihood and Bayes">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="D Further distributions used in Bayesian analysis | Statistics 2: Likelihood and Bayes">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<meta name="description" content="This appendix introduces a number of distributions essential for Bayesian analysis. See in particular the Chapter “Bayesian learning in practise”.  D.1 Beta distribution  D.1.1 Standard...">
<meta property="og:description" content="This appendix introduces a number of distributions essential for Bayesian analysis. See in particular the Chapter “Bayesian learning in practise”.  D.1 Beta distribution  D.1.1 Standard...">
<meta name="twitter:description" content="This appendix introduces a number of distributions essential for Bayesian analysis. See in particular the Chapter “Bayesian learning in practise”.  D.1 Beta distribution  D.1.1 Standard...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Statistics 2: Likelihood and Bayes</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li class="book-part">Likelihood estimation and inference</li>
<li><a class="" href="overview-of-statistical-learning.html"><span class="header-section-number">1</span> Overview of statistical learning</a></li>
<li><a class="" href="from-entropy-to-maximum-likelihood.html"><span class="header-section-number">2</span> From entropy to maximum likelihood</a></li>
<li><a class="" href="maximum-likelihood-estimation.html"><span class="header-section-number">3</span> Maximum likelihood estimation</a></li>
<li><a class="" href="quadratic-approximation-and-normal-asymptotics.html"><span class="header-section-number">4</span> Quadratic approximation and normal asymptotics</a></li>
<li><a class="" href="likelihood-based-confidence-interval-and-likelihood-ratio.html"><span class="header-section-number">5</span> Likelihood-based confidence interval and likelihood ratio</a></li>
<li><a class="" href="optimality-properties-and-conclusion.html"><span class="header-section-number">6</span> Optimality properties and conclusion</a></li>
<li class="book-part">Bayesian Statistics</li>
<li><a class="" href="conditioning-and-bayes-rule.html"><span class="header-section-number">7</span> Conditioning and Bayes rule</a></li>
<li><a class="" href="models-with-latent-variables-and-missing-data.html"><span class="header-section-number">8</span> Models with latent variables and missing data</a></li>
<li><a class="" href="essentials-of-bayesian-statistics.html"><span class="header-section-number">9</span> Essentials of Bayesian statistics</a></li>
<li><a class="" href="bayesian-learning-in-practise.html"><span class="header-section-number">10</span> Bayesian learning in practise</a></li>
<li><a class="" href="bayesian-model-comparison.html"><span class="header-section-number">11</span> Bayesian model comparison</a></li>
<li><a class="" href="choosing-priors-in-bayesian-analysis.html"><span class="header-section-number">12</span> Choosing priors in Bayesian analysis</a></li>
<li><a class="" href="optimality-properties-and-summary.html"><span class="header-section-number">13</span> Optimality properties and summary</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="matrix-and-calculus-refresher.html"><span class="header-section-number">A</span> Matrix and calculus refresher</a></li>
<li><a class="" href="probability-and-statistics-refresher.html"><span class="header-section-number">B</span> Probability and statistics refresher</a></li>
<li><a class="" href="distribution-refresher.html"><span class="header-section-number">C</span> Distribution refresher</a></li>
<li><a class="active" href="further-distributions-used-in-bayesian-analysis.html"><span class="header-section-number">D</span> Further distributions used in Bayesian analysis</a></li>
<li><a class="" href="further-study.html"><span class="header-section-number">E</span> Further study</a></li>
<li><a class="" href="bibliography.html">Bibliography</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="further-distributions-used-in-bayesian-analysis" class="section level1" number="17">
<h1>
<span class="header-section-number">D</span> Further distributions used in Bayesian analysis<a class="anchor" aria-label="anchor" href="#further-distributions-used-in-bayesian-analysis"><i class="fas fa-link"></i></a>
</h1>
<p>This appendix introduces a number of distributions
essential for Bayesian analysis.</p>
<p>See in particular the Chapter “Bayesian learning in practise”.</p>
<div id="beta-distribution" class="section level2" number="17.1">
<h2>
<span class="header-section-number">D.1</span> Beta distribution<a class="anchor" aria-label="anchor" href="#beta-distribution"><i class="fas fa-link"></i></a>
</h2>
<div id="standard-parameterisation" class="section level3" number="17.1.1">
<h3>
<span class="header-section-number">D.1.1</span> Standard parameterisation<a class="anchor" aria-label="anchor" href="#standard-parameterisation"><i class="fas fa-link"></i></a>
</h3>
<p>The density of the beta distribution <span class="math inline">\(\text{Beta}(\alpha, \beta)\)</span> is
<span class="math display">\[
p(x | \alpha, \beta) = \frac{1}{B(\alpha, \beta)} x^{\alpha-1} (1-x)^{\beta-1}
\]</span>
with <span class="math inline">\(x \in [0,1]\)</span> and <span class="math inline">\(\alpha&gt;0\)</span> and <span class="math inline">\(\beta&gt;0\)</span>.
The density depends on the beta function <span class="math inline">\(B(z_1, z_1) = \frac{ \Gamma(z_1) \Gamma(z_2)}{\Gamma(z_1 + z_2)}\)</span>
which in turn is defined via Euler’s gamma function <span class="math inline">\(\Gamma(x)\)</span>.
Note that <span class="math inline">\(\Gamma(x) = (x-1)!\)</span> for any positive integer <span class="math inline">\(x\)</span>.</p>
<p>The mean of the beta distribution is
<span class="math display">\[
\text{E}(x) = \frac{\alpha}{\alpha+\beta}
\]</span>
and its variance is
<span class="math display">\[
\text{Var}(x)=\frac{\alpha \beta}{(\alpha+\beta)^2 (\alpha+\beta+1)}
\]</span></p>
<p>The beta distribution is very flexible and can assume a number of different shapes, depending on the value of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>:</p>
<div class="inline-figure"><img src="fig/bayes2-betashapes.png" width="80%" style="display: block; margin: auto;"></div>
</div>
<div id="mean-parameterisation" class="section level3" number="17.1.2">
<h3>
<span class="header-section-number">D.1.2</span> Mean parameterisation<a class="anchor" aria-label="anchor" href="#mean-parameterisation"><i class="fas fa-link"></i></a>
</h3>
<p>A useful reparameterisation <span class="math inline">\(\text{Beta}(\mu, k)\)</span> of the beta distribution is in terms of a mean parameter
<span class="math inline">\(\mu \in [0,1]\)</span> and a concentration parameter <span class="math inline">\(k &gt; 0\)</span>. These are given by
<span class="math display">\[
k=\alpha+\beta
\]</span>
and
<span class="math display">\[\mu = \frac{\alpha}{\alpha+\beta}
\]</span>
The original parameters can be recovered by
<span class="math display">\[\alpha= \mu k\]</span> and <span class="math display">\[\beta=(1-\mu) k\]</span></p>
<p>The mean and variance of the beta distribution expressed in terms of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(k\)</span> are
<span class="math display">\[
\text{E}(x) = \mu
\]</span>
and
<span class="math display">\[
\text{Var}(x)=\frac{\mu (1-\mu)}{k+1}
\]</span>
With increasing concentration parameter <span class="math inline">\(k\)</span> the variance decreases and thus the probability mass becomes more concentrated around the mean.</p>
</div>
</div>
<div id="inverse-gamma-inverse-wishart-distribution" class="section level2" number="17.2">
<h2>
<span class="header-section-number">D.2</span> Inverse gamma (inverse Wishart) distribution<a class="anchor" aria-label="anchor" href="#inverse-gamma-inverse-wishart-distribution"><i class="fas fa-link"></i></a>
</h2>
<div id="standard-parameterisation-1" class="section level3" number="17.2.1">
<h3>
<span class="header-section-number">D.2.1</span> Standard parameterisation<a class="anchor" aria-label="anchor" href="#standard-parameterisation-1"><i class="fas fa-link"></i></a>
</h3>
<p>The inverse gamma (IG) distribution <span class="math inline">\(\text{Inv-Gam}(\alpha, \beta)\)</span>
has density
<span class="math display">\[
\frac{\beta^{\alpha}}{\Gamma(\alpha)} (1/x)^{\alpha+1} e^{-\beta/x}
\]</span>
with two parameters <span class="math inline">\(\alpha &gt;0\)</span> (shape parameter) and <span class="math inline">\(\beta &gt;0\)</span> (scale parameter) and support <span class="math inline">\(x &gt;0\)</span>.</p>
<p>The mean of the inverse gamma distribution is
<span class="math display">\[\text{E}(x) = \frac{\beta}{\alpha-1}\]</span>
and the variance
<span class="math display">\[\text{Var}(x) = \frac{\beta^2}{(\alpha-1)^2 (\alpha-2)}\]</span></p>
<p>Thus, for the mean to exist we have the restriction
<span class="math inline">\(\alpha&gt;1\)</span> and for the variance to exist <span class="math inline">\(\alpha&gt;2\)</span>.</p>
<p>The IG distribution is closely linked with the gamma distribution.
If <span class="math inline">\(x \sim \text{Inv-Gam}(\alpha, \beta)\)</span> is IG-distributed then the inverse of <span class="math inline">\(x\)</span> is gamma distributed:
<span class="math display">\[\frac{1}{x} \sim \text{Gam}(\alpha, \theta=\beta^{-1})\]</span>
where <span class="math inline">\(\alpha\)</span> is the shared shape parameter and <span class="math inline">\(\theta\)</span> the scale parameter of the gamma distribution.</p>
</div>
<div id="wishart-parameterisation" class="section level3" number="17.2.2">
<h3>
<span class="header-section-number">D.2.2</span> Wishart parameterisation<a class="anchor" aria-label="anchor" href="#wishart-parameterisation"><i class="fas fa-link"></i></a>
</h3>
<p>The inverse gamma distribution is frequently used with a different
set of parameters
<span class="math inline">\(\psi = 2\beta\)</span> (scale parameter) and <span class="math inline">\(\nu = 2\alpha\)</span> (shape parameter), or
conversely <span class="math inline">\(\alpha=\nu/2\)</span> and <span class="math inline">\(\beta=\psi/2\)</span>.
In this form it is called <strong>one-dimensional inverse Wishart distribution</strong>
<span class="math inline">\(W^{-1}_1(\psi, \nu)\)</span> with mean and variance given by
<span class="math display">\[
\text{E}(x) = \frac{\psi}{\nu-2} = \mu
\]</span>
for <span class="math inline">\(\nu&gt;2\)</span> and
<span class="math display">\[
\text{Var}(x) =\frac{2 \psi^2}{(\nu-4) (\nu-2)^2}  = \frac{2 \mu^2}{\nu-4}
\]</span>
for <span class="math inline">\(\nu &gt;4\)</span>.</p>
<p>Instead of <span class="math inline">\(\psi\)</span> and <span class="math inline">\(\nu\)</span> we may also equivalently use <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\kappa=\nu-2\)</span> as parameters for the inverse
Wishart distribution, so that <span class="math inline">\(W^{-1}_1(\psi=\kappa \mu, \nu=\kappa+2)\)</span>
has mean
<span class="math display">\[\text{E}(x) = \mu\]</span>
with <span class="math inline">\(\kappa&gt;0\)</span> and the variance is
<span class="math display">\[\text{Var}(x) = \frac{2 \mu^2}{\kappa-2}\]</span> with
<span class="math inline">\(\kappa&gt;2\)</span>.
This <strong>mean parameterisation</strong> is useful when employing the IG distribution
as prior and posterior.</p>
<p>Finally, with <span class="math inline">\(W^{-1}_1(\psi=\nu \tau^2, \nu)\)</span>, where
<span class="math inline">\(\tau^2 = \mu \frac{ \kappa}{\kappa+2} = \frac{\psi}{\nu}\)</span> is a
biased mean parameter, we get
the <strong>scaled inverse chi-squared distribution</strong> <span class="math inline">\(\tau^2 \text{Inv-$\chi^2_{\nu}$}\)</span>
with
<span class="math display">\[
\text{E}(x) = \tau^2 \frac{ \nu}{\nu-2}
\]</span>
for <span class="math inline">\(\nu&gt;2\)</span> and
<span class="math display">\[
\text{Var}(x) =\frac{2 \tau^4}{\nu-4} \frac{\nu^2}{(\nu-2)^2}
\]</span>
for <span class="math inline">\(\nu &gt;4\)</span>.</p>
<p>The inverse Wishart and Wishart distributions are linked.
If <span class="math inline">\(x \sim W^{-1}_1(\psi, \nu)\)</span> is inverse-Wishart distributed then the inverse of <span class="math inline">\(x\)</span> is Wishart distributed with inverted scale parameter:
<span class="math display">\[\frac{1}{x} \sim W_1(s^2=\psi^{-1}, k=\nu)\]</span>
where <span class="math inline">\(k\)</span> is the shape parameter and <span class="math inline">\(s^2\)</span> the scale parameter of the Wishart distribution.</p>
</div>
</div>
<div id="location-scale-t-distribution-as-compound-distribution" class="section level2" number="17.3">
<h2>
<span class="header-section-number">D.3</span> Location-scale <span class="math inline">\(t\)</span>-distribution as compound distribution<a class="anchor" aria-label="anchor" href="#location-scale-t-distribution-as-compound-distribution"><i class="fas fa-link"></i></a>
</h2>
<p>Suppose that
<span class="math display">\[
x | s^2 \sim N(\mu,s^2)
\]</span> with corresponding density <span class="math inline">\(p(x | s^2)\)</span>
and mean <span class="math inline">\(\text{E}(x | s^2) = \mu\)</span> and variance <span class="math inline">\(\text{Var}(x|s^2) = s^2\)</span>.</p>
<p>Now let the variance <span class="math inline">\(s^2\)</span> be distributed as inverse gamma / inverse Wishart
<span class="math display">\[
s^2 \sim  W^{-1}(\psi=\kappa \sigma^2, \nu=\kappa+2) = W^{-1}(\psi=\tau^2\nu, \nu)
\]</span>
with corresponding density <span class="math inline">\(p(s^2)\)</span> and mean <span class="math inline">\(\text{E}(s^2) = \sigma^2 = \tau^2 \nu/(\nu-2)\)</span>.
Note we use here both the mean parameterisation (<span class="math inline">\(\sigma^2, \kappa\)</span>)
and the inverse chi-squared parameterisation (<span class="math inline">\(\tau^2, \nu\)</span>).</p>
<p>The joint density for <span class="math inline">\(x\)</span> and <span class="math inline">\(s^2\)</span> is <span class="math inline">\(p(x, s^2) = p(x | s^2) p(s^2)\)</span>.
We are interested in the marginal density for <span class="math inline">\(x\)</span>:
<span class="math display">\[
p(x) = \int p(x, s^2) ds^2  = \int p(s^2)  p(x | s^2) ds^2
\]</span>
This is a compound distribution of a normal with fixed mean <span class="math inline">\(\mu\)</span>
and variance <span class="math inline">\(s^2\)</span> varying according the inverse gamma distribution.
Calculating the integral results in
the location-scale <span class="math inline">\(t\)</span>-distribution with parameters
<span class="math display">\[
x \sim  \text{lst}\left(\mu, \sigma^2 \frac{\kappa}{\kappa+2}, \kappa+2\right) = \text{lst}\left(\mu, \tau^2, \nu\right)
\]</span>
with mean
<span class="math display">\[
\text{E}(x) = \mu
\]</span>
and
variance
<span class="math display">\[
\text{Var}(x) = \sigma^2 =\tau^2 \frac{\nu}{\nu-2}
\]</span></p>
<p>From the law of total expectation and variance we can also directly verify that
<span class="math display">\[
\text{E}(x) = \text{E}( \text{E}(x| s^2) ) =\mu
\]</span>
and
<span class="math display">\[
\text{Var}(x) = \text{E}(\text{Var}(x|s^2))+ \text{Var}(\text{E}(x|s^2)) = \text{E}(s^2) = \sigma^2 =\tau^2 \frac{\nu}{\nu-2}
\]</span></p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="distribution-refresher.html"><span class="header-section-number">C</span> Distribution refresher</a></div>
<div class="next"><a href="further-study.html"><span class="header-section-number">E</span> Further study</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#further-distributions-used-in-bayesian-analysis"><span class="header-section-number">D</span> Further distributions used in Bayesian analysis</a></li>
<li>
<a class="nav-link" href="#beta-distribution"><span class="header-section-number">D.1</span> Beta distribution</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#standard-parameterisation"><span class="header-section-number">D.1.1</span> Standard parameterisation</a></li>
<li><a class="nav-link" href="#mean-parameterisation"><span class="header-section-number">D.1.2</span> Mean parameterisation</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#inverse-gamma-inverse-wishart-distribution"><span class="header-section-number">D.2</span> Inverse gamma (inverse Wishart) distribution</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#standard-parameterisation-1"><span class="header-section-number">D.2.1</span> Standard parameterisation</a></li>
<li><a class="nav-link" href="#wishart-parameterisation"><span class="header-section-number">D.2.2</span> Wishart parameterisation</a></li>
</ul>
</li>
<li><a class="nav-link" href="#location-scale-t-distribution-as-compound-distribution"><span class="header-section-number">D.3</span> Location-scale \(t\)-distribution as compound distribution</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Statistics 2: Likelihood and Bayes</strong>" was written by Korbinian Strimmer. It was last built on 13 December 2023.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
