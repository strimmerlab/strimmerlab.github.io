<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>3 Transforming and combining random variables | Probability and Distribution Refresher</title>
<meta name="author" content="Korbinian Strimmer">
<meta name="generator" content="bookdown 0.38 with bs4_book()">
<meta property="og:title" content="3 Transforming and combining random variables | Probability and Distribution Refresher">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="3 Transforming and combining random variables | Probability and Distribution Refresher">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<meta name="description" content="3.1 Affine or location-scale transformation of random variables Suppose \(a\) and \(b\) are constants and \(x \sim F_x\) is a scalar random variable with mean \(\text{E}(x) = \mu_x\) and variance...">
<meta property="og:description" content="3.1 Affine or location-scale transformation of random variables Suppose \(a\) and \(b\) are constants and \(x \sim F_x\) is a scalar random variable with mean \(\text{E}(x) = \mu_x\) and variance...">
<meta name="twitter:description" content="3.1 Affine or location-scale transformation of random variables Suppose \(a\) and \(b\) are constants and \(x \sim F_x\) is a scalar random variable with mean \(\text{E}(x) = \mu_x\) and variance...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Probability and Distribution Refresher</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="combinatorics.html"><span class="header-section-number">1</span> Combinatorics</a></li>
<li><a class="" href="probability.html"><span class="header-section-number">2</span> Probability</a></li>
<li><a class="active" href="transforming-and-combining-random-variables.html"><span class="header-section-number">3</span> Transforming and combining random variables</a></li>
<li><a class="" href="univariate-distributions.html"><span class="header-section-number">4</span> Univariate distributions</a></li>
<li><a class="" href="multivariate-distributions.html"><span class="header-section-number">5</span> Multivariate distributions</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="transforming-and-combining-random-variables" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Transforming and combining random variables<a class="anchor" aria-label="anchor" href="#transforming-and-combining-random-variables"><i class="fas fa-link"></i></a>
</h1>
<div id="affine-or-location-scale-transformation-of-random-variables" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Affine or location-scale transformation of random variables<a class="anchor" aria-label="anchor" href="#affine-or-location-scale-transformation-of-random-variables"><i class="fas fa-link"></i></a>
</h2>
<p>Suppose <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are constants and <span class="math inline">\(x \sim F_x\)</span> is a scalar random variable
with mean <span class="math inline">\(\text{E}(x) = \mu_x\)</span> and variance <span class="math inline">\(\text{Var}(x) = \sigma^2_x\)</span>.
The random variable <span class="math inline">\(y= a + b x\)</span> is a <strong>location-scale transformation</strong> or <strong>affine
transformation</strong> of <span class="math inline">\(x\)</span>, where <span class="math inline">\(a\)</span> plays the role of the <strong>location parameter</strong> and <span class="math inline">\(b\)</span> is
the <strong>scale parameter</strong>. For <span class="math inline">\(a=0\)</span> with no translation this is a <strong>linear transformation</strong>.
If <span class="math inline">\(b\neq 0\)</span> then the transformation is <strong>invertible</strong>, with <span class="math inline">\(x = (y-a)/b\)</span>.
Invertible transformations provide a one-to-one map between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
<p>The random variable <span class="math inline">\(y \sim F_y\)</span> has mean
<span class="math display">\[\text{E}(y) = a + b \mu_x\]</span>
and
variance
<span class="math display">\[\text{Var}(y) = b^2 \sigma^2_x\]</span></p>
<p>If <span class="math inline">\(x\)</span> is a continuous random variable with density <span class="math inline">\(f_{x}(x)\)</span> and assuming
an invertible transformation the density for <span class="math inline">\(y\)</span> is given by
<span class="math display">\[
f_{y}(y)=|b|^{-1} f_{x} \left( \frac{y-a}{b}\right)
\]</span></p>
<p>For a random vector <span class="math inline">\(\boldsymbol x\)</span> of dimension <span class="math inline">\(d\)</span> and location parameter <span class="math inline">\(\boldsymbol a\)</span> (a <span class="math inline">\(m \times 1\)</span> vector) and
scale parameter <span class="math inline">\(\boldsymbol B\)</span> (a <span class="math inline">\(m \times d\)</span> matrix) the location-scale transformation is
<span class="math inline">\(\boldsymbol y= \boldsymbol a+ \boldsymbol B\boldsymbol x\)</span>.
For <span class="math inline">\(m=d\)</span> (square <span class="math inline">\(\boldsymbol B\)</span>) and <span class="math inline">\(\det(\boldsymbol B) \neq 0\)</span> the affine transformation is <strong>invertible</strong>,
with forward transformation <span class="math inline">\(\boldsymbol y= \boldsymbol a+ \boldsymbol B\boldsymbol x\)</span> and backtransformation
<span class="math inline">\(\boldsymbol x= \boldsymbol B^{-1}(\boldsymbol y-\boldsymbol a)\)</span>.</p>
<p>Suppose the mean and variance of the original random vector <span class="math inline">\(\boldsymbol x\)</span> is
<span class="math inline">\(\text{E}(\boldsymbol x)=\boldsymbol \mu_{\boldsymbol x}\)</span> and <span class="math inline">\(\text{Var}(\boldsymbol x)=\boldsymbol \Sigma_{\boldsymbol x}\)</span>. Then the
mean and variance of the transformed random vector <span class="math inline">\(\boldsymbol y\)</span> is
<span class="math display">\[\text{E}(\boldsymbol y)=\boldsymbol a+ \boldsymbol B\,\boldsymbol \mu_{\boldsymbol x}\]</span>
and
<span class="math display">\[\text{Var}(\boldsymbol y)= \boldsymbol B\,\boldsymbol \Sigma_{\boldsymbol x} \,\boldsymbol B^T\]</span></p>
<p>Assuming an invertible transformation for a continous random vector <span class="math inline">\(\boldsymbol x\)</span>
with density <span class="math inline">\(f_{\boldsymbol x}(\boldsymbol x)\)</span> the density for <span class="math inline">\(\boldsymbol y\)</span> is given by
<span class="math display">\[
f_{\boldsymbol y}(\boldsymbol y)=|\det(\boldsymbol B)|^{-1} f_{\boldsymbol x} \left( \boldsymbol B^{-1}(\boldsymbol y-\boldsymbol a)\right)
\]</span></p>
<p>The constants <span class="math inline">\(\boldsymbol a\)</span> and <span class="math inline">\(\boldsymbol B\)</span> (or <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> in the univariate case)
are the parameters of the <strong>location-scale family</strong> <span class="math inline">\(F_{\boldsymbol y}\)</span> created from <span class="math inline">\(F_{\boldsymbol x}\)</span>.
Many important distributions are location-scale families (e.g. the normal distribution and
the location-scale <span class="math inline">\(t\)</span> distribution). Furthermore, key procedures in multivariate statistics
such as orthogonal transformations (including PCA) or whitening transformations (e.g. the Mahalanobis transformation) are affine transformations.</p>
</div>
<div id="general-invertible-transformation-of-random-variables" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> General invertible transformation of random variables<a class="anchor" aria-label="anchor" href="#general-invertible-transformation-of-random-variables"><i class="fas fa-link"></i></a>
</h2>
<p>As a generalisation of invertible affine transformations
we now consider general invertible transformations.
For a scalar random variable we assume the transfomation is specified by
<span class="math inline">\(y = y(x) = h(x)\)</span> and the backtransformation by <span class="math inline">\(x = x(y) = h^{-1}(y)\)</span>
For a random vector we assume <span class="math inline">\(\boldsymbol y(\boldsymbol x) = \boldsymbol h(\boldsymbol x)\)</span> is invertible
with <span class="math inline">\(\boldsymbol x(\boldsymbol y) = \boldsymbol h^{-1}(\boldsymbol y)\)</span>.</p>
<p>The mean and variance of the transformed random variable can typically
only be approximated. Linearising the
transformation and computing the correponding means and variance
is known as the <strong>delta method</strong>.</p>
<p>In the univariate case the delta method yields
<span class="math display">\[
\text{E}(y) \approx y(\mu_x)
\]</span>
and
<span class="math display">\[
\text{Var}(y)\approx (D y(\mu_x))^2 \, \sigma^2_x  
\]</span>
where <span class="math inline">\(D y(x) = y'(x)\)</span> is the first derivative of the transformation
<span class="math inline">\(y(x)\)</span> and <span class="math inline">\(D y(\mu_x)\)</span> is the first derivative evaluated at the mean <span class="math inline">\(\mu_x\)</span></p>
<p>The density of the transformed variable can be computed exactly and is given by
<span class="math display">\[
f_y(y) =\left| D x(y) \right| f_x(x(y))
\]</span>
Note in the above the use of the inverse transformation <span class="math inline">\(x(y)\)</span> and its derivative
<span class="math inline">\(D x(y)\)</span>.</p>
<p>Assuming <span class="math inline">\(y(x) = a + b x\)</span>, with <span class="math inline">\(x(y) = (y-a)/b\)</span>, <span class="math inline">\(D y(x) = b\)</span>
and <span class="math inline">\(D x(y) = b^{-1}\)</span>, recovers the location-scale transformation.</p>
<p>For the vector random variable the delta method yields as approximation
for the mean and variance
<span class="math display">\[\text{E}(\boldsymbol y)\approx\boldsymbol y(\boldsymbol \mu_{\boldsymbol x})\]</span>
and
<span class="math display">\[
\text{Var}(\boldsymbol y)\approx D \boldsymbol y(\boldsymbol \mu_{\boldsymbol x}) \, \boldsymbol \Sigma_{\boldsymbol x} \, D\boldsymbol y(\boldsymbol \mu_{\boldsymbol x})^T
\]</span>
where <span class="math inline">\(D \boldsymbol y(\boldsymbol x)\)</span> is the
Jacobian matrix (vector derivative) for the transformation <span class="math inline">\(\boldsymbol y(\boldsymbol x)\)</span>
and <span class="math inline">\(D \boldsymbol y(\boldsymbol \mu_{\boldsymbol x})\)</span> is the Jacobian matrix
evaluated at the mean <span class="math inline">\(\boldsymbol \mu_{\boldsymbol x}\)</span>.</p>
<p>The density for <span class="math inline">\(\boldsymbol y\)</span> is obtained by
<span class="math display">\[
f_{\boldsymbol y}(\boldsymbol y) = |\det\left( D\boldsymbol x(\boldsymbol y) \right)| \,\,\,  f_{\boldsymbol x}\left( \boldsymbol x(\boldsymbol y) \right)
\]</span>
where <span class="math inline">\(D\boldsymbol x(\boldsymbol y)\)</span> is the Jacobian matrix
of the inverse transformation <span class="math inline">\(\boldsymbol x(\boldsymbol y)\)</span>.</p>
<p>Assuming <span class="math inline">\(\boldsymbol y(\boldsymbol x) = \boldsymbol a+ \boldsymbol B\boldsymbol x\)</span>, with <span class="math inline">\(\boldsymbol x(\boldsymbol y) = \boldsymbol B^{-1}(\boldsymbol y-\boldsymbol a)\)</span>,
<span class="math inline">\(D\boldsymbol y(\boldsymbol x) = \boldsymbol B\)</span> and <span class="math inline">\(D\boldsymbol x(\boldsymbol y) = \boldsymbol B^{-1}\)</span>, recovers the location-scale transformation.</p>
</div>
<div id="exponential-tilting-and-exponential-families" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> Exponential tilting and exponential families<a class="anchor" aria-label="anchor" href="#exponential-tilting-and-exponential-families"><i class="fas fa-link"></i></a>
</h2>
<p>Another way to change the distribution of a random variable is by <strong>exponential tilting</strong>.</p>
<p>Suppose there is a vector valued function <span class="math inline">\(\boldsymbol u(x)\)</span> where each component is a transformation of <span class="math inline">\(x\)</span>,
usually a simple function such the identity <span class="math inline">\(x\)</span>, the square <span class="math inline">\(x^2\)</span>,
the logarithm <span class="math inline">\(\log(x)\)</span> etc. These are called the <strong>canonical statistics</strong>.
Typically, the dimension of <span class="math inline">\(\boldsymbol u(x)\)</span> is small.</p>
<p>The exponential tilt of a <strong>base distribution</strong> <span class="math inline">\(B\)</span> with density or probability mass function <span class="math inline">\(b(x)\)</span>
towards the linear combination <span class="math inline">\(\boldsymbol \eta^T \boldsymbol u(x)\)</span> of the canonical statistics <span class="math inline">\(\boldsymbol u(x)\)</span>
yields the distribution family <span class="math inline">\(P_{\boldsymbol \eta}\)</span> with density or probability mass function
<span class="math display">\[
p(x|\boldsymbol \eta) =    \underbrace{e^{ \boldsymbol \eta^T \boldsymbol u(x)}}_{\text{exponential tilt}}\, b(x) \, /\, e^{ \psi(\boldsymbol \eta)}
\]</span>
where <span class="math inline">\(\boldsymbol \eta\)</span> are the canonical parameters. The normalising factor <span class="math inline">\(e^{ \psi(\boldsymbol \eta)}\)</span> ensures that <span class="math inline">\(p(x|\boldsymbol \eta)\)</span> integrates to one following the exponential tilt.</p>
<p>The corresponding log-density / log probability mass function is
<span class="math display">\[
\log p(x|\boldsymbol \eta) =  \boldsymbol \eta^T \boldsymbol u(x) + \log b(x) - \psi(\boldsymbol \eta)
\]</span>
The <strong>log-normaliser</strong> or <strong>log-partition function</strong> <span class="math inline">\(\psi(\boldsymbol \eta)\)</span> is obtained by computing
<span class="math display">\[
\psi(\boldsymbol \eta) = \log \int_x \, e^{ \boldsymbol \eta^T \boldsymbol u(x)}\, b(x) \, dx
\]</span>
The set of
values of <span class="math inline">\(\boldsymbol \eta\)</span> for which the integral is finite and hence
<span class="math inline">\(\psi(\boldsymbol \eta) &lt; \infty\)</span> defines the parameter space.</p>
<p>The distribution family <span class="math inline">\(P_{\boldsymbol \eta}\)</span> obtained by exponential
tiling is called an <strong>exponential family</strong>.</p>
<p>Many commonly used distribution families are exponential families
(most importantly the normal distribution).
Exponential families are extremely important in probability and statistics.
They provide highly effective models for statistical learning using entropy,
likelihood and Bayesian approaches, allow for substantial data reduction via
minimal sufficiency, and provide the basis of generalised linear models.
Furthermore, exponential families often enable
to generalise probabilistic results valid for the normal distribution
to more general settings.</p>
</div>
<div id="sums-of-iid-random-variables-and-convolution" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> Sums of iid random variables and convolution<a class="anchor" aria-label="anchor" href="#sums-of-iid-random-variables-and-convolution"><i class="fas fa-link"></i></a>
</h2>
<p>Suppose we have a sum of <span class="math inline">\(n\)</span> independent and identically distributed (iid) random variables.
<span class="math display">\[
y = x_1 + x_2 + \ldots + x_n
\]</span>
where each <span class="math inline">\(x_i \sim F_x\)</span> with density or probability mass function <span class="math inline">\(f_x(x)\)</span>.
The density or probability mass function for <span class="math inline">\(y\)</span> is obtained by repeated
application of <strong>convolution</strong> (symbolised by the <span class="math inline">\(\ast\)</span> operator):
<span class="math display">\[
f_y(y) = (f_{x_1} \ast f_{x_2} \ast \ldots f_{x_n})(y)
\]</span></p>
<p>The convolution of two functions is defined as (continous case)
<span class="math display">\[
(f_{x_1}\ast f_{x_2})(y)=\int_x f_{x_1}(x)\, f_{x_2}(y-x) dx
\]</span>
and (discrete case)
<span class="math display">\[
(f_{x_1}\ast f_{x_2})(y)=\sum_x f_{x_1}(x)\, f_{x_2}(y-x)
\]</span>
Convolution is commutative and associative so it can be applied in any order
to compute the convolution of multiple functions.
Furthermore, the convolution of probability densities / mass function
yields another probability density / mass function.</p>
<p>Many commonly used random variables can be viewed as the outcome of convolutions.
For example, the sum of Bernoulli variables yields a binomial random variable
and the sum of normal variables yields another normal random variable.
See also: <a href="https://en.wikipedia.org/wiki/List_of_convolutions_of_probability_distributions">list of convolutions of probability distributions</a>.</p>
<p>The <strong>central limit theorem</strong>, first postulated by <a href="https://en.wikipedia.org/wiki/Abraham_de_Moivre">Abraham de Moivre (1667–1754)</a>, asserts
that, under appropriate conditions, the distribution of the sum of independent and identically distributed random variables converges in the limit of large <span class="math inline">\(n\)</span> to a normal distribution, even if the individual random variables are not normal. In other words, it asserts that for large <span class="math inline">\(n\)</span> the convolution of <span class="math inline">\(n\)</span>
identical distributions typically converges to the normal distribution.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="probability.html"><span class="header-section-number">2</span> Probability</a></div>
<div class="next"><a href="univariate-distributions.html"><span class="header-section-number">4</span> Univariate distributions</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#transforming-and-combining-random-variables"><span class="header-section-number">3</span> Transforming and combining random variables</a></li>
<li><a class="nav-link" href="#affine-or-location-scale-transformation-of-random-variables"><span class="header-section-number">3.1</span> Affine or location-scale transformation of random variables</a></li>
<li><a class="nav-link" href="#general-invertible-transformation-of-random-variables"><span class="header-section-number">3.2</span> General invertible transformation of random variables</a></li>
<li><a class="nav-link" href="#exponential-tilting-and-exponential-families"><span class="header-section-number">3.3</span> Exponential tilting and exponential families</a></li>
<li><a class="nav-link" href="#sums-of-iid-random-variables-and-convolution"><span class="header-section-number">3.4</span> Sums of iid random variables and convolution</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Probability and Distribution Refresher</strong>" was written by Korbinian Strimmer. It was last built on 2 March 2024.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
