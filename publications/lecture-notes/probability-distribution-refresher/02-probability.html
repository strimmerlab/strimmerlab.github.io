<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Probability – Probability and Distribution Refresher</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03-transformations.html" rel="next">
<link href="./01-combinatorics.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-c8ad9e5dbd60b7b70b38521ab19b7da4.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-c63e616a2164fee75212f002d4510366.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-probability.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Probability and Distribution Refresher</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Combinatorics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-probability.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-transformations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Transformations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-univariate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Univariate distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-multivariate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Multivariate distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bibliography.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#random-variables" id="toc-random-variables" class="nav-link active" data-scroll-target="#random-variables"><span class="header-section-number">2.1</span> Random variables</a></li>
  <li><a href="#conditional-probability" id="toc-conditional-probability" class="nav-link" data-scroll-target="#conditional-probability"><span class="header-section-number">2.2</span> Conditional probability</a></li>
  <li><a href="#probability-mass-and-density-function" id="toc-probability-mass-and-density-function" class="nav-link" data-scroll-target="#probability-mass-and-density-function"><span class="header-section-number">2.3</span> Probability mass and density function</a></li>
  <li><a href="#cumulative-distribution-function" id="toc-cumulative-distribution-function" class="nav-link" data-scroll-target="#cumulative-distribution-function"><span class="header-section-number">2.4</span> Cumulative distribution function</a></li>
  <li><a href="#quantile-function-and-quantiles" id="toc-quantile-function-and-quantiles" class="nav-link" data-scroll-target="#quantile-function-and-quantiles"><span class="header-section-number">2.5</span> Quantile function and quantiles</a></li>
  <li><a href="#expectation-or-mean" id="toc-expectation-or-mean" class="nav-link" data-scroll-target="#expectation-or-mean"><span class="header-section-number">2.6</span> Expectation or mean</a></li>
  <li><a href="#variance" id="toc-variance" class="nav-link" data-scroll-target="#variance"><span class="header-section-number">2.7</span> Variance</a></li>
  <li><a href="#moments-of-a-distribution" id="toc-moments-of-a-distribution" class="nav-link" data-scroll-target="#moments-of-a-distribution"><span class="header-section-number">2.8</span> Moments of a distribution</a></li>
  <li><a href="#expectation-of-a-transformed-random-variable" id="toc-expectation-of-a-transformed-random-variable" class="nav-link" data-scroll-target="#expectation-of-a-transformed-random-variable"><span class="header-section-number">2.9</span> Expectation of a transformed random variable</a></li>
  <li><a href="#probability-as-expectation" id="toc-probability-as-expectation" class="nav-link" data-scroll-target="#probability-as-expectation"><span class="header-section-number">2.10</span> Probability as expectation</a></li>
  <li><a href="#jensens-inequality-for-the-expectation" id="toc-jensens-inequality-for-the-expectation" class="nav-link" data-scroll-target="#jensens-inequality-for-the-expectation"><span class="header-section-number">2.11</span> Jensen’s inequality for the expectation</a></li>
  <li><a href="#random-vectors-and-their-mean-and-variance" id="toc-random-vectors-and-their-mean-and-variance" class="nav-link" data-scroll-target="#random-vectors-and-their-mean-and-variance"><span class="header-section-number">2.12</span> Random vectors and their mean and variance</a></li>
  <li><a href="#correlation-matrix" id="toc-correlation-matrix" class="nav-link" data-scroll-target="#correlation-matrix"><span class="header-section-number">2.13</span> Correlation matrix</a></li>
  <li><a href="#parameters-and-families-of-distributions" id="toc-parameters-and-families-of-distributions" class="nav-link" data-scroll-target="#parameters-and-families-of-distributions"><span class="header-section-number">2.14</span> Parameters and families of distributions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="random-variables" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="random-variables"><span class="header-section-number">2.1</span> Random variables</h2>
<p>A <strong>random variable</strong> describes a random experiment. The set of all possible outcomes is the <strong>sample space</strong> of the random variable and is denoted by <span class="math inline">\(\Omega\)</span>. If <span class="math inline">\(\Omega\)</span> is countable then the random variable is <strong>discrete</strong>, otherwise it is <strong>continuous</strong>. For a discrete random variable the sample space <span class="math inline">\(\Omega = \{\omega_1, \omega_2, \ldots\}\)</span> is composed of a finite or infinite number of <strong>elementary outcomes</strong>&nbsp;<span class="math inline">\(\omega_i\)</span>.</p>
<p>An event <span class="math inline">\(A \subseteq \Omega\)</span> is a subset of <span class="math inline">\(\Omega\)</span>. This includes as special cases the complete set <span class="math inline">\(\Omega\)</span> (“certain event”) and the empty set <span class="math inline">\(\emptyset\)</span> (“impossible event”). The set of all possible events is denoted by&nbsp;<span class="math inline">\(\mathcal{F}\)</span>. The complementary event <span class="math inline">\(A^C = \Omega \setminus A\)</span> is the complement of the set <span class="math inline">\(A\)</span> in the sample space&nbsp;<span class="math inline">\(\Omega\)</span>. Two events <span class="math inline">\(A_1\)</span> and <span class="math inline">\(A_2\)</span> are mutually exclusive if the sets are disjoint with <span class="math inline">\(A_1 \cap A_2 = \emptyset\)</span>.</p>
<p>For a discrete random variable, the elementary outcomes <span class="math inline">\(\omega_i\)</span> are referred to as <strong>elementary events</strong>, and they are all mutually exclusive. An event <span class="math inline">\(A\)</span> consists of a number of elementary events <span class="math inline">\(\omega_i \in A\)</span> and the complementary event is given by <span class="math inline">\(A^C = \{\omega_i \in \Omega:  \omega_i \notin A\}\)</span>.</p>
<p>The <strong>probability of an event</strong> <span class="math inline">\(A\)</span> is denoted by <span class="math inline">\(\text{Pr}(A)\)</span>. Broadly, <span class="math inline">\(\text{Pr}(A)\)</span> provides a measure of the size of the set <span class="math inline">\(A\)</span> relative to the set&nbsp;<span class="math inline">\(\Omega\)</span>. The probability measure <span class="math inline">\(\text{Pr}(A)\)</span> satisfies the three <a href="https://en.wikipedia.org/wiki/Probability_axioms">axioms of probability</a>:</p>
<ol type="1">
<li><span class="math inline">\(\text{Pr}(A) \geq 0\)</span>, probabilities are non-negative,</li>
<li><span class="math inline">\(\text{Pr}(\Omega) = 1\)</span>, the certain event has probability 1, and</li>
<li><span class="math inline">\(\text{Pr}(A_1 \cup A_2 \cup \ldots) = \sum_i \text{Pr}(A_i)\)</span>, the probability of countable mutually exclusive events <span class="math inline">\(A_i\)</span> is additive.</li>
</ol>
<p>This implies</p>
<ul>
<li><span class="math inline">\(\text{Pr}(A) \leq 1\)</span>, probability values lie within the range <span class="math inline">\([0,1]\)</span>,</li>
<li><span class="math inline">\(\text{Pr}(A^C) = 1 - \text{Pr}(A)\)</span>, the probability of the complement, and</li>
<li><span class="math inline">\(\text{Pr}(\emptyset) = 0\)</span>, the impossible event has probability&nbsp;0.</li>
</ul>
<p>From the above it is evident that probability is closely linked to set theory, in particular to measure theory which serves as the theoretical foundations of probability and generalisations. For instance, if <span class="math inline">\(\text{Pr}(\emptyset) = 0\)</span> is assumed instead of <span class="math inline">\(\text{Pr}(\Omega) = 1\)</span>, this leads to the axioms for a <strong>positive measure</strong> (of which probability is a special case).</p>
</section>
<section id="conditional-probability" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="conditional-probability"><span class="header-section-number">2.2</span> Conditional probability</h2>
<p>Consider two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, which may not be be mutually exclusive. The probability of the event “<span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>” is given by the probability of the set intersection <span class="math inline">\(\text{Pr}(A \cap B)\)</span>. The probability of the event “<span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span>” is given by the probability of the set union <span class="math display">\[
\text{Pr}(A \cup B) = \text{Pr}(A) + \text{Pr}(B) - \text{Pr}(A \cap B)\,.
\]</span> This identity follows from the axioms.</p>
<p>The <strong>conditional probability</strong> of event <span class="math inline">\(A\)</span> assuming event <span class="math inline">\(B\)</span> has occurred is given by <span class="math display">\[
\text{Pr}(A | B) = {\text{Pr}( A \cap B) \over \text{Pr}(B)}
\]</span> Essentially, now <span class="math inline">\(B\)</span> acts as the new sample space relative to which <span class="math inline">\(A\)</span> is measured, restricting it from <span class="math inline">\(\Omega\)</span>. Note that <span class="math inline">\(\text{Pr}(A | B)\)</span> is generally not the same as <span class="math inline">\(\text{Pr}(B | A)\)</span>, see Bayes’ theorem below.</p>
<p>Importantly, it can be seen that any probability may be viewed as conditional, namely relative to <span class="math inline">\(\Omega\)</span> as <span class="math inline">\(\text{Pr}(A) = \text{Pr}(A| \Omega)\)</span>.</p>
<p>From the definition of conditional probability we derive the <strong>product rule</strong> <span class="math display">\[
\begin{split}
\text{Pr}( A \cap B) &amp;= \text{Pr}(A | B)\, \text{Pr}(B) \\
&amp;= \text{Pr}(B | A)\, \text{Pr}(A)
\end{split}
\]</span> which in turn yields <strong>Bayes’ theorem</strong> <span class="math display">\[
\text{Pr}(A | B ) = \text{Pr}(B | A) { \text{Pr}(A) \over \text{Pr}(B)}
\]</span> This theorem is useful for changing the order of conditioning and it plays a key role in Bayesian statistics.</p>
<p>If <span class="math inline">\(\text{Pr}( A \cap B) =  \text{Pr}(A) \, \text{Pr}(B)\)</span> then the two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent</strong> with <span class="math inline">\(\text{Pr}(A | B ) = \text{Pr}(A)\)</span> and <span class="math inline">\(\text{Pr}(B | A ) = \text{Pr}(B)\)</span>.</p>
</section>
<section id="probability-mass-and-density-function" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="probability-mass-and-density-function"><span class="header-section-number">2.3</span> Probability mass and density function</h2>
<p>The <strong>distribution</strong> (or <strong>law</strong>) of a random variable <span class="math inline">\(x\)</span> with sample space <span class="math inline">\(\Omega\)</span> gives the probability for each value or a range of values of <span class="math inline">\(x\)</span> according to the underlying probability measure. This is done in practise by employing probability mass functions (for discrete random variables) or probability density functions (for continuous random variables).</p>
<p>Since <span class="math inline">\(x\)</span> is a scalar random variable we use lower case.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> This notation is common in statistical machine learning and multivariate statistics, see for example <span class="citation" data-cites="MKB1979">Mardia, Kent, and Bibby (<a href="bibliography.html#ref-MKB1979" role="doc-biblioref">1979</a>)</span>.</p>
<p>For a discrete random variable we define the event <span class="math inline">\(A = \{x: x=a\} = \{a\}\)</span> (corresponding to a single elementary event) and get the probability <span class="math display">\[
\text{Pr}(A) = \text{Pr}(x=a) = f(a)
\]</span> directly from the <strong>probability mass function</strong> (<strong>pmf</strong>). The pmf has the property that <span class="math inline">\(\sum_{x \in \Omega} f(x) = 1\)</span> and that <span class="math inline">\(f(x) \in [0,1]\)</span>.</p>
<p>For continuous random variables employ a <strong>probability density function</strong> (<strong>pdf</strong>) instead. We define the event <span class="math inline">\(A = \{x: a &lt; x \leq a + da\}\)</span> (corresponding to an infinitesimal interval) and then assign the probability <span class="math display">\[
\text{Pr}(A) = \text{Pr}( a &lt; x \leq a + da) = f(a) da \,.
\]</span> Similarly, the probability of the event <span class="math inline">\(A = \{x:a_1 &lt; x \leq a_2  \}\)</span> is given by <span class="math display">\[
\text{Pr}(A) = \text{Pr}( a_1 &lt; x \leq a_2) = \int_{a_1}^{a_2} f(a) da \,.
\]</span> The pdf has the property that <span class="math inline">\(\int_{x \in \Omega} f(x) dx = 1\)</span> but in contrast to a pmf the density <span class="math inline">\(f(x)\geq 0\)</span> may take on values larger than 1.</p>
<p>It is sometimes convenient to refer to a pdf or a pmf collectively <strong>as probability density mass function</strong> (<strong>pdmf</strong>) without specifying whether <span class="math inline">\(x\)</span> is continuous or discrete.</p>
<p>The set of all <span class="math inline">\(x\)</span> for which <span class="math inline">\(f(x)\)</span> is positive is called the <strong>support</strong> of the pdmf.</p>
<p>Using the pdmf, the probability of general event <span class="math inline">\(A  \subseteq \Omega\)</span> is given by <span class="math display">\[
\text{Pr}(A) =
\begin{cases}
\sum_{x \in A} f(x) &amp; \text{discrete case} \\
\int_{x \in A} f(x) dx &amp; \text{continuous case} \\
\end{cases}
\]</span></p>
<div id="fig-pdfcdf" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="t">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pdfcdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/pdfcdf.jpg" class="img-fluid figure-img" style="width:100.0%" data-fig-pos="t">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pdfcdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: Illustration of i) pdmf, ii) distribution function and iii) quantile function for a continuous (first column) and a discrete random variable (second column).
</figcaption>
</figure>
</div>
<p><a href="#fig-pdfcdf" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> (first row) illustrates the pdmf for a continuous and discrete random variable.</p>
<p>In the above we denoted the pdmf by the lower case letter <span class="math inline">\(f\)</span> though we also often use <span class="math inline">\(p\)</span> or <span class="math inline">\(q\)</span>.</p>
</section>
<section id="cumulative-distribution-function" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="cumulative-distribution-function"><span class="header-section-number">2.4</span> Cumulative distribution function</h2>
<p>As alternative to the pdmf we can describe the random variable using a <strong>cumulative distribution function</strong> (<strong>cdf</strong>). This requires an ordering so that we can define the event <span class="math inline">\(A = \{x: x \leq a \}\)</span> and compute its probability as <span class="math display">\[
F(a) = \text{Pr}(A) = \text{Pr}( x \leq a ) =
\begin{cases}
\sum_{x \in A} f(x) &amp; \text{discrete case} \\
\int_{x \in A} f(x) dx &amp; \text{continuous case} \\
\end{cases}
\]</span> Th cdf is denoted by the same letter as the pdmf but in upper case (usually <span class="math inline">\(F\)</span>, <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span>). By construction the cumulative distribution function is monotonically non-decreasing and its value ranges from 0 to 1. For a discrete random variable <span class="math inline">\(F(a)\)</span> is a step function with jumps of size <span class="math inline">\(f(\omega_i)\)</span> at the elementary outcomes <span class="math inline">\(\omega_i\)</span>.</p>
<p>With the help of the cdf we can compute the probability of the event <span class="math inline">\(A = \{x:a_1 &lt; x \leq a_2  \}\)</span> simply as <span class="math display">\[
\text{Pr}( A ) = F(a_2)-F(a_1) \,.
\]</span> This works both for discrete and continuous random variables.</p>
<p><a href="#fig-pdfcdf" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> (second row) illustrates the distribution function for a continuous and discrete random variable.</p>
<p>It is common to use the same upper case letter as the cdf to name the distribution. Thus, if a random variable <span class="math inline">\(x\)</span> has distribution <span class="math inline">\(F\)</span> we write <span class="math inline">\(x \sim F\)</span>, and this implies it has a pdmf <span class="math inline">\(f(x)\)</span> and cdf <span class="math inline">\(F(x)\)</span>.</p>
</section>
<section id="quantile-function-and-quantiles" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="quantile-function-and-quantiles"><span class="header-section-number">2.5</span> Quantile function and quantiles</h2>
<p>The <strong>quantile function</strong> is defined as <span class="math inline">\(q_F(b) = \min\{ x: F(x) \geq b \}\)</span>. For a continuous random variable the quantile function simplifies to <span class="math inline">\(q_F(b) = F^{-1}(b)\)</span>, i.e.&nbsp;it is the ordinary inverse <span class="math inline">\(F^{-1}(b)\)</span> of the distribution function.</p>
<p><a href="#fig-pdfcdf" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> (third row) illustrates the quantile function for a continuous and discrete random variable.</p>
<p>The quantile <span class="math inline">\(x\)</span> of order <span class="math inline">\(b\)</span> of the distribution <span class="math inline">\(F\)</span> is often denoted by <span class="math inline">\(x_b= q_F(b)\)</span>.</p>
<p>The 25% quantile <span class="math inline">\(x_{1/4} = x_{25\%} =  q_F(1/4)\)</span> is called the <strong>first quartile</strong> or <strong>lower quartile</strong>.</p>
<p>The 50% quantile <span class="math inline">\(x_{1/2} = x_{50\%} = q_F(1/2)\)</span> is called the <strong>second quartile</strong> or <strong>median</strong>.</p>
<p>The 75% quantile <span class="math inline">\(x_{3/4} = x_{75\%} = q_F(3/4)\)</span> is called the <strong>third quartile</strong> or <strong>upper quartile</strong>.</p>
<p>The interquartile range is the difference between the upper and lower quartiles and equals <span class="math inline">\(\text{IQR}(F) =
q_F(3/4) - q_F(1/4)\)</span>.</p>
<p>The quantile function is also useful for generating general random variates from uniform random variates. If <span class="math inline">\(y\sim \text{Unif}(0,1)\)</span> then <span class="math inline">\(x=q_F(y) \sim F\)</span>.</p>
</section>
<section id="expectation-or-mean" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="expectation-or-mean"><span class="header-section-number">2.6</span> Expectation or mean</h2>
<p>The expected value <span class="math inline">\(\text{E}(x)\)</span> of a random variable <span class="math inline">\(x\)</span> is defined as the weighted average over all possible outcomes, with the weight given by the pdmf&nbsp;<span class="math inline">\(f(x)\)</span>: <span class="math display">\[
\text{E}(x) =
\begin{cases}
\sum_{x \in \Omega} f(x) \, x &amp; \text{discrete case} \\
\int_{x \in \Omega} f(x) \, x \, dx  &amp; \text{continuous case} \\
\end{cases}
\]</span> We may can also write <span class="math inline">\(\text{E}_{F}(x)\)</span> as a reminder that the expectation is taken with regard to the distribution <span class="math inline">\(F\)</span>. Usually, the subscript <span class="math inline">\(F\)</span> is left out if there are no ambiguities. A further variant is to write the expectation as <span class="math inline">\(\text{E}(F)\)</span> to indicate that we are computing the mean of the distribution&nbsp;<span class="math inline">\(F\)</span>.</p>
<p>Because the sum or integral may diverge, not all distributions have finite means so the mean does not always exist (in contrast to the median, or quantiles in general). For example, the location-scale <span class="math inline">\(t\)</span>-distribution <span class="math inline">\(\text{$t_{\nu}$}(\mu, \tau^2)\)</span> does not have a mean for a degree of freedom in the range <span class="math inline">\(0 &lt; \nu \leq 1\)</span> (see <a href="04-univariate.html#sec-lstdist" class="quarto-xref"><span>Section 4.6</span></a>).</p>
</section>
<section id="variance" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="variance"><span class="header-section-number">2.7</span> Variance</h2>
<p>The variance of a random variable <span class="math inline">\(x\)</span> is the expected value of the squared deviation around the mean: <span class="math display">\[
\text{Var}(x) = \text{E}\left( (x - \text{E}(x))^2 \right)
\]</span> By construction, <span class="math inline">\(\text{Var}(x) \geq 0\)</span>. The variance can also be obtained by <span class="math display">\[
\text{Var}(x) = \text{E}(x^2)-\text{E}(x)^2
\]</span><br>
Occasionally we write <span class="math inline">\(\text{Var}_F(x)\)</span> to express that the expectation is taken with regard to the distribution <span class="math inline">\(F\)</span>. The alternative notation <span class="math inline">\(\text{Var}(F)\)</span> highlights that we are computing the variance of the distribution&nbsp;<span class="math inline">\(F\)</span>.</p>
<p>Like the mean, the variance may diverge and hence not necessarily exists for all distribution. For example, the location-scale <span class="math inline">\(t\)</span>-distribution <span class="math inline">\(\text{$t_{\nu}$}(\mu, \tau^2)\)</span> does not have a variance for the degree of freedom in the range <span class="math inline">\(0 &lt; \nu \leq 2\)</span> (see <a href="04-univariate.html#sec-lstdist" class="quarto-xref"><span>Section 4.6</span></a>).</p>
</section>
<section id="moments-of-a-distribution" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="moments-of-a-distribution"><span class="header-section-number">2.8</span> Moments of a distribution</h2>
<p>The <span class="math inline">\(n\)</span>-th moment of a distribution <span class="math inline">\(F\)</span> for a random variable <span class="math inline">\(x\)</span> is defined as follows: <span class="math display">\[
\mu_n(F) = \text{E}(x^n)
\]</span></p>
<p>Special important cases are the</p>
<ul>
<li>Zeroth moment: <span class="math inline">\(\mu_0(F) = \text{E}(x^0) = 1\)</span> (since the pdmf integrates to one)</li>
<li>First moment: <span class="math inline">\(\mu_1(F) = \text{E}(x^1) = \text{E}(x) = \mu\)</span> (=the mean)</li>
<li>Second moment: <span class="math inline">\(\mu_2(F) = \text{E}(x^2)\)</span></li>
</ul>
<p>The <span class="math inline">\(n\)</span>-th central moment centred around the mean <span class="math inline">\(\text{E}(x) = \mu\)</span> is given by <span class="math display">\[
m_n(F) = \text{E}((x-\mu)^n)
\]</span></p>
<p>The first few central moments are the</p>
<ul>
<li>Zeroth central moment: <span class="math inline">\(m_0(F) = \text{E}((x-\mu)^0) = 1\)</span></li>
<li>First central moment: <span class="math inline">\(m_1(F) = \text{E}((x-\mu)^1) = 0\)</span></li>
<li>Second central moment: <span class="math inline">\(m_2(F) = \text{E}\left( (x - \mu)^2 \right)\)</span> (=the variance)</li>
</ul>
<p>The moments of a distribution are not necessarily all finite, i.e.&nbsp;some moments may not exist. For example, the location-scale <span class="math inline">\(t\)</span>-distribution <span class="math inline">\(\text{$t_{\nu}$}(\mu, \tau^2)\)</span> only has finite moments of degree smaller than the degree of freedom <span class="math inline">\(\nu\)</span> (see <a href="04-univariate.html#sec-lstdist" class="quarto-xref"><span>Section 4.6</span></a>).</p>
</section>
<section id="expectation-of-a-transformed-random-variable" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="expectation-of-a-transformed-random-variable"><span class="header-section-number">2.9</span> Expectation of a transformed random variable</h2>
<p>Often, one needs to find the mean of a transformed random variable. If <span class="math inline">\(x\sim F_x\)</span> and <span class="math inline">\(y= h(x)\)</span> with <span class="math inline">\(y \sim F_y\)</span> then one can directly apply the above definition to obtain <span class="math inline">\(\text{E}(y) = \text{E}(F_y)\)</span>. However, this requires knowledge of the transformed pdmf <span class="math inline">\(f_y(y)\)</span> (see <a href="03-transformations.html" class="quarto-xref"><span>Chapter 3</span></a> for more details about variable transformations).</p>
<p>As an alternative, the <a href="https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician">“law of the unconscious statistician”</a>(LOTUS) provides a convenient shortcut to compute the mean of the transformed random variable <span class="math inline">\(y=h(x)\)</span> using only the pdmf of the original variable&nbsp;<span class="math inline">\(x\)</span>: <span class="math display">\[
\text{E}(h(x)) =
\begin{cases}
\sum_{x \in \Omega} f(x) \, h(x) &amp; \text{discrete case} \\
\int_{x \in \Omega}  f(x) \, h(x) \, dx &amp; \text{continuous case} \\
\end{cases}
\]</span> Note this is not an approximation but equivalent to obtaining the mean using the transformed pdmf.</p>
</section>
<section id="probability-as-expectation" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="probability-as-expectation"><span class="header-section-number">2.10</span> Probability as expectation</h2>
<p>Probability itself can also be understood as an expectation.</p>
<p>For an event <span class="math inline">\(A  \subseteq \Omega\)</span> we define a corresponding indicator function <span class="math inline">\([x \in A]\)</span>. From LOTUS it then follows immediately that <span class="math display">\[
\begin{split}
\text{E}\left( \left[x \in A\right] \right) &amp;=
\begin{cases}
\sum_{x \in A} f(x)  &amp; \text{discrete case} \\
\int_{x \in A}  f(x)  \, dx &amp; \text{continuous case} \\
\end{cases}\\
&amp; =\text{Pr}(A)
\end{split}
\]</span></p>
<p>This relation is called the “fundamental bridge” between probability and expectation. Interestingly, one can develop the whole theory of probability from this perspective <span class="citation" data-cites="Whittle2000">(e.g., <a href="bibliography.html#ref-Whittle2000" role="doc-biblioref">Whittle 2000</a>)</span>.</p>
</section>
<section id="jensens-inequality-for-the-expectation" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="jensens-inequality-for-the-expectation"><span class="header-section-number">2.11</span> Jensen’s inequality for the expectation</h2>
<p>If <span class="math inline">\(h(\boldsymbol x)\)</span> is a <em>convex</em> function then the following inequality holds:</p>
<p><span class="math display">\[
\text{E}(h(\boldsymbol x)) \geq h(\text{E}(\boldsymbol x))
\]</span></p>
<p>Recall: a con<strong>ve</strong>x function (such as <span class="math inline">\(x^2\)</span>) has the shape of a “<strong>va</strong>lley”.</p>
<p>An example of Jensen’s inequality is <span class="math inline">\(\text{E}(x^2)\geq \text{E}(x)^2\)</span>.</p>
</section>
<section id="random-vectors-and-their-mean-and-variance" class="level2" data-number="2.12">
<h2 data-number="2.12" class="anchored" data-anchor-id="random-vectors-and-their-mean-and-variance"><span class="header-section-number">2.12</span> Random vectors and their mean and variance</h2>
<p>In addition to scalar random variables we often make use of random vectors and also random matrices.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>For a random vector <span class="math inline">\(\boldsymbol x= (x_1, x_2,...,x_d)^T \sim F\)</span> the mean <span class="math inline">\(\text{E}(\boldsymbol x) = \boldsymbol \mu\)</span> is given by the means of its elements, i.e.&nbsp;<span class="math inline">\(\boldsymbol \mu= (\mu_1, \ldots, \mu_d)^T\)</span> with <span class="math inline">\(\mu_i = \text{E}(x_i)\)</span>. Thus, the mean of a random vector of dimension <span class="math inline">\(d\)</span> is a vector of the same length.</p>
<p>The variance of a random vector of length <span class="math inline">\(d\)</span>, however, is not a vector but a matrix of size <span class="math inline">\(d\times d\)</span>. This matrix is called the <strong>covariance matrix</strong>: <span class="math display">\[
\begin{split}
\text{Var}(\boldsymbol x) &amp;= \underbrace{\boldsymbol \Sigma}_{d\times d} = (\sigma_{ij}) \\
          &amp;= \begin{pmatrix}
    \sigma_{11} &amp; \dots &amp; \sigma_{1d}\\
     \vdots &amp; \ddots &amp; \vdots \\
    \sigma_{d1} &amp; \dots &amp; \sigma_{dd}
\end{pmatrix} \\
  &amp;=\text{E}\left(\underbrace{(\boldsymbol x-\boldsymbol \mu)}_{d\times 1} \underbrace{(\boldsymbol x-\boldsymbol \mu)^T}_{1\times d}\right) \\
  &amp; = \text{E}(\boldsymbol x\boldsymbol x^T)-\boldsymbol \mu\boldsymbol \mu^T \\
\end{split}
\]</span> The entries of the covariance matrix <span class="math inline">\(\text{Cov}(x_i, x_j)=\sigma_{ij}\)</span> describe the covariance between the random variables <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span>. The covariance matrix is symmetric, hence <span class="math inline">\(\sigma_{ij}=\sigma_{ji}\)</span>. The diagonal entries <span class="math inline">\(\text{Cov}(x_i, x_i)=\sigma_{ii}\)</span> correspond to the variances <span class="math inline">\(\text{Var}(x_i) = \sigma_i^2\)</span> of the elements of <span class="math inline">\(\boldsymbol x\)</span>. The covariance matrix is by construction <strong>positive semi-definite</strong>, i.e.&nbsp;the eigenvalues of <span class="math inline">\(\boldsymbol \Sigma\)</span> are all positive or equal to zero.</p>
<p>However, wherever possible one will aim to use models with non-singular covariance matrices, with all eigenvalues positive, so that the covariance matrix is invertible.</p>
</section>
<section id="correlation-matrix" class="level2" data-number="2.13">
<h2 data-number="2.13" class="anchored" data-anchor-id="correlation-matrix"><span class="header-section-number">2.13</span> Correlation matrix</h2>
<p>The <strong>correlation matrix</strong> <span class="math inline">\(\boldsymbol P\)</span> (“upper case rho”, not “upper case p”) is the variance standardised version of the covariance matrix <span class="math inline">\(\boldsymbol \Sigma\)</span>.</p>
<p>Specifically, denote by <span class="math inline">\(\boldsymbol V\)</span> the diagonal matrix containing the variances <span class="math display">\[
\boldsymbol V= \begin{pmatrix}
    \sigma_{11} &amp; \dots &amp; 0\\
     \vdots &amp; \ddots &amp; \vdots \\
    0 &amp; \dots &amp; \sigma_{dd}
\end{pmatrix}
\]</span> then the correlation matrix <span class="math inline">\(\boldsymbol P\)</span> is given by <span class="math display">\[
\boldsymbol P= (\rho_{ij}) = \begin{pmatrix}
    1 &amp; \dots &amp; \rho_{1d}\\
     \vdots &amp; \ddots &amp; \vdots \\
    \rho_{d1} &amp; \dots &amp; 1
\end{pmatrix}   = \boldsymbol V^{-1/2} \, \boldsymbol \Sigma\, \boldsymbol V^{-1/2}
\]</span> Like the covariance matrix the correlation matrix is symmetric. The elements of the diagonal of <span class="math inline">\(\boldsymbol P\)</span> are all set to 1.</p>
<p>Equivalently, in component notation the correlation between <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> is given by <span class="math display">\[
\rho_{ij} = \text{Cor}(x_i,x_j) = \frac{\sigma_{ij}}{\sqrt{\sigma_{ii}\sigma_{jj}}}
\]</span></p>
<p>Using the above, a covariance matrix can be factorised into the product of standard deviations <span class="math inline">\(\boldsymbol V^{1/2}\)</span> and the correlation matrix as follows: <span class="math display">\[
\boldsymbol \Sigma= \boldsymbol V^{1/2}\, \boldsymbol P\,\boldsymbol V^{1/2}
\]</span></p>
</section>
<section id="parameters-and-families-of-distributions" class="level2" data-number="2.14">
<h2 data-number="2.14" class="anchored" data-anchor-id="parameters-and-families-of-distributions"><span class="header-section-number">2.14</span> Parameters and families of distributions</h2>
<p>A <strong>distribution family</strong> <span class="math inline">\(F(\theta)\)</span> is a collection of distributions obtained by varying a parameter <span class="math inline">\(\theta\)</span>. Each specific value of the parameter <span class="math inline">\(\theta\)</span> indexes one distribution in that family.</p>
<p>Common distribution families are usually denoted by familiar abbreviation such as <span class="math inline">\(N(\mu, \sigma^2)\)</span> for the normal family. We also call these simply “distributions” with parameters and omit the word “family”.</p>
<p>If a random variable <span class="math inline">\(x\)</span> has distribution <span class="math inline">\(F(\theta)\)</span> we write <span class="math inline">\(x \sim F(\theta)\)</span> or simply <span class="math inline">\(x \sim N(\mu, \sigma^2)\)</span> in case of a named normal distribution.</p>
<p>The associated pdmf is written <span class="math inline">\(f(x; \theta)\)</span> or <span class="math inline">\(f(x | \theta)\)</span>. The conditional notation is more general because it implies the parameter <span class="math inline">\(\theta\)</span> may have its own distribution, yielding a joint density <span class="math inline">\(f(x, \theta) = f(x | \theta) f(\theta)\)</span>. Similarly, the corresponding cumulative distribution function is written <span class="math inline">\(F(x; \theta)\)</span> or <span class="math inline">\(F(x | \theta)\)</span>.</p>
<p>Note that parametrisations are generally not unique, as any one-to-one transformation of <span class="math inline">\(\theta\)</span> yields an equivalent index of the same distribution family. For most commonly used distribution families there exist several standard parametrisations. We usually prefer those whose parameters that can be interpreted easily (e.g.&nbsp;in terms of moments) or that help to simplify calculations.</p>
<p>If for any pair of different parameter values <span class="math inline">\(\theta_1 \neq \theta_2\)</span> we get distinct distributions with <span class="math inline">\(F(\theta_1) \neq F(\theta_2)\)</span> then the distribution family <span class="math inline">\(F(\theta)\)</span> is said to be <strong>identifiable</strong> by the parameter&nbsp;<span class="math inline">\(\theta\)</span>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-MKB1979" class="csl-entry" role="listitem">
Mardia, K. V., J. T. Kent, and J. M. Bibby. 1979. <em>Multivariate Analysis</em>. Academic Press.
</div>
<div id="ref-Whittle2000" class="csl-entry" role="listitem">
Whittle, P. 2000. <em>Probability via Expectation</em>. 3rd ed. Springer. <a href="https://doi.org/10.1007/978-1-4612-0509-8">https://doi.org/10.1007/978-1-4612-0509-8</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>For scalar random variables often upper case is used denote the variable and lower case for the associated realisations. However, that convention doesn’t work well for random vectors and matrices and is also ill-suited in Bayesian statistics where random variables describe the uncertainty of parameters. Therefore, we use the same symbol to denote a random variable and its realisations.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In our notational conventions, a <strong>vector</strong> <span class="math inline">\(\boldsymbol x\)</span> is written in <em>lower case bold font</em>, a <strong>matrix</strong> <span class="math inline">\(\boldsymbol M\)</span> in <em>upper case bold font</em>. Hence random vectors and matrices as well as their realisations are indicated in bold font, with vectors given in lower case and matrices in upper case. Hence, as for scalar variables, upper case versus lower case does not indicate randomness versus realisation.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/strimmerlab\.github\.io\/publications\/lecture-notes\/probability-distribution-refresher\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01-combinatorics.html" class="pagination-link" aria-label="Combinatorics">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Combinatorics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03-transformations.html" class="pagination-link" aria-label="Transformations">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Transformations</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>