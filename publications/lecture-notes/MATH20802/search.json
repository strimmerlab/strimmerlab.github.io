[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"lecture notes MATH20802, course Statistical Methods second year mathematics students Department Mathematics University Manchester taking place 2019–2023. course text written Korbinian Strimmer. version 6 June 2023.can view notes online web browser \ndownload MATH20802 lecture notes PDF A4 format printing (double page layout) 6x9 inch PDF use tablets (single page layout).updated version notes (Bayes Likelihood chapters) visit online MATH27720 Statistics 2 lecture notes.","code":""},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"notes licensed Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"about-the-author","chapter":"Preface","heading":"About the author","text":"Hello! name Korbinian Strimmer Professor Statistics. member Statistics group\nDepartment Mathematics University Manchester. can find information home page.notes version MATH20802 taught spring 2023 University Manchester.hope enjoy course find notes useful! questions, comments, corrections please email korbinian.strimmer@manchester.ac.uk.","code":""},{"path":"preface.html","id":"about-the-module","chapter":"Preface","heading":"About the module","text":"","code":""},{"path":"preface.html","id":"topics-covered","chapter":"Preface","heading":"Topics covered","text":"MATH20802 module designed run course 11 weeks.\nthree main parts:Likelihood estimation inference (W1–W4)Bayesian learning inference (W5–W8)Linear regression (W9–W11)module focuses conceptual understanding methods, theory. Specifically, learn foundations statistical learning using likelihood Bayesian approaches also underpinned entropy., presentation course non-technical.\naim offer insights diverse statistical approaches linked demonstrate statistics offers concise coherent theory information rather adhoc collection “recipes” data analysis (common wrong perception statistics).","code":""},{"path":"preface.html","id":"prerequisites","chapter":"Preface","heading":"Prerequisites","text":"module important refresh knowledge :Introduction statisticsProbabilityR data analysis programmingIn addition need elements matrix algebra compute gradient curvature function several variables.Check Appendix notes brief refresher essential material.","code":""},{"path":"preface.html","id":"additional-support-material","chapter":"Preface","heading":"Additional support material","text":"University Manchester student enrolled module\nfind Blackboard:weekly learning plan 11 week study period (plus one additional week revision),weekly worksheets examples solutions R code, andexam papers previous years.Furthermore, also MATH20802 online reading list hosted University Manchester library.","code":""},{"path":"preface.html","id":"the-future","chapter":"Preface","heading":"The future","text":"year 2 MATH20802 “Statistical Methods” module (10 credits) last run academic year 2022/23.2023/24 onwards likelihood Bayes parts module delivered part 2 new year 2 module MATH27720 “Probability Statistics 2” (20 credits). Linear regression taught new year 2 module MATH27711 “Linear regression models” (10 credits).","code":""},{"path":"preface.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"Many thanks Beatriz Costa Gomes help creating 2019 version lecture notes teaching module first time Kristijonas Raudys extensive feedback 2020 version.","code":""},{"path":"overview-of-statistical-learning.html","id":"overview-of-statistical-learning","chapter":"1 Overview of statistical learning","heading":"1 Overview of statistical learning","text":"","code":""},{"path":"overview-of-statistical-learning.html","id":"how-to-learn-from-data","chapter":"1 Overview of statistical learning","heading":"1.1 How to learn from data?","text":"fundamental question extract information data optimal way, make predictions based information.purpose, number competing theories information developed. Statistics oldest science information concerned offering principled ways learn data extract process information using probabilistic models.\nHowever, theories information (e.g. Vapnik-Chernov theory learning, computational learning) algorithmic analytic sometimes even based probability theory.Furthermore, disciplines, computer science machine learning closely linked also substantial overlap statistics. field “data science” today comprises statistics machine learning brings together mathematics, statistics computer science. Also growing field -called “artificial intelligence” makes substantial use statistical machine learning techniques.recent popular science book “Master Algorithm” Domingos (2015) provides accessible informal overview \nvarious schools science information. discusses main algorithms used machine learning statistics:Starting early 1763, Bayesian school learning started later turned closely linked likelihood inference established 1922 R.. Fisher (1890–1962) generalised 1951 entropy learning Kullback Leibler.Starting early 1763, Bayesian school learning started later turned closely linked likelihood inference established 1922 R.. Fisher (1890–1962) generalised 1951 entropy learning Kullback Leibler.also 1950s concept artificial neural network arises, essentially nonlinear input-output map works non-probabilistic way. field saw another leap 1980s progressed 2010 onwards development deep dearning. now one popular (effective) methods analysing imaging data. Even mobile phone likely dedicated computer chip special neural network hardware, example.also 1950s concept artificial neural network arises, essentially nonlinear input-output map works non-probabilistic way. field saw another leap 1980s progressed 2010 onwards development deep dearning. now one popular (effective) methods analysing imaging data. Even mobile phone likely dedicated computer chip special neural network hardware, example.advanced theories information developed 1960 term \ncomputational learning, notably Vapnik-Chernov theory, prominent example “support vector machine” (another non-probabilistic model).advanced theories information developed 1960 term \ncomputational learning, notably Vapnik-Chernov theory, prominent example “support vector machine” (another non-probabilistic model).advent large-scale genomic high-dimensional data surge new exciting developments field high-dimensional (large dimension) also big data (large dimension large sample size), statistics machine learning.advent large-scale genomic high-dimensional data surge new exciting developments field high-dimensional (large dimension) also big data (large dimension large sample size), statistics machine learning.connections various fields information still perfectly understood, clear overarching theory need based probabilistic learning.","code":""},{"path":"overview-of-statistical-learning.html","id":"probability-theory-versus-statistical-learning","chapter":"1 Overview of statistical learning","heading":"1.2 Probability theory versus statistical learning","text":"study statistics (information theory) need aware fundamental difference probability theory\nstatistics, relates distinction \n“randomness” “uncertainty”.Probability theory studies randomness, developing mathematical models randomness (probability distributions), studying corresponding mathematical properties (including asymptotics etc). Probability theory may fact viewed branch measure theory, thus belongs\ndomain pure mathematics.Probability theory provides probabilistic generative models data, simulation\ndata use learning data, .e. inference model observations.\nMethods theory best learn data domain applied mathematics, specifically statistics related areas machine learning data science.Note statistics, contrast probability, fact concerned randomness. Instead, focus measuring elucidating uncertainty events, predictions, outcomes, parameters uncertainty measures state knowledge. Note new data information becomes available, state knowledge thus uncertainty changes! Thus, uncertainty epistemological property.uncertainty often due ignorance true underlying processes (purpose ), underlying process actually random. success statistics based fact can mathematically model uncertainty without knowing specifics underlying processes, still procedures optimal inference despite uncertainty.short, statistics describing state knowledge world, \nmay uncertain incomplete, make decisions predictions face uncertainty, uncertaintly sometimes derives randomness often ignorance (sometimes ignorance even helps create simple yet effective model)!","code":""},{"path":"overview-of-statistical-learning.html","id":"cartoon-of-statistical-learning","chapter":"1 Overview of statistical learning","heading":"1.3 Cartoon of statistical learning","text":"observe data \\(D = \\{x_1, \\ldots, x_n\\}\\)\nassumed generated underlying true model \\(M_{\\text{true}}\\) \ntrue parameters \\(\\boldsymbol \\theta_{\\text{true}}\\)explain data, make predictions, make hypotheses\nform candidate models \\(M_{1}, M_{2}, \\ldots\\) corresponding parameters \\(\\boldsymbol \\theta_1, \\boldsymbol \\theta_2, \\ldots\\).\ntrue model unknown observed. However, can observe data \\(D\\) true model measuring properties objects interest (observations experiments). Sometimes can also perturb model see effect (interventional study).various candidate models \\(M_1, M_2, \\ldots\\) model world never perfect correct\ntrue model \\(M_{\\text{true}}\\) among candidate models idealised situation. However, even imperfect candidate model often provide useful mathematical approximation capture important characteristics true model thus help\ninterpret observed data.\\[\n\\begin{array}{cc}\n\\textbf{Hypothesis} \\\\\n\\text{world works} \\\\\n\\end{array}\n\\longrightarrow\n\\begin{array}{cc}\n\\textbf{Model world} \\\\\nM_1,  \\boldsymbol \\theta_1  \\\\\nM_2, \\boldsymbol \\theta_2  \\\\\n\\vdots\\\\\n\\end{array}\n\\]\n\\[\n\\longrightarrow\n\\begin{array}{cc}\n\\textbf{Real world,} \\\\\n\\textbf{unknown true model} \\\\\nM_{\\text{true}}, \\boldsymbol \\theta_{\\text{true}} \\\\\n\\end{array}\n\\longrightarrow \\textbf{Data } x_1, \\ldots, x_n\n\\]aim statistical learning identify model(s) explain current data also predict future data (.e. predict outcome experiments conducted yet).Thus good model provides good fit current data (.e. explains current observations well) also future data (.e. generalises well).large proportion statistical theory devoted finding “good” models\navoid overfitting (models complex don’t generalise well) \nunderfitting (models simplistic hence also don’t predict well).Typically aim find model whose model complexity matches \ncomplexity unknown true model also complexity data observed unknown true model.","code":""},{"path":"overview-of-statistical-learning.html","id":"likelihood","chapter":"1 Overview of statistical learning","heading":"1.4 Likelihood","text":"statistics machine learning models used probabilistic take\naccount randomness uncertainty.\ncore task statistical learning identify models explain existing data well also generalise well unseen data.need, among things, measure well candidate model approximates (typically unknown) true data generating model approach choose best model(s).\nOne approach provided method maximum likelihood enables us estimate parameters models find particular model best fit data.Given probability distribution \\(P_{\\boldsymbol \\theta}\\) density mass function \\(p(x|\\boldsymbol \\theta)\\) \\(\\boldsymbol \\theta\\) parameter vector, \\(D = \\{x_1,\\dots,x_n\\}\\) observed iid data (.e. independent identically distributed), likelihood function defined \n\\[\nL_n(\\boldsymbol \\theta| D ) =\\prod_{=1}^{n} p(x_i|\\boldsymbol \\theta)\n\\]\nTypically, instead likelihood one uses log-likelihood function:\n\\[\nl_n(\\boldsymbol \\theta| D) = \\log L_n(\\boldsymbol \\theta| D) =  \\sum_{=1}^n \\log p(x_i|\\boldsymbol \\theta)\n\\]\nReasons preferring log-likelihood (rather likelihood) include thatthe log-density fact “natural” relevant quantity (become clear upcoming chapters) thataddition numerically stable multiplication computer.discrete random variables \\(p(x |\\boldsymbol \\theta)\\) probability mass function likelihood often interpreted probability observe data given model specified parameters \\(\\boldsymbol \\theta\\). fact, indeed way likelihood historically introduced. However, view strictly correct.\nFirst, given samples iid thus ordering \\(x_i\\) important, additional factor accounting possible permutations needed likelihood obtain actual probability data. Moreover, continuous random variables interpretation breaks due use densities rather probability mass functions likelihood. Thus, view likelihood probability data fact simplistic.next chapter see justification using likelihood rather stems close link Kullback-Leibler information cross-entropy. also helps understand using likelihood estimation optimal limit large sample size.first part MATH28082 “Statistical Methods” module study likelihood estimation inference much detail. provide links related methods inference discuss information-theoretic foundations. also discuss optimality properties well limitations likelihood inference. Extensions likelihood analysis, particular Bayesian learning, discussed second part module. third part module apply statistical learning linear regression.","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"from-entropy-to-maximum-likelihood","chapter":"2 From entropy to maximum likelihood","heading":"2 From entropy to maximum likelihood","text":"","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"entropy","chapter":"2 From entropy to maximum likelihood","heading":"2.1 Entropy","text":"","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"overview","chapter":"2 From entropy to maximum likelihood","heading":"2.1.1 Overview","text":"chapter discuss various information criteria connection maximum likelihood.modern definition (relative) entropy, “disorder”, first discovered 1870s physicist L. Boltzmann (1844–1906)\ncontext thermodynamics. probabilistic interpretation statistical mechanics \nentropy developed J. W. Gibbs (1839–1903).1940–1950’s notion entropy turned central information theory, field pioneered mathematicians \nR. Hartley (1888–1970),\nS. Kullback (1907–1994),\n. Turing (1912–1954),\nR. Leibler (1914–2003),\n. J. Good (1916–2009),\nC. Shannon (1916–2001), \nE. T. Jaynes (1922–1998),\nlater explored \nS. Amari (1936–),\n. Ciszár (1938–),\nB. Efron (1938–),\n. P. Dawid (1946–) \nmany others.\\[\\begin{align*}\n\\left.\n\\begin{array}{cc}\n\\\\\n\\textbf{Entropy} \\\\\n\\\\\n\\end{array}\n\\right.\n\\left.\n\\begin{array}{cc}\n\\\\\n\\nearrow  \\\\\n\\searrow  \\\\\n\\\\\n\\end{array}\n\\right.\n\\begin{array}{ll}\n\\text{Shannon Entropy} \\\\\n\\\\\n\\text{Relative Entropy}  \\\\\n\\end{array}\n\\begin{array}{ll}\n\\text{(Shannon 1948)} \\\\\n\\\\\n\\text{(Kullback-Leibler 1951)}  \\\\\n\\end{array}\n\\end{align*}\\]\\[\\begin{align*}\n\\left.\n\\begin{array}{ll}\n\\text{Fisher information} \\\\\n\\\\\n\\text{Mutual Information} \\\\\n\\end{array}\n\\right.\n\\begin{array}{ll}\n\\rightarrow\\text{ Likelihood theory} \\\\\n\\\\\n\\rightarrow\\text{ Information theory} \\\\\n\\end{array}\n\\begin{array}{ll}\n\\text{(Fisher 1922)} \\\\\n\\\\\n\\text{(Shannon 1948, Lindley 1953)}  \\\\\n\\end{array}\n\\end{align*}\\]","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"surprise-surprisal-or-shannon-information","chapter":"2 From entropy to maximum likelihood","heading":"2.1.2 Surprise, surprisal or Shannon information","text":"surprise observe event probability \\(p\\) defined \\(-\\log(p)\\).\nalso called surprisal Shannon information.Thus, surprise observe certain event (\\(p=1\\)) zero,\nconversely surprise observe event certain happen\n(\\(p=0\\)) infinite.log-odds ratio can viewed difference surprise event surprise complementary event:\n\\[\n\\log\\left( \\frac{p}{1-p} \\right) =  -\\log(1-p) - ( -\\log(p))\n\\]module always use natural logarithm default, explicitly write \\(\\log_2\\) \\(\\log_{10}\\) logarithms respect base 2 10, respectively.Surprise entropy computed natural logarithm (\\(\\log\\)) given “nats” (=natural information units ). Using \\(\\log_2\\) leads “bits” using \\(\\log_{10}\\) “ban” “Hartley”.","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"shannon-entropy","chapter":"2 From entropy to maximum likelihood","heading":"2.1.3 Shannon entropy","text":"Assume categorical distribution \\(P\\) \\(K\\) classes/categories. corresponding\nclass probabilities \\(p_1, \\ldots, p_K\\) \\(\\text{Pr}(\\text{\"class k\"}) = p_k\\)\n\\(\\sum_{k=1}^K p_k= 1\\). probability mass function (PMF)\n\\(p(x = \\text{\"class k\"})= p_k\\).random variable \\(x\\) discrete categorical distribution\n\\(P\\) discrete distribution \\(P\\) generally also known discrete distribution.Shannon entropy (1948) 1 distribution \\(P\\) defined \nexpected surprise, .e. negative expected log-probability\n\\[\n\\begin{split}\nH(P) &=-\\text{E}_P\\left(\\log p(x)\\right) \\\\\n     &= - \\sum_{k=1}^{K}p_k \\log(p_k) \\\\\n\\end{split}\n\\]\n\\(p_k \\[0,1]\\) construction Shannon entropy must larger equal 0.Furthermore, bounded \\(\\log K\\). can seen maximising Shannon entropy\nfunction regard \\(p_k\\) constraint \\(\\sum_{k=1}^K p_k= 1\\), e.g., constrained optimisation using Langrange\nmultipliers. maximum achieved \\(P\\) discrete uniform - see Example 2.1.Hence categorical distribution \\(P\\) \\(K\\) categories \n\\[\\log K \\geq  H(P) \\geq 0\\]statistical physics, Shannon entropy known Gibbs entropy (1878).Example 2.1  Discrete uniform distribution \\(U_K\\): let \\(p_1=p_2= \\ldots = p_K = \\frac{1}{K}\\).\n\\[H(U_K) = - \\sum_{k=1}^{K}\\frac{1}{K} \\log\\left(\\frac{1}{K}\\right) = \\log K\\]Note largest value Shannon entropy can assume\n\\(K\\) classes.Example 2.2  Concentrated probability mass: let\n\\(p_1=1\\) \\(p_2=p_3=\\ldots=p_K=0\\).\nUsing \\(0\\times\\log(0)=0\\) obtain Shannon entropy\n\\[H(P) = 1\\times\\log(1) + 0\\times\\log(0) + \\dots = 0\\]Note 0 smallest value Shannon entropy can assume, corresponds maximum concentration.Thus, large entropy implies distribution spread whereas small entropy\nmeans distribution concentrated.Correspondingly, maximum entropy distributions can considered minimally informative random variable.interpretation also supported close link Shannon entropy multinomial coefficients counting permutations \\(n\\) items (samples) \\(K\\) distinct types (classes).Example 2.3  Large sample asymptotics log-multinomial coefficient link Shannon entropy:number possible permutation \\(n\\) items \\(K\\) distinct types, \\(n_1\\) type 1, \\(n_2\\) type 2 , given multinomial coefficient\n\\[\nW = \\binom{n}{n_1, \\ldots, n_K} = \\frac {n!}{n_1! \\times n_2! \\times\\ldots \\times n_K! }\n\\]\n\\(\\sum_{k=1}^K n_k = n\\) \\(K \\leq n\\).Now recall Moivre-Sterling formula large \\(n\\) allow approximate\nfactorial \n\\[\n\\log n! \\approx  n \\log n  -n\n\\]\n\\[\n\\begin{split}\n\\log W &= \\log \\binom{n}{n_1, \\ldots, n_K} \\\\\n       &= \\log n! - \\sum_{k=1}^K \\log n_k!\\\\\n& \\approx    n \\log n  -n - \\sum_{k=1}^K (n_k \\log n_k  -n_k) \\\\\n& = n \\log n - \\sum_{k=1}^K n_k \\log n_k\\\\\n& = \\sum_{k=1}^K n_k \\log n - \\sum_{k=1}^K n_k \\log n_k\\\\\n& = - n \\sum_{k=1}^K \\frac{n_k}{n} \\log\\left( \\frac{n_k}{n} \\right)\\\\\n\\end{split}\n\\]\nthus\n\\[\n\\begin{split}\n\\frac{1}{n}\\log \\binom{n}{n_1, \\ldots, n_K} &\\approx - \\sum_{k=1}^K \\hat{p}_k \\log \\hat{p}_k \\\\\n&=H(\\hat{P})\n\\end{split}\n\\]\n\\(\\hat{P}\\) empirical categorical distribution \\(\\hat{p}_k = \\frac{n_k}{n}\\).combinatorical derivation Shannon entropy now credited Wallis (1962)\nalready used century earlier Boltzmann (1877) discovered work\nstatistical mechanics (recall \\(S = k_b \\log W\\) \nBoltzmann entropy ).","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"differential-entropy","chapter":"2 From entropy to maximum likelihood","heading":"2.1.4 Differential entropy","text":"Shannon entropy defined discrete random variables.Differential Entropy results applying \ndefinition Shannon entropy continuous random variable \\(x\\) density \\(p(x)\\):\n\\[\nH(P) = -\\text{E}_P(\\log p(x)) = - \\int_x p(x) \\log p(x) \\, dx\n\\]\nDespite essentially formula different name justified differential entropy exhibits different properties compared Shannon entropy, logarithm taken density\ncontrast probability can assume values larger one.\nconsequence, differential entropy bounded zero can negative.Example 2.4  Consider uniform distribution \\(U(0, )\\) \\(>0\\), support \\(0\\) \\(\\) density \\(p(x) = 1/\\). \\(-\\int_0^p(x) \\log p(x) dx =- \\int_0^\\frac{1}{} \\log(\\frac{1}{}) dx = \\log \\)\ndifferential entropy \n\\[H( U(0, ) ) =  \\log \\,.\\]\nNote \\(< 1\\) differential entropy negative.Example 2.5  log density univariate normal \\(N(\\mu, \\sigma^2)\\) distribution\n\\(\\log p(x |\\mu, \\sigma^2) = -\\frac{1}{2} \\left( \\log(2\\pi\\sigma^2) + \\frac{(x-\\mu)^2}{\\sigma^2} \\right)\\) \\(\\sigma^2 > 0\\).\ncorresponding differential entropy \\(\\text{E}((x-\\mu)^2) = \\sigma^2\\)\n\\[\n\\begin{split}\nH(P) & = -\\text{E}\\left( \\log p(x |\\mu, \\sigma^2) \\right)\\\\\n& = \\frac{1}{2} \\left( \\log(2 \\pi \\sigma^2)+1\\right) \\,. \\\\\n\\end{split}\n\\]\nInterestingly, \\(H(P)\\) depends variance mean, entropy grows variance. Note \\(\\sigma^2 < 1/(2 \\pi e) \\approx 0.0585\\) differential entropy negative.","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"maximum-entropy-principle-to-characterise-distributions","chapter":"2 From entropy to maximum likelihood","heading":"2.1.5 Maximum entropy principle to characterise distributions","text":"maximum Shannon entropy differential entropy useful characterise distributions:discrete\nuniform distribution maximum entropy distribution among discrete distributions.discrete\nuniform distribution maximum entropy distribution among discrete distributions.maximum entropy distribution continuous random variable support \\([-\\infty, \\infty]\\) specific mean variance normal distributionthe maximum entropy distribution continuous random variable support \\([-\\infty, \\infty]\\) specific mean variance normal distributionthe maximum entropy distribution among continuous distributions supported \\([0, \\infty]\\) specified mean exponential distribution.maximum entropy distribution among continuous distributions supported \\([0, \\infty]\\) specified mean exponential distribution.higher entropy spread (uninformative) distribution.Using maximum entropy characterise maximally uniformative distributions\nadvocated E.T. Jaynes (also proposed use maximum entropy context finding Bayesian priors). maximum entropy principle statistical physics goes back Boltzmann.list maximum entropy distribution given :\nhttps://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution .Many distributions commonly used statistical modelling exponential families.\nIntriguingly, distribution maximum entropy distributions, close link\nprinciple maximum entropy common model choices statistics machine learning.","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"cross-entropy","chapter":"2 From entropy to maximum likelihood","heading":"2.1.6 Cross-entropy","text":"definition Shannon entropy (differential entropy) expectation \nlog-density (say \\(g(x)\\) distribution \\(G\\)) taken regard different distribution \\(F\\) state space\narrive cross-entropy\n\\[\nH(F, G) =-\\text{E}_F\\left( \\log g(x)  \\right)\n\\]\ndiscrete distributions \\(F\\) \\(G\\) class probabilities\n\\(f_1, \\ldots, f_K\\) \\(g_1, \\ldots, g_K\\) cross-entropy computed weighted sum \\(H(F, G) = - \\sum_{k=1}^{K} f_k \\log g_k\\).\ncontinuous distributions \\(F\\) \\(G\\) densities \\(f(x)\\) \\(g(x)\\) compute integral\n\\(H(F, G) =- \\int_x f(x) \\log g(x) \\, dx\\).Therefore, cross-entropy measure linking two distributions \\(F\\) \\(G\\).Note thatcross-entropy symmetric regard \\(F\\) \\(G\\), \nexpectation taken reference \\(F\\).construction \\(H(F, F) = H(F)\\). Thus distributions identical cross-entropy reduces Shannon differential entropy, respectively.crucial property cross-entropy \\(H(F, G)\\) bounded entropy \\(F\\), therefore\n\\[\nH(F, G) \\geq H(F)\n\\]\nequality \\(F=G\\). known Gibbs’ inequality.Equivalently can write\n\\[\n\\underbrace{H(F, G)-H(F)}_{\\text{relative entropy}} \\geq 0\n\\]\nfact, recalibrated cross-entropy (known KL divergence relative entropy) turns fundamental cross-entropy entropy. studied detail next section.Example 2.6  Cross-entropy two normals:Assume \\(F_{\\text{ref}}=N(\\mu_{\\text{ref}},\\sigma^2_{\\text{ref}})\\) \\(F=N(\\mu,\\sigma^2)\\).\ncross-entropy \\(H(F_{\\text{ref}}, F)\\) \n\\[\n\\begin{split}\nH(F_{\\text{ref}}, F) &=  -\\text{E}_{F_{\\text{ref}}} \\left( \\log p(x |\\mu, \\sigma^2) \\right)\\\\\n&=  \\frac{1}{2}  \\text{E}_{F_{\\text{ref}}} \\left(  \\log(2\\pi\\sigma^2)  + \\frac{(x-\\mu)^2}{\\sigma^2} \\right) \\\\\n&= \\frac{1}{2} \\left( \\frac{(\\mu - \\mu_{\\text{ref}})^2}{ \\sigma^2 }\n+\\frac{\\sigma^2_{\\text{ref}}}{\\sigma^2}  +\\log(2 \\pi \\sigma^2) \\right)  \\\\\n\\end{split}\n\\]\nusing \\(\\text{E}_{F_{\\text{ref}}} ((x-\\mu)^2) = (\\mu_{\\text{ref}}-\\mu)^2 + \\sigma^2_{\\text{ref}}\\).Example 2.7  \\(\\mu_{\\text{ref}} = \\mu\\) \\(\\sigma^2_{\\text{ref}} = \\sigma^2\\)\ncross-entropy \\(H(F_{\\text{ref}},F)\\) Example 2.6\ndegenerates differential entropy\n\\(H(F_{\\text{ref}}) = \\frac{1}{2} \\left(\\log( 2 \\pi \\sigma^2_{\\text{ref}}) +1 \\right)\\).","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"kullback-leibler-divergence","chapter":"2 From entropy to maximum likelihood","heading":"2.2 Kullback-Leibler divergence","text":"","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"definition","chapter":"2 From entropy to maximum likelihood","heading":"2.2.1 Definition","text":"Also known relative entropy discrimination information.relative entropy measures divergence\ndistribution \\(G\\) distribution \\(F\\) defined \n\\[\n\\begin{split}\nD_{\\text{KL}}(F,G) &= \\text{E}_F\\log\\left(\\frac{dF}{dG}\\right) \\\\\n& = \\text{E}_F\\log\\left(\\frac{f(x)}{g(x)}\\right) \\\\\n& =\n\\underbrace{-\\text{E}_F(\\log g(x))}_{\\text{cross-entropy}} -\n(\\underbrace{-\\text{E}_F (\\log f(x))  }_\\text{(differential) entropy})  \\\\\n& = H(F, G)-H(F) \\\\\n\\end{split}\n\\]\\(D_{\\text{KL}}(F, G)\\) measures amount information lost \\(G\\) used approximate \\(F\\).\\(F\\) \\(G\\) identical (information lost) \\(D_{\\text{KL}}(F,G)=0\\).(Note: “divergence” measures dissimilarity probability distributions. type divergence related confused divergence (div) used vector analysis.)use term “divergence” rather “distance” serves emphasise distributions \\(F\\) \\(G\\) interchangeable \\(D_{\\text{KL}}(F, G)\\).exist various notations KL divergence literature.\nuse \\(D_{\\text{KL}}(F, G)\\) often find well \\(\\text{KL}(F || G)\\)\n\\(^{KL}(F; G)\\).authors (e.g. Efron) call twice KL divergence \\(2 D_{\\text{KL}}(F, G) = D(F, G)\\) deviance \\(G\\) \\(F\\).","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"properties-of-kl-divergence","chapter":"2 From entropy to maximum likelihood","heading":"2.2.2 Properties of KL divergence","text":"\\(D_{\\text{KL}}(F, G) \\neq D_{\\text{KL}}(G, F)\\), .e. KL divergence symmetric, \\(F\\) \\(G\\) interchanged.\\(D_{\\text{KL}}(F, G) = 0\\) \\(F=G\\), .e., KL divergence zero \\(F\\) \\(G\\) identical.\\(D_{\\text{KL}}(F, G)\\geq 0\\), proof via Jensen’s inequality.\\(D_{\\text{KL}}(F, G)\\) remains invariant coordinate transformations,\n.e. invariant geometric quantity.Note KL divergence expectation taken ratio densities (ratio probabilities discrete random variables). creates transformation invariance.details proofs properties 3 4 see Worksheet E1.","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"origin-of-kl-divergence-and-application-in-statistics","chapter":"2 From entropy to maximum likelihood","heading":"2.2.3 Origin of KL divergence and application in statistics","text":"Historically, physics (negative) relative entropy discovered Boltzmann (1878). 2\nstatistics information theory introduced Kullback Leibler (1951). 3In statistics typical roles distribution \\(F\\) \\(G\\) \\(D_{\\text{KL}}(F, G)\\) :\\(F\\) (unknown) underlying true model data generating process\\(G\\) approximating model (typically distribution family indexed parameters)Optimising (.e. minimising) KL divergence regard \\(G\\) amounts approximation optimising regard \\(F\\) imputation. Later see leads method maximum likelihood Bayesian learning, respectively.","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"kl-divergence-examples","chapter":"2 From entropy to maximum likelihood","heading":"2.2.4 KL divergence examples","text":"Example 2.8  KL divergence two Bernoulli distributions \\(\\text{Ber}(\\theta_1)\\) \\(\\text{Ber}(\\theta_2)\\):“success” probabilities two distributions \\(\\theta_1\\) \\(\\theta_2\\),\nrespectively, complementary “failure” probabilities \\(1-\\theta_1\\) \\(1-\\theta_2\\).\nget KL divergence\n\\[\nD_{\\text{KL}}(\\text{Ber}(\\theta_1), \\text{Ber}(\\theta_2))=\\theta_1 \\log\\left( \\frac{\\theta_1}{\\theta_2}\\right) + (1-\\theta_1) \\log\\left(\\frac{1-\\theta_1}{1-\\theta_2}\\right)\n\\]Example 2.9  KL divergence two univariate normals different means variances:Assume \\(F_{\\text{ref}}=N(\\mu_{\\text{ref}},\\sigma^2_{\\text{ref}})\\) \\(F=N(\\mu,\\sigma^2)\\).\n\n\\[\n\\begin{split}\nD_{\\text{KL}}(F_{\\text{ref}},F) &= H(F_{\\text{ref}}, F) - H(F_{\\text{ref}}) \\\\\n&= \\frac{1}{2} \\left(   \\frac{(\\mu-\\mu_{\\text{ref}})^2}{\\sigma^2}  + \\frac{\\sigma_{\\text{ref}}^2}{\\sigma^2}\n-\\log\\left(\\frac{\\sigma_{\\text{ref}}^2}{\\sigma^2}\\right)-1  \n   \\right) \\\\\n\\end{split}\n\\]Example 2.10  KL divergence two univariate normals different means common variance:important special case previous Example 2.9 occurs \nvariances equal. get\n\\[D_{\\text{KL}}(N(\\mu_{\\text{ref}}, \\sigma^2),   N(\\mu, \\sigma^2)  )=\\frac{1}{2} \\left(\\frac{(\\mu-\\mu_{\\text{ref}})^2}{\\sigma^2}\\right)\\]","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"local-quadratic-approximation-and-expected-fisher-information","chapter":"2 From entropy to maximum likelihood","heading":"2.3 Local quadratic approximation and expected Fisher information","text":"","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"definition-of-expected-fisher-information","chapter":"2 From entropy to maximum likelihood","heading":"2.3.1 Definition of expected Fisher information","text":"KL information measures divergence two distributions.\nmay thus use relative entropy measure divergence two distributions family, separated parameter space small \\(\\boldsymbol \\varepsilon\\).First, consider \\(D_{\\text{KL}}(F_{\\boldsymbol \\theta}, F_{\\boldsymbol \\theta+\\boldsymbol \\varepsilon}) = \\text{E}_{F_{\\boldsymbol \\theta}}\\left( \\log f(\\boldsymbol x| \\boldsymbol \\theta) - \\log f(\\boldsymbol x| \\boldsymbol \\theta+\\boldsymbol \\varepsilon) \\right) = h(\\boldsymbol \\varepsilon)\\)\n\\(\\boldsymbol \\theta\\) kept constant \\(\\boldsymbol \\varepsilon\\) varying. properties\nKL divergence know \\(D_{\\text{KL}}(F_{\\boldsymbol \\theta}, F_{\\boldsymbol \\theta+\\boldsymbol \\varepsilon})\\geq 0\\)\nbecomes zero \\(\\boldsymbol \\varepsilon=0\\). Thus, construction function\n\\(h(\\boldsymbol \\varepsilon)\\) achieves true minimum \\(h(0)=0\\) \\(\\boldsymbol \\varepsilon=0\\),\nvanishing gradient \\(\\nabla h(0)=0\\) positive definite Hessian matrix \\(\\nabla \\nabla^T h(0)\\). Therfore can approximate quadratic function around \\(\\boldsymbol \\varepsilon=0\\):\n\\[\nh(\\boldsymbol \\varepsilon) \\approx \\frac{1}{2} \\boldsymbol \\varepsilon^T \\, \\nabla \\nabla^T h(0) \\, \\boldsymbol \\varepsilon\n\\]\nHessian matrix \\(\\nabla \\nabla^T h(0)\\) computed \\(\\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta) = -\\text{E}_{F_{\\boldsymbol \\theta}} \\nabla \\nabla^T \\log f(\\boldsymbol x| \\boldsymbol \\theta)\\) negative expected Hessian matrix log-density \\(\\boldsymbol \\theta\\). called expected Fisher information \\(\\boldsymbol \\theta\\).\nKL divergence can thus locally approximated \n\\[\nD_{\\text{KL}}(F_{\\boldsymbol \\theta}, F_{\\boldsymbol \\theta+\\boldsymbol \\varepsilon})\\approx \\frac{1}{2} \\boldsymbol \\varepsilon^T  \\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta) \\boldsymbol \\varepsilon\n\\]second possibility may also vary first argument KL divergence.\nstraightforward show leads approximation second order\n\\(\\boldsymbol \\varepsilon\\):\n\\[\n\\begin{split}\nD_{\\text{KL}}(F_{\\boldsymbol \\theta+\\boldsymbol \\varepsilon}, F_{\\boldsymbol \\theta})\n&\\approx \\frac{1}{2}\\boldsymbol \\varepsilon^T \\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta)\\, \\boldsymbol \\varepsilon\\\\\n\\end{split}\n\\]Computing expected Fisher information involves observed data,\npurely property model, precisely \nmodel family indexed \\(\\boldsymbol \\theta\\).\nnext Chapter study related quantity,\nobserved Fisher information contrast function observed data.","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"examples","chapter":"2 From entropy to maximum likelihood","heading":"2.3.2 Examples","text":"Example 2.11  Expected Fisher information Bernoulli distribution:log-probability mass function Bernoulli \\(\\text{Ber}(\\theta)\\) distribution \n\\[\n\\log p(x | \\theta) = x \\log(\\theta) + (1-x) \\log(1-\\theta)\n\\]\n\\(\\theta\\) probability “success”.\nsecond derivative regard parameter \\(\\theta\\) \n\\[\n\\frac{d^2}{d\\theta^2} \\log p(x | \\theta)  =  -\\frac{x}{\\theta^2}-  \\frac{1-x}{(1-\\theta)^2}\n\\]\nSince \\(\\text{E}(x) = \\theta\\) get Fisher information\n\\[\n\\begin{split}\n^{\\text{Fisher}}(\\theta) & = -\\text{E}\\left(\\frac{d^2}{d\\theta^2} \\log p(x | \\theta)  \\right)\\\\\n                           &= \\frac{\\theta}{\\theta^2}+  \\frac{1-\\theta}{(1-\\theta)^2} \\\\\n                            &= \\frac{1}{\\theta(1-\\theta)}\\\\\n\\end{split}\n\\]Example 2.12  Quadratic approximations KL divergence two Bernoulli distributions:Example 2.8 KL divergence\n\\[\nD_{\\text{KL}}\\left (\\text{Ber}(\\theta_1), \\text{Ber}(\\theta_2) \\right)=\\theta_1 \\log\\left( \\frac{\\theta_1}{\\theta_2}\\right) + (1-\\theta_1) \\log\\left(\\frac{1-\\theta_1}{1-\\theta_2}\\right)\n\\]\n\nExample 2.11 corresponding expected Fisher information.quadratic approximation implies \n\\[\nD_{\\text{KL}}\\left( \\text{Ber}(\\theta), \\text{Ber}(\\theta + \\varepsilon) \\right) \\approx \\frac{\\varepsilon^2}{2}  ^{\\text{Fisher}}(\\theta) =  \\frac{\\varepsilon^2}{2 \\theta (1-\\theta)}\n\\]\nalso \n\\[\nD_{\\text{KL}}\\left( \\text{Ber}(\\theta+\\varepsilon), \\text{Ber}(\\theta) \\right) \\approx \\frac{\\varepsilon^2}{2} ^{\\text{Fisher}}(\\theta) =  \\frac{\\varepsilon^2}{2 \\theta (1-\\theta)}\n\\]Worksheet E1 verified using second order Taylor series applied KL divergence.Example 2.13  Expected Fisher information normal distribution \\(N(\\mu, \\sigma^2)\\).log-density \n\\[\n\\log f(x | \\mu, \\sigma^2) = -\\frac{1}{2} \\log(\\sigma^2)\n-\\frac{1}{2 \\sigma^2} (x-\\mu)^2 - \\frac{1}{2}\\log(2 \\pi)\n\\]\ngradient respect \\(\\mu\\) \\(\\sigma^2\\) (!) vector\n\\[\n\\nabla \\log f(x | \\mu, \\sigma^2) =\n\\begin{pmatrix}\n\\frac{1}{\\sigma^2} (x-\\mu) \\\\\n- \\frac{1}{2 \\sigma^2} + \\frac{1}{2 \\sigma^4} (x- \\mu)^2 \\\\\n\\end{pmatrix}\n\\]\nHint calculating gradient: replace \\(\\sigma^2\\) \\(v\\) take partial derivative regard \\(v\\), substitute back.corresponding Hessian matrix \n\\[\n\\nabla \\nabla^T \\log f(x | \\mu, \\sigma^2) =\n\\begin{pmatrix}\n-\\frac{1}{\\sigma^2} & -\\frac{1}{\\sigma^4} (x-\\mu)\\\\\n-\\frac{1}{\\sigma^4} (x-\\mu) &  \\frac{1}{2\\sigma^4} - \\frac{1}{\\sigma^6}(x- \\mu)^2 \\\\\n\\end{pmatrix}\n\\]\n\\(\\text{E}(x) = \\mu\\) \\(\\text{E}(x-\\mu) =0\\).\nFurthermore, \\(\\text{E}( (x-\\mu)^2 ) =\\sigma^2\\) see \n\\(\\text{E}\\left(\\frac{1}{\\sigma^6}(x- \\mu)^2\\right) = \\frac{1}{\\sigma^4}\\). Therefore\nexpected Fisher information matrix negative expected Hessian matrix \n\\[\n\\boldsymbol ^{\\text{Fisher}}\\left(\\mu,\\sigma^2\\right) = \\begin{pmatrix} \\frac{1}{\\sigma^2} & 0 \\\\ 0 & \\frac{1}{2\\sigma^4} \\end{pmatrix}\n\\]Example 2.14  Expected Fisher information set independent identically distributed random variables.Assume random variable \\(x \\sim F_{\\boldsymbol \\theta}\\) log-density \\(\\log f(x| \\boldsymbol \\theta)\\)\nexpected Fisher information \\(\\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta)\\).\nexpected Fisher information \\(\\boldsymbol I_{x_1, \\ldots, x_n}^{\\text{Fisher}}(\\boldsymbol \\theta)\\)\nset iid random variables \\(x_1, \\ldots, x_n \\sim F_{\\boldsymbol \\theta}\\)\ncomputed joint log-density \\(\\log f(x_1, \\ldots, x_n) = \\sum_{}^n \\log f(x_i| \\boldsymbol \\theta)\\).\nyields \\(\\boldsymbol I_{x_1, \\ldots, x_n}^{\\text{Fisher}}(\\boldsymbol \\theta) = -\\text{E}_{F_{\\boldsymbol \\theta}} \\nabla \\nabla^T \\sum_{}^n \\log f(x_i| \\boldsymbol \\theta) = \\sum_{}^n \\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta) = n \\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta)\\).","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"entropy-learning-and-maximum-likelihood","chapter":"2 From entropy to maximum likelihood","heading":"2.4 Entropy learning and maximum likelihood","text":"","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"the-relative-entropy-between-true-model-and-approximating-model","chapter":"2 From entropy to maximum likelihood","heading":"2.4.1 The relative entropy between true model and approximating model","text":"Assume observations \\(D = \\{x_1, \\ldots, x_n\\}\\). data sampled \\(F\\), true unknown data generating distribution. also specify family distributions \\(G_{\\boldsymbol \\theta}\\)\nindexed \\(\\boldsymbol \\theta\\) approximate \\(F\\).relative entropy \\(D_{\\text{KL}}(F,G_{\\boldsymbol \\theta})\\) measures divergence approximation \\(G_{\\boldsymbol \\theta}\\)\nunknown true model \\(F\\). can written :\n\\[\n\\begin{split}\nD_{\\text{KL}}(F,G_{\\boldsymbol \\theta}) &= H(F,G_{\\boldsymbol \\theta}) - H(F) \\\\\n&= \\underbrace{- \\text{E}_{F}\\log g_{\\boldsymbol \\theta}(x)}_{\\text{cross-entropy}}\n-(\\underbrace{-\\text{E}_{F}\\log f(x)}_{\\text{entropy $F$, depend $\\boldsymbol \\theta$}})\\\\\n\\end{split}\n\\]However, since know \\(F\\) actually compute divergence. Nonetheless, may use\nempirical distribution \\(\\hat{F}_n\\) — function observed data — approximation \\(F\\), way arrive approximation \\(D_{\\text{KL}}(F,G_{\\boldsymbol \\theta})\\) becomes accurate growing sample size.Recall “Law Large Numbers” :strong law large numbers empirical distribution\n\\(\\hat{F}_n\\) based observed data \\(D=\\{x_1, \\ldots, x_n\\}\\) converges true underlying distribution \\(F\\) \\(n \\rightarrow \\infty\\) almost surely:\n\\[\n\\hat{F}_n\\overset{. s.}{\\} F\n\\]strong law large numbers empirical distribution\n\\(\\hat{F}_n\\) based observed data \\(D=\\{x_1, \\ldots, x_n\\}\\) converges true underlying distribution \\(F\\) \\(n \\rightarrow \\infty\\) almost surely:\n\\[\n\\hat{F}_n\\overset{. s.}{\\} F\n\\]\\(n \\rightarrow \\infty\\) average \\(\\text{E}_{\\hat{F}_n}(h(x)) = \\frac{1}{n} \\sum_{=1}^n h(x_i)\\) converges expectation \\(\\text{E}_{F}(h(x))\\).\\(n \\rightarrow \\infty\\) average \\(\\text{E}_{\\hat{F}_n}(h(x)) = \\frac{1}{n} \\sum_{=1}^n h(x_i)\\) converges expectation \\(\\text{E}_{F}(h(x))\\).Hence, large sample size \\(n\\) can approximate cross-entropy result KL divergence. cross-entropy \\(H(F, G_{\\boldsymbol \\theta})\\) approximated empirical cross-entropy expectation taken regard \\(\\hat{F}_n\\) rather \\(F\\):\n\\[\n\\begin{split}\nH(F, G_{\\boldsymbol \\theta}) & \\approx H(\\hat{F}_n, G_{\\boldsymbol \\theta}) \\\\\n                  & = - \\text{E}_{\\hat{F}_n} (\\log g(x|\\boldsymbol \\theta))  \\\\\n                  & = -\\frac{1}{n} \\sum_{=1}^n \\log g(x_i | \\boldsymbol \\theta) \\\\\n                  & = -\\frac{1}{n} l_n ({\\boldsymbol \\theta}| D)\n\\end{split}\n\\]\nturns equal negative log-likelihood standardised sample size \\(n\\)! words, log-likelihood negative empirical cross-entropy multiplied sample size \\(n\\).link multinomial coefficient Shannon entropy (Example 2.3) already know large sample size\n\\[\nH(\\hat{F}) \\approx \\frac{1}{n} \\log \\binom{n}{n_1, \\ldots, n_K}\n\\]KL divergence \\(D_{\\text{KL}}(F,G_{\\boldsymbol \\theta})\\) can therefore approximated \n\\[\nD_{\\text{KL}}(F,G_{\\boldsymbol \\theta}) \\approx -\\frac{1}{n} \\left( \\log \\binom{n}{n_1, \\ldots, n_K} + l_n ({\\boldsymbol \\theta}| D)  \\right)\n\\]\nThus, KL divergence obtain just log-likelihood (cross-entropy part) also multiplicity factor taking account possible orderings data (entropy part).","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"minimum-kl-divergence-and-maximum-likelihood","chapter":"2 From entropy to maximum likelihood","heading":"2.4.2 Minimum KL divergence and maximum likelihood","text":"knew \\(F\\) simply minimise \\(D_{\\text{KL}}(F, G_{\\boldsymbol \\theta})\\) find particular model \\(G_{\\boldsymbol \\theta}\\) closest true model. Equivalently, minimise cross-entropy \\(H(F, G_{\\boldsymbol \\theta})\\).\nHowever, since actually don’t know \\(F\\) possible.However, large sample size \\(n\\) empirical distribution \\(\\hat{F}_n\\)\ngood approximation \\(F\\), can use results previous section.\nThus, instead minimising KL divergence\n\\(D_{\\text{KL}}(F, G_{\\boldsymbol \\theta})\\) simply minimise \\(H(\\hat{F}_n, G_{\\boldsymbol \\theta})\\) \nmaximising log-likelihood \\(l_n ({\\boldsymbol \\theta}| D)\\).Conversely, implies maximising likelihood regard \\(\\boldsymbol \\theta\\) equivalent ( asymptotically large \\(n\\)) minimising KL divergence approximating model unknown true model!\\[\n\\begin{split}\n\\hat{\\boldsymbol \\theta}^{ML} &= \\underset{\\boldsymbol \\theta}{\\arg \\max}\\,\\, l_n(\\boldsymbol \\theta| D) \\\\\n&= \\underset{\\boldsymbol \\theta}{\\arg \\min}\\,\\, H(\\hat{F}_n, G_{\\boldsymbol \\theta}) \\\\\n&\\approx \\underset{\\boldsymbol \\theta}{\\arg \\min}\\,\\, D_{\\text{KL}}(F, G_{\\boldsymbol \\theta}) \\\\\n\\end{split}\n\\]Therefore, reasoning behind method maximum likelihood minimises large sample approximation KL divergence candidate model \\(G_{\\boldsymbol \\theta}\\) unkown true model \\(F\\).consequence close link maximum likelihood relative entropy\nmaximum likelihood inherits large \\(n\\) (!) optimality properties KL divergence. discussed detail later course.","code":""},{"path":"from-entropy-to-maximum-likelihood.html","id":"further-connections","chapter":"2 From entropy to maximum likelihood","heading":"2.4.3 Further connections","text":"Since minimising KL divergence contains ML estimation special case may wonder whether broader justification relative entropy context statistical data analysis?Indeed, KL divergence strong geometrical interpretation forms basis information geometry.\nfield manifold distributions\nstudied using tools differential geometry. expected Fisher information\nplays important role metric tensor space distributions.Furthermore, also linked probabilistic forecasting.\nframework -called scoring rules.\nlocal proper scoring rule negative log-probability (“surprise”).\nexpected “surprise” cross-entropy\nrelative entropy corresponding natural divergence connected log scoring rule.Furthermore, another intriguing property KL divergence relative entropy \\(D_{\\text{KL}}(F, G)\\) divergence measure Bregman \\(f\\)-divergence.\nNote \\(f\\)-divergences Bregman-divergences (turn related proper scoring rules) two large classes measures similarity divergence two probability distributions.Finally, likelihood estimation also Bayesian update rule (discussed later module) another special case entropy learning.","code":""},{"path":"maximum-likelihood-estimation.html","id":"maximum-likelihood-estimation","chapter":"3 Maximum likelihood estimation","heading":"3 Maximum likelihood estimation","text":"","code":""},{"path":"maximum-likelihood-estimation.html","id":"principle-of-maximum-likelihood-estimation","chapter":"3 Maximum likelihood estimation","heading":"3.1 Principle of maximum likelihood estimation","text":"","code":""},{"path":"maximum-likelihood-estimation.html","id":"outline","chapter":"3 Maximum likelihood estimation","heading":"3.1.1 Outline","text":"starting points ML analysis arethe observed data \\(D = \\{x_1,\\ldots,x_n\\}\\) \\(n\\) independent identically distributed (iid) samples, ordering irrelevant, amodel \\(F_{\\boldsymbol \\theta}\\) corresponding probability density probability mass function \\(f(x|\\boldsymbol \\theta)\\) parameters \\(\\boldsymbol \\theta\\)construct likelihood function:\\(L_n(\\boldsymbol \\theta|D)=\\prod_{=1}^{n} f(x_i|\\boldsymbol \\theta)\\)Historically, likelihood also often interpreted probability data given model. However, strictly correct. First, interpretation applies discrete random variables. Second, since samples iid even case one still need add factor accounting multiplicity possible orderings samples obtain correct probability data. Third, interpretation likelihood probability data completely breaks continuous random variables \\(f(x |\\boldsymbol \\theta)\\) density, probability.seen previous chapter origin likelihood function\nlies connection relative entropy. Specifically, \nlog-likelihood function\\(l_n(\\boldsymbol \\theta|D)=\\sum_{=1}^n \\log f(x_i|\\boldsymbol \\theta)\\)divided sample size \\(n\\) large sample approximation cross-entropy unknown true data generating model approximating model \\(F_{\\boldsymbol \\theta}\\).\nNote log-likelihood additive samples \\(x_i\\).maximum likelihood point estimate \\(\\hat{\\boldsymbol \\theta}^{ML}\\) \ngiven maximising (log)-likelihood\\[\\hat{\\boldsymbol \\theta}^{ML} = \\text{arg max}\\, l_n(\\boldsymbol \\theta|D)\\]Thus, finding MLE optimisation problem practise often solved numerically computer, using approaches gradient ascent (negative log-likelihood gradient descent) related algorithms. Depending complexity likelihood function finding maximum can difficult.","code":""},{"path":"maximum-likelihood-estimation.html","id":"obtaining-mles-for-a-regular-model","chapter":"3 Maximum likelihood estimation","heading":"3.1.2 Obtaining MLEs for a regular model","text":"regular situations, .e. whenthe log-likelihood function twice differentiable regard parameters,maximum (peak) likelihood function lies inside parameter space\nboundary,parameters model identifiable (particular model overparameterised), andthe second derivative log-likelihood maximum negative zero (\none parameter: Hessian matrix maximum negative definite singular)order maximise \\(l_n(\\boldsymbol \\theta|D)\\) one may use score function \\(\\boldsymbol S(\\boldsymbol \\theta)\\)\nfirst derivative log-likelihood function:\\[\\begin{align*}\n\\begin{array}{cc}\nS_n(\\theta) = \\frac{d l_n(\\theta|D)}{d \\theta}\\\\\n\\\\\n\\\\\n\\boldsymbol S_n(\\boldsymbol \\theta)=\\nabla l_n(\\boldsymbol \\theta|D)\\\\\n\\\\\n\\end{array}\n\\begin{array}{ll}\n\\text{scalar parameter $\\theta$: first derivative}\\\\\n\\text{log-likelihood function}\\\\\n\\\\\n\\text{gradient } \\boldsymbol \\theta\\text{ vector}\\\\\n\\text{(.e. one parameter)}\\\\\n\\end{array}\n\\end{align*}\\]necessary (sufficient) condition MLE \n\\[\n\\boldsymbol S_n(\\hat{\\boldsymbol \\theta}_{ML}) = 0\n\\]demonstrate log-likelihood function actually achieves \nmaximum \\(\\hat{\\boldsymbol \\theta}_{ML}\\) curvature\nMLE must negative, .e. log-likelihood must locally concave MLE.case single parameter (scalar \\(\\theta\\)) requires check\nsecond derivative log-likelihood function negative:\n\\[\n\\frac{d^2 l_n(\\hat{\\theta}_{ML}| D)}{d \\theta^2} <0\n\\]\ncase parameter vector (multivariate \\(\\boldsymbol \\theta\\)) need compute\nHessian matrix (matrix second order derivatives)\nMLE:\n\\[\n\\nabla \\nabla^T l_n(\\hat{\\boldsymbol \\theta}_{ML}| D)\n\\]\nverify matrix negative definite (.e. eigenvalues must negative).see later second order derivatives log-likelihood function also play important role assessing uncertainty MLE.","code":""},{"path":"maximum-likelihood-estimation.html","id":"invariance-property-of-the-maximum-likelihood","chapter":"3 Maximum likelihood estimation","heading":"3.1.3 Invariance property of the maximum likelihood","text":"invariance principle states maximum likelihood invariant reparameterisation.Assume transform parameter \\(\\theta\\) another parameter \\(\\omega\\) using invertible function \\(g()\\)\n\\(\\omega= g(\\theta)\\).\nmaximum likelihood estimate \\(\\hat{\\omega}_{ML}\\) new parameter \\(\\omega\\) simply\ntransformation maximum likelihood estimate \\(\\hat{\\theta}_{ML}\\) original parameter \\(\\theta\\)\n\\(\\hat{\\omega}_{ML}= g( \\hat{\\theta}_{ML})\\). achieved\nmaximum likelihood cases.reason works maximisation procedure invariant transformations argument\nfunction maximised. Consider function \\(h(x)\\) maximum \\(x_{\\max} = \\text{arg max } h(x)\\). Now relabel argument using\n\\(y = g(x)\\) \\(g\\) invertible function. function terms \\(y\\) \\(h( g^{-1}(y))\\).\nclearly function maximum \\(y_{\\max} = g(x_{\\max})\\) since\n\\(h(g^{-1}(y_{\\max} ) ) = h( x_{\\max} )\\).invariance property can useful practise often easier (sometimes numerically stable) maximise likelihood different set parameters.See Worksheet L1 example application invariance principle.","code":""},{"path":"maximum-likelihood-estimation.html","id":"consistency-of-maximum-likelihood-estimates","chapter":"3 Maximum likelihood estimation","heading":"3.1.4 Consistency of maximum likelihood estimates","text":"One important property maximum likelihood produces consistent estimates.Specifically, true underlying model \\(F_{\\text{true}}\\) parameter \\(\\boldsymbol \\theta_{\\text{true}}\\) contained set specified candidates models \\(F_{\\boldsymbol \\theta}\\)\n\\[\\underbrace{F_{\\text{true}}}_{\\text{true model}} \\subset \\underbrace{F_{\\boldsymbol \\theta}}_{\\text{specified models}}\\] \\[\\hat{\\boldsymbol \\theta}_{ML} \\overset{\\text{large }n}{\\longrightarrow} \\boldsymbol \\theta_{\\text{true}}\\]consequence \\(D_{\\text{KL}}(F_{\\text{true}},F_{\\boldsymbol \\theta})\\rightarrow 0\\) \\(F_{\\boldsymbol \\theta} \\rightarrow F_{\\text{true}}\\), maximisation likelihood function large \\(n\\) equivalent minimising relative entropy.Thus given sufficient data MLE converge true value. consequence, MLEs asympotically unbiased. see examples can still biased finite samples.Note even candidate model \\(F_{\\boldsymbol \\theta}\\) misspecified (.e. contain actual true model) MLE still optimal sense find closest possible model.possible find inconsistent MLEs, occurs situations dimension model / number parameters increases sample size, MLE boundary singularities likelihood function.","code":""},{"path":"maximum-likelihood-estimation.html","id":"maximum-likelihood-estimation-in-practise","chapter":"3 Maximum likelihood estimation","heading":"3.2 Maximum likelihood estimation in practise","text":"","code":""},{"path":"maximum-likelihood-estimation.html","id":"likelihood-estimation-for-a-single-parameter","chapter":"3 Maximum likelihood estimation","heading":"3.2.1 Likelihood estimation for a single parameter","text":"following illustrate likelihood estimation\nmodels single parameter. case score\nfunction second derivative log-likelihood scalar-valued\nlike log-likelihood function .Example 3.1  Estimation proportion – maximum likelihood Bernoulli model:aim estimate true proportion \\(\\theta\\) Bernoulli experiment binary\noutcomes, say proportion “successes” vs. “failures” “heads” vs. “tails” coin tossing experiment.Bernoulli model \\(\\text{Ber}(\\theta)\\): \\(\\text{Pr}(\\text{\"success\"}) = \\theta\\) \\(\\text{Pr}(\\text{\"failure\"}) = 1-\\theta\\).“success” indicated outcome \\(x=1\\) “failure” \\(x=0\\).conduct \\(n\\) trials record \\(n_1\\) successes \\(n-n_1\\) failures.Parameter: \\(\\theta\\) probability “success”.MLE \\(\\theta\\)?observations \\(D=\\{x_1, \\ldots, x_n\\}\\) take values 0 1.observations \\(D=\\{x_1, \\ldots, x_n\\}\\) take values 0 1.average data points \\(\\bar{x} = \\frac{1}{n} \\sum_{=1}^n x_i = \\frac{n_1}{n}\\).average data points \\(\\bar{x} = \\frac{1}{n} \\sum_{=1}^n x_i = \\frac{n_1}{n}\\).probability mass function (PMF) Bernoulli distribution \\(\\text{Ber}(\\theta)\\) :\n\\[\np(x| \\theta) = \\theta^x (1-\\theta)^{1-x} =\n\\begin{cases}\n\\theta &  \\text{$x=1$ }\\\\\n1-\\theta & \\text{$x=0$} \\\\\n\\end{cases}\n\\]probability mass function (PMF) Bernoulli distribution \\(\\text{Ber}(\\theta)\\) :\n\\[\np(x| \\theta) = \\theta^x (1-\\theta)^{1-x} =\n\\begin{cases}\n\\theta &  \\text{$x=1$ }\\\\\n1-\\theta & \\text{$x=0$} \\\\\n\\end{cases}\n\\]log-PMF:\n\\[\n\\log p(x| \\theta) =  x \\log(\\theta) + (1-x) \\log(1 - \\theta)\n\\]log-PMF:\n\\[\n\\log p(x| \\theta) =  x \\log(\\theta) + (1-x) \\log(1 - \\theta)\n\\]log-likelihood function:\n\\[\n\\begin{split}\nl_n(\\theta| D) & = \\sum_{=1}^n \\log f(x_i| \\theta) \\\\\n    & = n_1 \\log \\theta + (n-n_1) \\log(1-\\theta) \\\\\n    & = n \\left( \\bar{x} \\log \\theta + (1-\\bar{x}) \\log(1-\\theta) \\right) \\\\\n\\end{split}\n\\]\nNote log-likelihood depends data \\(\\bar{x}\\)! \nexample sufficient statistic parameter \\(\\theta\\) (fact also minimally sufficient statistic). discussed detail later.log-likelihood function:\n\\[\n\\begin{split}\nl_n(\\theta| D) & = \\sum_{=1}^n \\log f(x_i| \\theta) \\\\\n    & = n_1 \\log \\theta + (n-n_1) \\log(1-\\theta) \\\\\n    & = n \\left( \\bar{x} \\log \\theta + (1-\\bar{x}) \\log(1-\\theta) \\right) \\\\\n\\end{split}\n\\]\nNote log-likelihood depends data \\(\\bar{x}\\)! \nexample sufficient statistic parameter \\(\\theta\\) (fact also minimally sufficient statistic). discussed detail later.Score function:\n\\[\nS_n(\\theta)=  \\frac{dl_n(\\theta| D)}{d\\theta}= n \\left( \\frac{\\bar{x}}{\\theta}-\\frac{1-\\bar{x}}{1-\\theta} \\right)\n\\]Score function:\n\\[\nS_n(\\theta)=  \\frac{dl_n(\\theta| D)}{d\\theta}= n \\left( \\frac{\\bar{x}}{\\theta}-\\frac{1-\\bar{x}}{1-\\theta} \\right)\n\\]Maximum likelihood estimate: Setting \\(S_n(\\hat{\\theta}_{ML})=0\\) yields solution\n\\[\n\\hat{\\theta}_{ML} = \\bar{x} = \\frac{n_1}{n}\n\\]\n\\(\\frac{dS_n(\\theta)}{d\\theta} = -n \\left( \\frac{\\bar{x}}{\\theta^2} + \\frac{1-\\bar{x}}{(1-\\theta)^2} \\right) <0\\) optimum corresponds indeed maximum (log-)likelihood function negative \\(\\hat{\\theta}_{ML}\\) (indeed \\(\\theta\\)).\nmaximum likelihood estimator \\(\\theta\\) therefore identical frequency\nsuccesses among observations.Maximum likelihood estimate: Setting \\(S_n(\\hat{\\theta}_{ML})=0\\) yields solution\n\\[\n\\hat{\\theta}_{ML} = \\bar{x} = \\frac{n_1}{n}\n\\]\\(\\frac{dS_n(\\theta)}{d\\theta} = -n \\left( \\frac{\\bar{x}}{\\theta^2} + \\frac{1-\\bar{x}}{(1-\\theta)^2} \\right) <0\\) optimum corresponds indeed maximum (log-)likelihood function negative \\(\\hat{\\theta}_{ML}\\) (indeed \\(\\theta\\)).maximum likelihood estimator \\(\\theta\\) therefore identical frequency\nsuccesses among observations.Note analyse coin tossing experiment estimate \\(\\theta\\) may equally well use binomial distribution \\(\\text{Bin}(n, \\theta)\\) model number successes. results MLE \\(\\theta\\) likelihood function based binomial PMF includes binomial coefficient. However, depend \\(\\theta\\) disappears score function influence derivation MLE.Example 3.2  Normal distribution unknown mean known variance:\\(x \\sim N(\\mu,\\sigma^2)\\) \\(\\text{E}(x)=\\mu\\) \\(\\text{Var}(x) = \\sigma^2\\)parameter estimated \\(\\mu\\) whereas \\(\\sigma^2\\) known.’s MLE parameter \\(\\mu\\)?data \\(D= \\{x_1, \\ldots, x_n\\}\\) real range \\(x_i \\[-\\infty, \\infty]\\).data \\(D= \\{x_1, \\ldots, x_n\\}\\) real range \\(x_i \\[-\\infty, \\infty]\\).average \\(\\bar{x} = \\frac{1}{n} \\sum_{=1}^n x_i\\) real well.average \\(\\bar{x} = \\frac{1}{n} \\sum_{=1}^n x_i\\) real well.Density: \\[ f(x| \\mu)=\n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\n\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\]Density: \\[ f(x| \\mu)=\n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\n\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\]Log-Density:\n\\[\\log f(x| \\mu) =-\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2}\\]Log-Density:\n\\[\\log f(x| \\mu) =-\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2}\\]Log-likelihood function:\n\\[\n\\begin{split}\nl_n(\\mu| D) &= \\sum_{=1}^n \\log f(x_i| \\mu)\\\\\n&=-\\frac{1}{2\\sigma^2}\\sum_{=1}^n(x_i-\\mu)^2  \\underbrace{-\\frac{n}{2}\\log(2 \\pi \\sigma^2) }_{\\text{constant term, depend } \\mu \\text{, can removed}}\\\\\n&=-\\frac{1}{2\\sigma^2}\\sum_{=1}^n(x_i^2 - 2 x_i \\mu+\\mu^2)  + C\\\\\n&=\\frac{n}{\\sigma^2}  ( \\bar{x} \\mu  - \\frac{1}{2}\\mu^2)  \\underbrace{ - \\frac{1}{2\\sigma^2}\\sum_{=1}^n   x_i^2 }_{\\text{another constant term}}   + C\\\\\n\\end{split}\n\\]\nNote non-constant terms log-likelihood depend data \\(\\bar{x}\\)!Log-likelihood function:\n\\[\n\\begin{split}\nl_n(\\mu| D) &= \\sum_{=1}^n \\log f(x_i| \\mu)\\\\\n&=-\\frac{1}{2\\sigma^2}\\sum_{=1}^n(x_i-\\mu)^2  \\underbrace{-\\frac{n}{2}\\log(2 \\pi \\sigma^2) }_{\\text{constant term, depend } \\mu \\text{, can removed}}\\\\\n&=-\\frac{1}{2\\sigma^2}\\sum_{=1}^n(x_i^2 - 2 x_i \\mu+\\mu^2)  + C\\\\\n&=\\frac{n}{\\sigma^2}  ( \\bar{x} \\mu  - \\frac{1}{2}\\mu^2)  \\underbrace{ - \\frac{1}{2\\sigma^2}\\sum_{=1}^n   x_i^2 }_{\\text{another constant term}}   + C\\\\\n\\end{split}\n\\]\nNote non-constant terms log-likelihood depend data \\(\\bar{x}\\)!Score function:\n\\[\nS_n(\\mu) =\n\\frac{n}{\\sigma^2} ( \\bar{x}- \\mu)\n\\]Score function:\n\\[\nS_n(\\mu) =\n\\frac{n}{\\sigma^2} ( \\bar{x}- \\mu)\n\\]Maximum likelihood estimate:\n\\[S_n(\\hat{\\mu}_{ML})=0 \\Rightarrow \\hat{\\mu}_{ML} = \\bar{x}\\]Maximum likelihood estimate:\n\\[S_n(\\hat{\\mu}_{ML})=0 \\Rightarrow \\hat{\\mu}_{ML} = \\bar{x}\\]\\(\\frac{dS_n(\\mu)}{d\\mu} = -\\frac{n}{\\sigma^2}<0\\) optimum indeed maximumWith \\(\\frac{dS_n(\\mu)}{d\\mu} = -\\frac{n}{\\sigma^2}<0\\) optimum indeed maximumThe constant term \\(C\\) log-likelihood function collects terms depend parameter. taking first derivative regard parameter term disappears thus \\(C\\) relevant finding MLE parameter.\nfuture often omit constant terms log-likelihood function without mention.Example 3.3  Normal distribution known mean unknown variance:\\(x \\sim N(\\mu,\\sigma^2)\\) \\(\\text{E}(x)=\\mu\\) \\(\\text{Var}(x) = \\sigma^2\\)\\(\\sigma^2\\) needs estimated whereas mean \\(\\mu\\) knownWhat’s MLE \\(\\sigma^2\\)?data \\(D= \\{x_1, \\ldots, x_n\\}\\) real range \\(x_i \\[-\\infty, \\infty]\\).data \\(D= \\{x_1, \\ldots, x_n\\}\\) real range \\(x_i \\[-\\infty, \\infty]\\).average squared centred data \\(\\overline{(x-\\mu)^2} = \\frac{1}{n} \\sum_{=1}^n (x_i-\\mu)^2 \\geq 0\\) non-negative.average squared centred data \\(\\overline{(x-\\mu)^2} = \\frac{1}{n} \\sum_{=1}^n (x_i-\\mu)^2 \\geq 0\\) non-negative.Density: \\[ f(x| \\sigma^2)=(2\\pi\\sigma^2)^{-\\frac{1}{2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\]Density: \\[ f(x| \\sigma^2)=(2\\pi\\sigma^2)^{-\\frac{1}{2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\]Log-Density:\n\\[\\log f(x | \\sigma^2) =-\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2}\\]Log-Density:\n\\[\\log f(x | \\sigma^2) =-\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2}\\]Log-likelihood function:\n\\[\n\\begin{split}\nl_n(\\sigma | D) & = l_n(\\mu, \\sigma^2 | D) = \\sum_{=1}^n \\log f(x_i| \\sigma^2)\\\\\n&= -\\frac{n}{2}\\log(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{=1}^n(x_i-\\mu)^2  \\underbrace{-\\frac{n}{2} \\log(2 \\pi) }_{\\text{constant depending } \\sigma^2}\\\\\n&= -\\frac{n}{2}\\log(\\sigma^2)-\\frac{n}{2\\sigma^2}  \\overline{(x-\\mu)^2}  + C\\\\\n\\end{split}\n\\]\nNote log-likelihood function depends data \\(\\overline{(x-\\mu)^2}\\)!Log-likelihood function:\n\\[\n\\begin{split}\nl_n(\\sigma | D) & = l_n(\\mu, \\sigma^2 | D) = \\sum_{=1}^n \\log f(x_i| \\sigma^2)\\\\\n&= -\\frac{n}{2}\\log(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{=1}^n(x_i-\\mu)^2  \\underbrace{-\\frac{n}{2} \\log(2 \\pi) }_{\\text{constant depending } \\sigma^2}\\\\\n&= -\\frac{n}{2}\\log(\\sigma^2)-\\frac{n}{2\\sigma^2}  \\overline{(x-\\mu)^2}  + C\\\\\n\\end{split}\n\\]\nNote log-likelihood function depends data \\(\\overline{(x-\\mu)^2}\\)!Score function:\n\\[\nS_n(\\sigma^2) =\n-\\frac{n}{2\\sigma^2}+\\frac{n}{2\\sigma^4}    \\overline{(x-\\mu)^2}\n\\]\nNote obtain score function derivative needs taken regard variance parameter \\(\\sigma^2\\) — regard \\(\\sigma\\)! trick, relabel \\(\\sigma^2 = v\\) log-likelihood function, take derivative regard \\(v\\), backsubstitute \\(v=\\sigma^2\\) final result.Score function:\n\\[\nS_n(\\sigma^2) =\n-\\frac{n}{2\\sigma^2}+\\frac{n}{2\\sigma^4}    \\overline{(x-\\mu)^2}\n\\]Note obtain score function derivative needs taken regard variance parameter \\(\\sigma^2\\) — regard \\(\\sigma\\)! trick, relabel \\(\\sigma^2 = v\\) log-likelihood function, take derivative regard \\(v\\), backsubstitute \\(v=\\sigma^2\\) final result.Maximum likelihood estimate:\n\\[\nS_n(\\widehat{\\sigma^2}_{ML})=0 \\Rightarrow\n\\]\n\\[\n\\widehat{\\sigma^2}_{ML}\n=\\overline{(x-\\mu)^2} = \\frac{1}{n}\\sum_{=1}^n (x_i-\\mu)^2\n\\]Maximum likelihood estimate:\n\\[\nS_n(\\widehat{\\sigma^2}_{ML})=0 \\Rightarrow\n\\]\n\\[\n\\widehat{\\sigma^2}_{ML}\n=\\overline{(x-\\mu)^2} = \\frac{1}{n}\\sum_{=1}^n (x_i-\\mu)^2\n\\]confirm actually maximum need verify \nsecond derivative log-likelihood optimum negative. \\(\\frac{dS_n(\\sigma^2)}{d\\sigma^2} = -\\frac{n}{2\\sigma^4} \\left(\\frac{2}{\\sigma^2} \\overline{(x-\\mu)^2} -1\\right)\\)\nhence \\(\\frac{dS_n( \\widehat{\\sigma^2}_{ML} )}{d\\sigma^2} = -\\frac{n}{2} \\left(\\widehat{\\sigma^2}_{ML} \\right)^{-2}<0\\)\noptimum indeed maximum.confirm actually maximum need verify \nsecond derivative log-likelihood optimum negative. \\(\\frac{dS_n(\\sigma^2)}{d\\sigma^2} = -\\frac{n}{2\\sigma^4} \\left(\\frac{2}{\\sigma^2} \\overline{(x-\\mu)^2} -1\\right)\\)\nhence \\(\\frac{dS_n( \\widehat{\\sigma^2}_{ML} )}{d\\sigma^2} = -\\frac{n}{2} \\left(\\widehat{\\sigma^2}_{ML} \\right)^{-2}<0\\)\noptimum indeed maximum.","code":""},{"path":"maximum-likelihood-estimation.html","id":"likelihood-estimation-for-multiple-parameters","chapter":"3 Maximum likelihood estimation","heading":"3.2.2 Likelihood estimation for multiple parameters","text":"several parameters likelihood estimation conceptually\ndifferent case single parameter. However, \nscore function now vector-valued second derivative log-likelihood matrix-valued function.Example 3.4  Normal distribution mean variance unknown:\\(x \\sim N(\\mu,\\sigma^2)\\) \\(\\text{E}(x)=\\mu\\) \\(\\text{Var}(x) = \\sigma^2\\)\\(\\mu\\) \\(\\sigma^2\\) need estimated.’s MLE parameter vector \\(\\boldsymbol \\theta= (\\mu,\\sigma^2)^T\\)?data \\(D= \\{x_1, \\ldots, x_n\\}\\) real range \\(x_i \\[-\\infty, \\infty]\\).data \\(D= \\{x_1, \\ldots, x_n\\}\\) real range \\(x_i \\[-\\infty, \\infty]\\).average \\(\\bar{x} = \\frac{1}{n} \\sum_{=1}^n x_i\\) real well.average \\(\\bar{x} = \\frac{1}{n} \\sum_{=1}^n x_i\\) real well.average squared data \\(\\overline{x^2} = \\frac{1}{n} \\sum_{=1}^n x_i^2 \\geq 0\\) non-negative.average squared data \\(\\overline{x^2} = \\frac{1}{n} \\sum_{=1}^n x_i^2 \\geq 0\\) non-negative.Density: \\[ f(x| \\mu, \\sigma^2)=(2\\pi\\sigma^2)^{-\\frac{1}{2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\]Density: \\[ f(x| \\mu, \\sigma^2)=(2\\pi\\sigma^2)^{-\\frac{1}{2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\]Log-Density:\n\\[\\log f(x | \\mu, \\sigma^2) =-\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2}\\]Log-Density:\n\\[\\log f(x | \\mu, \\sigma^2) =-\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2}\\]Log-likelihood function:\n\\[\n\\begin{split}\nl_n(\\boldsymbol \\theta| D) & = l_n(\\mu, \\sigma^2 | D) = \\sum_{=1}^n \\log f(x_i| \\mu, \\sigma^2)\\\\\n&= -\\frac{n}{2}\\log(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{=1}^n(x_i-\\mu)^2  \\underbrace{-\\frac{n}{2} \\log(2 \\pi) }_{\\text{constant depending }\\mu \\text{ } \\sigma^2}\\\\\n&= -\\frac{n}{2}\\log(\\sigma^2)-\\frac{n}{2\\sigma^2}  ( \\overline{x^2} -2 \\bar{x} \\mu + \\mu^2)  + C\\\\\n\\end{split}\n\\]\nNote log-likelihood function depends data \\(\\bar{x}\\)\n\\(\\overline{x^2}\\)!Log-likelihood function:\n\\[\n\\begin{split}\nl_n(\\boldsymbol \\theta| D) & = l_n(\\mu, \\sigma^2 | D) = \\sum_{=1}^n \\log f(x_i| \\mu, \\sigma^2)\\\\\n&= -\\frac{n}{2}\\log(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{=1}^n(x_i-\\mu)^2  \\underbrace{-\\frac{n}{2} \\log(2 \\pi) }_{\\text{constant depending }\\mu \\text{ } \\sigma^2}\\\\\n&= -\\frac{n}{2}\\log(\\sigma^2)-\\frac{n}{2\\sigma^2}  ( \\overline{x^2} -2 \\bar{x} \\mu + \\mu^2)  + C\\\\\n\\end{split}\n\\]\nNote log-likelihood function depends data \\(\\bar{x}\\)\n\\(\\overline{x^2}\\)!Score function \\(\\boldsymbol S_n\\), gradient \\(l_n(\\boldsymbol \\theta| D)\\):\n\\[\n\\begin{split}\n\\boldsymbol S_n(\\boldsymbol \\theta) &= \\nabla l_n(\\boldsymbol \\theta| D) \\\\\n&=\n\\begin{pmatrix}\n\\frac{n}{\\sigma^2} (\\bar{x}-\\mu) \\\\\n-\\frac{n}{2\\sigma^2}+\\frac{n}{2\\sigma^4}   \\left( \\overline{x^2} - 2\\bar{x} \\mu +\\mu^2 \\right)  \\\\\n\\end{pmatrix}\\\\\n\\end{split}\n\\]Score function \\(\\boldsymbol S_n\\), gradient \\(l_n(\\boldsymbol \\theta| D)\\):\n\\[\n\\begin{split}\n\\boldsymbol S_n(\\boldsymbol \\theta) &= \\nabla l_n(\\boldsymbol \\theta| D) \\\\\n&=\n\\begin{pmatrix}\n\\frac{n}{\\sigma^2} (\\bar{x}-\\mu) \\\\\n-\\frac{n}{2\\sigma^2}+\\frac{n}{2\\sigma^4}   \\left( \\overline{x^2} - 2\\bar{x} \\mu +\\mu^2 \\right)  \\\\\n\\end{pmatrix}\\\\\n\\end{split}\n\\]Maximum likelihood estimate:\n\\[\n\\boldsymbol S_n(\\hat{\\boldsymbol \\theta}_{ML})=0 \\Rightarrow\n\\]\n\\[\n\\hat{\\boldsymbol \\theta}_{ML}=\n\\begin{pmatrix}\n\\hat{\\mu}_{ML}  \\\\\n\\widehat{\\sigma^2}_{ML} \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\bar{x} \\\\\n\\overline{x^2} -\\bar{x}^2\\\\\n\\end{pmatrix}\n\\]\nML estimate variance can also written\n\\(\\widehat{\\sigma^2}_{ML} = \\overline{x^2} -\\bar{x}^2 =\\overline{(x-\\bar{x})^2} =  \\frac{1}{n}\\sum_{=1}^n (x_i-\\bar{x})^2\\).Maximum likelihood estimate:\n\\[\n\\boldsymbol S_n(\\hat{\\boldsymbol \\theta}_{ML})=0 \\Rightarrow\n\\]\n\\[\n\\hat{\\boldsymbol \\theta}_{ML}=\n\\begin{pmatrix}\n\\hat{\\mu}_{ML}  \\\\\n\\widehat{\\sigma^2}_{ML} \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\bar{x} \\\\\n\\overline{x^2} -\\bar{x}^2\\\\\n\\end{pmatrix}\n\\]\nML estimate variance can also written\n\\(\\widehat{\\sigma^2}_{ML} = \\overline{x^2} -\\bar{x}^2 =\\overline{(x-\\bar{x})^2} =  \\frac{1}{n}\\sum_{=1}^n (x_i-\\bar{x})^2\\).confirm actually maximum need verify eigenvalues\nHessian matrix optimum negative. indeed case, \ndetails see Example 3.7.confirm actually maximum need verify eigenvalues\nHessian matrix optimum negative. indeed case, \ndetails see Example 3.7.","code":""},{"path":"maximum-likelihood-estimation.html","id":"relationship-of-maximum-likelihood-with-least-squares-estimation","chapter":"3 Maximum likelihood estimation","heading":"3.2.3 Relationship of maximum likelihood with least squares estimation","text":"Example 3.2\nform log-likelihood function\nfunction sum squared differences. Maximising \\(l_n(\\mu| D) =-\\frac{1}{2\\sigma^2}\\sum_{=1}^n(x_i-\\mu)^2\\) equivalent minimising \\(\\sum_{=1}^n(x_i-\\mu)^2\\). Hence, finding mean maximum likelihood assuming normal model equivalent least-squares estimation!Note least-squares estimation use least since early 1800s 4 thus predates maximum likelihood (1922). Due simplicity still popular particular regression link maximum likelihood normality allows understand usually works well!","code":""},{"path":"maximum-likelihood-estimation.html","id":"bias-and-maximum-likelihood-estimates","chapter":"3 Maximum likelihood estimation","heading":"3.2.4 Bias and maximum likelihood estimates","text":"Example 3.4 interesting shows maximum likelihood can result biased well unbiased estimators.Recall \\(x \\sim N(\\mu, \\sigma^2)\\). result\n\\[\\hat{\\mu}_{ML}=\\bar{x} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\]\n\\(\\text{E}( \\hat{\\mu}_{ML} ) = \\mu\\)\n\n\\[\n\\widehat{\\sigma^2}_{\\text{ML}} \\sim\nW_1\\left(s^2 = \\frac{\\sigma^2}{n}, k=n-1\\right)\n\\]\n(see Appendix) mean \\(\\text{E}(\\widehat{\\sigma^2}_{ML}) = \\frac{n-1}{n} \\, \\sigma^2\\).Therefore, MLE \\(\\mu\\) unbiased \\[\n\\text{Bias}(\\hat{\\mu}_{ML}) = \\text{E}( \\hat{\\mu}_{ML} ) - \\mu = 0\n\\]\ncontrast, however, MLE \\(\\sigma^2\\) negatively biased \n\\[\n\\text{Bias}(\\widehat{\\sigma^2}_{ML}) = \\text{E}( \\widehat{\\sigma^2}_{ML} ) - \\sigma^2 = -\\frac{1}{n} \\, \\sigma^2\n\\]Thus, case variance parameter normal distribution MLE recovering well-known unbiased estimator variance\\[\n\\widehat{\\sigma^2}_{UB} = \\frac{1}{n-1}\\sum_{=1}^n(x_i-\\bar{x})^2 = \\frac{n}{n-1} \\widehat{\\sigma^2}_{ML}\n\\]\nwords, unbiased variance estimate maximum likelihood estimate!Therefore worth keeping mind maximum likelihood can result biased estimates finite \\(n\\).\nlarge \\(n\\), however, bias disappears MLEs consistent.","code":""},{"path":"maximum-likelihood-estimation.html","id":"observed-fisher-information","chapter":"3 Maximum likelihood estimation","heading":"3.3 Observed Fisher information","text":"","code":""},{"path":"maximum-likelihood-estimation.html","id":"motivation-and-definition","chapter":"3 Maximum likelihood estimation","heading":"3.3.1 Motivation and definition","text":"inspection log-likelihood curves apparent log-likelihood function contains information parameter \\(\\boldsymbol \\theta\\) just maximum point \\(\\hat{\\boldsymbol \\theta}_{ML}\\).particular curvature log-likelihood function MLE must somehow related accuracy \\(\\hat{\\boldsymbol \\theta}_{ML}\\): likelihood surface flat near maximum\n(low curvature) difficult find optimal parameter (also numerically!). Conversely, likelihood surface peaked (strong curvature) maximum point clearly defined.curvature described second-order derivatives (Hessian matrix) log-likelihood function.univariate \\(\\theta\\) Hessian scalar:\n\\[\\frac{d^2 l_n(\\theta|D)}{d\\theta^2}\\]multivariate parameter vector \\(\\boldsymbol \\theta\\) dimension \\(d\\) Hessian matrix size \\(d \\times d\\):\n\\[\\nabla \\nabla^T l_n(\\boldsymbol \\theta| D)\\]construction Hessian negative definite MLE (.e. eigenvalues negative) ensure function concave MLE (.e. peak shaped).observed Fisher information (matrix) defined \nnegative curvature MLE \\(\\hat{\\boldsymbol \\theta}_{ML}\\):\n\\[\n{\\boldsymbol J_n}(\\hat{\\boldsymbol \\theta}_{ML}) = -\\nabla \\nabla^T l_n(\\hat{\\boldsymbol \\theta}_{ML}| D)\n\\]Sometimes simply called “observed information”.\navoid confusion expected Fisher information introduced earlier\\[\n\\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta) = -\\text{E}_{F_{\\boldsymbol \\theta}} \\left( \\nabla \\nabla^T \\log f(x|\\boldsymbol \\theta)\\right)\n\\]\nnecessary always use qualifier “observed” referring \\({\\boldsymbol J_n}(\\hat{\\boldsymbol \\theta}_{ML})\\).","code":""},{"path":"maximum-likelihood-estimation.html","id":"examples-of-observed-fisher-information","chapter":"3 Maximum likelihood estimation","heading":"3.3.2 Examples of observed Fisher information","text":"Example 3.5  Bernoulli model \\(\\text{Ber}(\\theta)\\):continue Example 3.1. Recall \n\\(\\hat{\\theta}_{ML} = \\bar{x}=\\frac{n_1}{n}\\) score function\n\\(S_n(\\theta)=n \\left( \\frac{\\bar{x} }{\\theta} - \\frac{1-\\bar{x}}{1-\\theta} \\right)\\). negative second derivative log-likelihood function \n\\[\n-\\frac{d S_n(\\theta)}{d\\theta}=n \\left( \\frac{ \\bar{x} }{\\theta^2} + \\frac{1 - \\bar{x} }{(1-\\theta)^2} \\right)\n\\]\nobserved Fisher information therefore\n\\[\n\\begin{split}\nJ_n(\\hat{\\theta}_{ML}) & = n \\left(\\frac{ \\bar{x} }{\\hat{\\theta}_{ML}^2} + \\frac{ 1 - \\bar{x} }{  (1-\\hat{\\theta}_{ML})^2  } \\right) \\\\\n  & = n \\left(\\frac{1}{\\hat{\\theta}_{ML}} + \\frac{1}{1-\\hat{\\theta}_{ML}} \\right) \\\\\n  &= \\frac{n}{\\hat{\\theta}_{ML} (1-\\hat{\\theta}_{ML})} \\\\\n\\end{split}\n\\]inverse observed Fisher information :\n\\[J_n(\\hat{\\theta}_{ML})^{-1}=\\frac{\\hat{\\theta}_{ML}(1-\\hat{\\theta}_{ML})}{n}\\]Compare \\(\\text{Var}\\left(\\frac{x}{n}\\right) = \\frac{\\theta(1-\\theta)}{n}\\) \n\\(x \\sim \\text{Bin}(n, \\theta)\\).Example 3.6  Normal distribution unknown mean known variance:continuation Example 3.2.\nRecall MLE mean\n\\(\\hat{\\mu}_{ML}=\\frac{1}{n}\\sum_{=1}^n x_i=\\bar{x}\\)\nscore function\n\\(\\boldsymbol S_n(\\mu) = \\frac{n}{\\sigma^2} (\\bar{x} -\\mu)\\).\nnegative second derivative score function \n\\[\n-\\frac{d S_n(\\mu)}{d\\mu}= \\frac{n}{\\sigma^2}\n\\]\nobserved Fisher information MLE therefore\n\\[\nJ_n(\\hat{\\mu}_{ML}) = \\frac{n}{\\sigma^2}\n\\]\ninverse observed Fisher information \n\\[\nJ_n(\\hat{\\mu}_{ML})^{-1} = \\frac{\\sigma^2}{n}\n\\]\\(x_i \\sim N(\\mu, \\sigma^2)\\) \\(\\text{Var}(x_i) = \\sigma^2\\)\nhence \\(\\text{Var}(\\bar{x}) = \\frac{\\sigma^2}{n}\\),\nequal inverse observed Fisher information.Example 3.7  Normal distribution mean variance parameter:continuation Example 3.4.\nRecall MLE mean variance:\n\\[\\hat{\\mu}_{ML}=\\frac{1}{n}\\sum_{=1}^n x_i=\\bar{x}\\]\n\\[\\widehat{\\sigma^2}_{ML} = \\frac{1}{n}\\sum_{=1}^n(x_i-\\bar{x})^2 =  \\overline{x^2} - \\bar{x}^2\\]\nscore function\n\\[\\boldsymbol S_n(\\mu,\\sigma^2)=\\nabla l_n(\\mu, \\sigma^2| D) =\n\\begin{pmatrix}\n\\frac{n}{\\sigma^2}   (\\bar{x}-\\mu) \\\\\n-\\frac{n}{2\\sigma^2}+\\frac{n}{2\\sigma^4} \\left(\\overline{x^2} - 2 \\mu \\bar{x} + \\mu^2\\right) \\\\\n\\end{pmatrix}\n\\]\nHessian matrix log-likelihood function \n\\[\\nabla \\nabla^T l_n(\\mu,\\sigma^2| D) =\n\\begin{pmatrix}\n    - \\frac{n}{\\sigma^2}&  -\\frac{n}{\\sigma^4} (\\bar{x} -\\mu)\\\\\n    - \\frac{n}{\\sigma^4} (\\bar{x} -\\mu) & \\frac{n}{2\\sigma^4}-\\frac{n}{\\sigma^6} \\left(\\overline{x^2} - 2 \\mu \\bar{x} + \\mu^2\\right) \\\\\n    \\end{pmatrix}\n\\]\nnegative Hessian MLE, .e. \\(\\hat{\\mu}_{ML} = \\bar{x}\\)\n\\(\\widehat{\\sigma^2}_{ML} = \\overline{x^2} -\\bar{x}^2\\)\nyields observed Fisher information matrix:\n\\[\n\\boldsymbol J_n(\\hat{\\mu}_{ML},\\widehat{\\sigma^2}_{ML}) = \\begin{pmatrix}\n    \\frac{n}{\\widehat{\\sigma^2}_{ML}}&0 \\\\\n    0 & \\frac{n}{2(\\widehat{\\sigma^2}_{ML})^2}\n    \\end{pmatrix}\n\\]\nNote observed Fisher information matrix diagonal\npositive entries. Therefore \neigenvalues positive required maximum, diagonal matrix eigenvalues simply \nentries diagonal.inverse observed Fisher information matrix \n\\[\n\\boldsymbol J_n(\\hat{\\mu}_{ML},\\widehat{\\sigma^2}_{ML})^{-1} = \\begin{pmatrix}\n    \\frac{\\widehat{\\sigma^2}_{ML}}{n}& 0\\\\\n    0 & \\frac{2(\\widehat{\\sigma^2}_{ML})^2}{n}\n    \\end{pmatrix}\n\\]Recall \\(x \\sim N(\\mu, \\sigma^2)\\) therefore\n\\[\\hat{\\mu}_{ML}=\\bar{x} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\]\nHence \\(\\text{Var}(\\hat{\\mu}_{ML}) = \\frac{\\sigma^2}{n}\\). compare \n\nfirst diagonal entry inverse observed Fisher information matrix see essentially expression (apart “hat”).empirical variance \\(\\widehat{\\sigma^2}_{ML}\\) follows one-dimensional Wishart distribution\n\\[\n\\widehat{\\sigma^2}_{\\text{ML}} \\sim\nW_1\\left(s^2 = \\frac{\\sigma^2}{n}, k=n-1\\right)\n\\]\n(see Appendix) variance\n\\(\\text{Var}(\\widehat{\\sigma^2}_{ML}) = \\frac{n-1}{n} \\, \\frac{2 \\sigma ^4}{n}\\). large \\(n\\) becomes \\(\\text{Var}(\\widehat{\\sigma^2}_{ML})\\overset{}{=} \\frac{2 \\sigma ^4}{n}\\) essentially (apart “hat”) second diagonal entry inverse observed Fisher information matrix.","code":""},{"path":"maximum-likelihood-estimation.html","id":"relationship-between-observed-and-expected-fisher-information","chapter":"3 Maximum likelihood estimation","heading":"3.3.3 Relationship between observed and expected Fisher information","text":"observed Fisher information \\(\\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML})\\) expected Fisher information\n\\(\\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta)\\) related also two clearly different entities:types Fisher information based computing second order derivatives\n(Hessian matrix), thus based curvature function.types Fisher information based computing second order derivatives\n(Hessian matrix), thus based curvature function.observed Fisher information computed log-likelihood function.\nTherefore takes observed data \\(D\\) account explicitly depends sample size \\(n\\). contains estimates parameters parameters . curvature log-likelihood function may computed point log-likelihood function observed Fisher information specifically refers curvature MLE \\(\\hat{\\boldsymbol \\theta}_{ML}\\). linked (asymptotic) variance MLE seen examples discuss detail later.observed Fisher information computed log-likelihood function.\nTherefore takes observed data \\(D\\) account explicitly depends sample size \\(n\\). contains estimates parameters parameters . curvature log-likelihood function may computed point log-likelihood function observed Fisher information specifically refers curvature MLE \\(\\hat{\\boldsymbol \\theta}_{ML}\\). linked (asymptotic) variance MLE seen examples discuss detail later.contrast, expected Fisher information derived directly log-density. depend observed data, thus depend sample size. can computed value parameters. describes geometry space models, local approximation relative entropy.contrast, expected Fisher information derived directly log-density. depend observed data, thus depend sample size. can computed value parameters. describes geometry space models, local approximation relative entropy.Assume large sample size \\(n\\) MLE converges \\(\\hat{\\boldsymbol \\theta}_{ML} \\rightarrow \\boldsymbol \\theta_0\\).\nfollows construction \nobserved Fisher information law large numbers asymptotically large sample size \\(\\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML}) \\rightarrow n \\boldsymbol ^{\\text{Fisher}}( \\boldsymbol \\theta_0 )\\) (.e. expected Fisher information set iid random variables, see Example 2.14).Assume large sample size \\(n\\) MLE converges \\(\\hat{\\boldsymbol \\theta}_{ML} \\rightarrow \\boldsymbol \\theta_0\\).\nfollows construction \nobserved Fisher information law large numbers asymptotically large sample size \\(\\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML}) \\rightarrow n \\boldsymbol ^{\\text{Fisher}}( \\boldsymbol \\theta_0 )\\) (.e. expected Fisher information set iid random variables, see Example 2.14).important class models, namely exponential family model, find \n\\(\\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML}) = n \\boldsymbol ^{\\text{Fisher}}( \\hat{\\boldsymbol \\theta}_{ML} )\\) valid also finite sample size \\(n\\). fact case examples discussed (e.g. see\nExamples 3.5 2.11\nBernoulli distribution Examples 3.7 2.13\nnormal distribution).important class models, namely exponential family model, find \n\\(\\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML}) = n \\boldsymbol ^{\\text{Fisher}}( \\hat{\\boldsymbol \\theta}_{ML} )\\) valid also finite sample size \\(n\\). fact case examples discussed (e.g. see\nExamples 3.5 2.11\nBernoulli distribution Examples 3.7 2.13\nnormal distribution).However, exception. general model \\(\\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML}) \\neq n \\boldsymbol ^{\\text{Fisher}}( \\hat{\\boldsymbol \\theta}_{ML} )\\)\nfinite sample size \\(n\\). example provided Cauchy distribution median parameter \\(\\theta\\). exponential family model expected Fisher information \\(^{\\text{Fisher}}(\\theta )=\\frac{1}{2}\\) regardless choice\nmedian parameter whereas observed Fisher information \\(J_n(\\hat{\\theta}_{ML})\\) depends \nMLE \\(\\hat{\\theta}_{ML}\\) median parameter simply \\(\\frac{n}{2}\\).However, exception. general model \\(\\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML}) \\neq n \\boldsymbol ^{\\text{Fisher}}( \\hat{\\boldsymbol \\theta}_{ML} )\\)\nfinite sample size \\(n\\). example provided Cauchy distribution median parameter \\(\\theta\\). exponential family model expected Fisher information \\(^{\\text{Fisher}}(\\theta )=\\frac{1}{2}\\) regardless choice\nmedian parameter whereas observed Fisher information \\(J_n(\\hat{\\theta}_{ML})\\) depends \nMLE \\(\\hat{\\theta}_{ML}\\) median parameter simply \\(\\frac{n}{2}\\).","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"quadratic-approximation-and-normal-asymptotics","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4 Quadratic approximation and normal asymptotics","text":"","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"multivariate-statistics-for-random-vectors","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.1 Multivariate statistics for random vectors","text":"","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"covariance-and-correlation","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.1.1 Covariance and correlation","text":"Assume scalar random variable \\(x\\) mean \\(\\text{E}(x) = \\mu\\). corresponding variance given \n\\[\n\\begin{split}\n\\text{Var}(x) & = \\text{E}\\left((x-\\mu)^2 \\right) \\\\\n        & =\\text{E}\\left( (x-\\mu)(x-\\mu) \\right) \\\\\n        & = \\text{E}(x^2)-\\mu^2 \\\\\n\\end{split}\n\\]random vector \\(\\boldsymbol x= (x_1, x_2,...,x_d)^T\\) mean \\(\\text{E}(\\boldsymbol x) = \\boldsymbol \\mu\\) simply comprised means components, .e. \\(\\boldsymbol \\mu= (\\mu_1, \\ldots, \\mu_d)^T\\). Thus, mean random vector dimension vector length.variance random vector length \\(d\\), however, vector matrix size \\(d\\times d\\). matrix called covariance matrix:\n\\[\n\\begin{split}\n\\text{Var}(\\boldsymbol x) &= \\underbrace{\\boldsymbol \\Sigma}_{d\\times d} = (\\sigma_{ij}) = \\begin{pmatrix}\n    \\sigma_{11} & \\dots & \\sigma_{1d}\\\\\n     \\vdots & \\ddots & \\vdots \\\\\n    \\sigma_{d1} & \\dots & \\sigma_{dd}\n\\end{pmatrix} \\\\\n  &=\\text{E}\\left(\\underbrace{(\\boldsymbol x-\\boldsymbol \\mu)}_{d\\times 1} \\underbrace{(\\boldsymbol x-\\boldsymbol \\mu)^T}_{1\\times d}\\right) \\\\\n  & = \\text{E}(\\boldsymbol x\\boldsymbol x^T)-\\boldsymbol \\mu\\boldsymbol \\mu^T \\\\\n\\end{split}\n\\]\nentries covariance matrix \\(\\sigma_{ij} =\\text{Cov}(x_i, x_j)\\) describe covariance random variables \\(x_i\\) \\(x_j\\). covariance matrix symmetric, hence \\(\\sigma_{ij}=\\sigma_{ji}\\). diagonal entries \\(\\sigma_{ii} = \\text{Cov}(x_i, x_i) = \\text{Var}(x_i) = \\sigma_i^2\\) correspond variances components \\(\\boldsymbol x\\). covariance matrix positive semi-definite, .e. eigenvalues \\(\\boldsymbol \\Sigma\\) positive equal zero. However, practise one aims use non-singular covariance matrices, eigenvalues positive, invertible.covariance matrix can factorised product\n\\[\n\\boldsymbol \\Sigma= \\boldsymbol V^{\\frac{1}{2}} \\boldsymbol P\\boldsymbol V^{\\frac{1}{2}}\n\\]\n\\(\\boldsymbol V\\) diagonal matrix containing variances\n\\[\n\\boldsymbol V= \\begin{pmatrix}\n    \\sigma_{11} & \\dots & 0\\\\\n     \\vdots & \\ddots & \\vdots \\\\\n    0 & \\dots & \\sigma_{dd}\n\\end{pmatrix}\n\\]\nmatrix \\(\\boldsymbol P\\) (“upper case rho”) symmetric correlation matrix\n\\[\n\\boldsymbol P= (\\rho_{ij}) = \\begin{pmatrix}\n    1 & \\dots & \\rho_{1d}\\\\\n     \\vdots & \\ddots & \\vdots \\\\\n    \\rho_{d1} & \\dots & 1\n\\end{pmatrix}   = \\boldsymbol V^{-\\frac{1}{2}} \\boldsymbol \\Sigma\\boldsymbol V^{-\\frac{1}{2}}\n\\]\nThus, correlation \\(x_i\\) \\(x_j\\) defined \n\\[\n\\rho_{ij} = \\text{Cor}(x_i,x_j) = \\frac{\\sigma_{ij}}{\\sqrt{\\sigma_{ii}\\sigma_{jj}}}\n\\]univariate \\(x\\) scalar constant \\(\\) variance \\(x\\) equals \\(\\text{Var}(x) = ^2 \\text{Var}(x)\\). random vector \\(\\boldsymbol x\\) dimension \\(d\\) matrix \\(\\boldsymbol \\) dimension \\(m \\times d\\) generalises \\(\\text{Var}(\\boldsymbol Ax) = \\boldsymbol \\text{Var}(\\boldsymbol x) \\boldsymbol ^T\\).","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"multivariate-normal-distribution","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.1.2 Multivariate normal distribution","text":"density normally distributed scalar variable \\(x \\sim N(\\mu, \\sigma^2)\\) mean \\(\\text{E}(x) = \\mu\\) variance \\(\\text{Var}(x) = \\sigma^2\\) \n\\[\nf(x |\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2} \\right)\n\\]univariate normal distribution scalar \\(x\\) generalises multivariate normal distribution vector \\(\\boldsymbol x= (x_1, x_2,...,x_d)^T \\sim N_d(\\boldsymbol \\mu, \\boldsymbol \\Sigma)\\) mean \\(\\text{E}(\\boldsymbol x) = \\boldsymbol \\mu\\) covariance matrix \\(\\text{Var}(\\boldsymbol x) = \\boldsymbol \\Sigma\\). corresponding density \n\\[\nf(\\boldsymbol x| \\boldsymbol \\mu, \\boldsymbol \\Sigma) = (2\\pi)^{-\\frac{d}{2}} \\det(\\boldsymbol \\Sigma)^{-\\frac{1}{2}} \\exp\\left({{-\\frac{1}{2}} \\underbrace{\\underbrace{(\\boldsymbol x-\\boldsymbol \\mu)^T}_{1 \\times d} \\underbrace{\\boldsymbol \\Sigma^{-1}}_{d \\times d} \\underbrace{(\\boldsymbol x-\\boldsymbol \\mu)}_{d \\times 1} }_{1 \\times 1 = \\text{scalar!}}}\\right)\n\\]\\(d=1\\) \\(\\boldsymbol x=x\\), \\(\\boldsymbol \\mu= \\mu\\) \\(\\boldsymbol \\Sigma= \\sigma^2\\) multivariate normal density reduces univariate normal density.Example 4.1  Maximum likelihood estimates parameters multivariate normal distribution:Maximising log-likelihood based multivariate normal density yields \nMLEs \\(\\boldsymbol \\mu\\) \\(\\boldsymbol \\Sigma\\). generalisations MLEs mean \\(\\mu\\)\nvariance \\(\\sigma^2\\) univariate normal encountered Example 3.4.estimates can written three different ways:) data vector notationwith \\(\\boldsymbol x_1,\\ldots, \\boldsymbol x_n\\) \\(n\\) vector-valued observations multivariate normal:MLE mean:\n\\[\n\\hat{\\boldsymbol \\mu}_{ML} = \\frac{1}{n}\\sum^{n}_{k=1} \\boldsymbol x_k = \\bar{\\boldsymbol x}\n\\]MLE covariance:\n\\[\\underbrace{\\widehat{\\boldsymbol \\Sigma}_{ML}}_{d \\times d} = \\frac{1}{n}\\sum^{n}_{k=1} \\underbrace{\\left(\\boldsymbol x_k-\\bar{\\boldsymbol x}\\right)}_{d \\times 1} \\; \\underbrace{\\left(\\boldsymbol x_k-\\bar{\\boldsymbol x}\\right)^T}_{1 \\times d}\\]\nNote factor \\(\\frac{1}{n}\\) estimator covariance matrix.\\(\\overline{\\boldsymbol x\\boldsymbol x^T} = \\frac{1}{n}\\sum^{n}_{k=1} \\boldsymbol x_k \\boldsymbol x_k^T\\)\ncan also write\n\\[\n\\widehat{\\boldsymbol \\Sigma}_{ML} = \\overline{\\boldsymbol x\\boldsymbol x^T} - \\bar{\\boldsymbol x} \\bar{\\boldsymbol x}^T\n\\]b) data component notationwith \\(x_{ki}\\) \\(\\)-th component \\(k\\)-th sample \\(\\boldsymbol x_k\\):\\[\\hat{\\mu}_i = \\frac{1}{n}\\sum^{n}_{k=1} x_{ki} \\text{ }\n\\hat{\\boldsymbol \\mu}=\\begin{pmatrix}\n    \\hat{\\mu}_{1}       \\\\\n    \\vdots \\\\\n    \\hat{\\mu}_{d}\n\\end{pmatrix}\\]\\[\\hat{\\sigma}_{ij} = \\frac{1}{n}\\sum^{n}_{k=1} \\left(x_{ki}-\\hat{\\mu}_i\\right) (\\\nx_{kj}-\\hat{\\mu}_j) \\text{ } \\widehat{\\boldsymbol \\Sigma} = (\\hat{\\sigma}_{ij})\n\\]c) data matrix notationwith \\(\\boldsymbol X= \\begin{pmatrix} \\boldsymbol x_1^T \\\\ ... \\\\ \\boldsymbol x_n^T \\\\\\end{pmatrix}\\) data matrix containing samples rows. Note statistics convention — much engineering computer science literature data matrix often transposed samples stored columns. Thus, formulas correct assuming statistics convention.\\[\n\\hat{\\boldsymbol \\mu} = \\frac{1}{n} \\boldsymbol X^T \\boldsymbol 1_n\n\\]\n\\(\\boldsymbol 1_n\\) vector length \\(n\\) containing 1 component.\\[\n\\hat{\\boldsymbol \\Sigma} = \\frac{1}{n} \\boldsymbol X^T \\boldsymbol X- \\hat{\\boldsymbol \\mu} \\hat{\\boldsymbol \\mu}^T\n\\]\nsimplify expression estimate covariance matrix\none often assumes data matrix centered, .e. \\(\\hat{\\boldsymbol \\mu} = 0\\).ambiguity convention (machine learning versus statistics convention) often implicit use\ncentered data matrices matrix notation often source confusion. Hence, using two\nnotations generally preferable.","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"approximate-distribution-of-maximum-likelihood-estimates","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.2 Approximate distribution of maximum likelihood estimates","text":"","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"quadratic-log-likelihood-resulting-from-normal-model","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.2.1 Quadratic log-likelihood resulting from normal model","text":"Assume observe single sample \\(\\boldsymbol x\\sim N(\\boldsymbol \\mu, \\boldsymbol \\Sigma^2)\\) known covariance. corresponding log-likelihood \\(\\boldsymbol \\mu\\) \n\\[\nl_1(\\boldsymbol \\mu| \\boldsymbol x) = C - \\frac{1}{2}(\\boldsymbol x-\\boldsymbol \\mu)^T \\boldsymbol \\Sigma^{-1} (\\boldsymbol x-\\boldsymbol \\mu)\n\\]\n\\(C\\) constant depend \\(\\boldsymbol \\mu\\).\nNote log-likelihood exactly quadratic maximum lies\n\\((\\boldsymbol x, C)\\).","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"quadratic-approximation-of-a-log-likelihood-function","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.2.2 Quadratic approximation of a log-likelihood function","text":"Now consider quadratic approximation log-likelihood function \\(l_n(\\boldsymbol \\theta| D)\\) \naround MLE \\(\\hat{\\boldsymbol \\theta}_{ML}\\).assume underlying model regular \n\\(\\nabla l_n(\\hat{\\boldsymbol \\theta}_{ML} | D) = 0\\).Taylor series approximation scalar-valued function \\(f(\\boldsymbol x)\\) around \\(\\boldsymbol x_0\\) \n\\[\nf(\\boldsymbol x) = f(\\boldsymbol x_0) + \\nabla f(\\boldsymbol x_0)^T (\\boldsymbol x-\\boldsymbol x_0) + \\frac{1}{2}\n(\\boldsymbol x-\\boldsymbol x_0)^T \\nabla \\nabla^T f(\\boldsymbol x_0) (\\boldsymbol x-\\boldsymbol x_0) + \\ldots\n\\]\nApplied log-likelihood function yields\\[l_n(\\boldsymbol \\theta| D) \\approx l_n(\\hat{\\boldsymbol \\theta}_{ML} | D)- \\frac{1}{2}(\\hat{\\boldsymbol \\theta}_{ML}- \\boldsymbol \\theta)^T J_n(\\hat{\\boldsymbol \\theta}_{ML})(\\hat{\\boldsymbol \\theta}_{ML}-\\boldsymbol \\theta)\\]quadratic function maximum \\(( \\hat{\\boldsymbol \\theta}_{ML}, l_n(\\hat{\\boldsymbol \\theta}_{ML} | D) )\\).\nNote natural appearance\nobserved Fisher information \\(J_n(\\hat{\\boldsymbol \\theta}_{ML})\\) quadratic term.\nlinear term vanishing gradient MLE.Crucially, realise approximation form \\(\\hat{\\boldsymbol \\theta}_{ML}\\) sample\nmultivariate normal distribution mean \\(\\boldsymbol \\theta\\) covariance given inverse\nobserved Fisher information! Note requires positive definite observed\nFisher information matrix \\(J_n(\\hat{\\boldsymbol \\theta}_{ML})\\) actually invertible!Example 4.2  Quadratic approximation log-likelihood proportion:Example 3.1 log-likelihood\n\\[\nl_n(p | D) = n \\left( \\bar{x} \\log p + (1-\\bar{x}) \\log(1-p) \\right)\n\\]\nMLE\n\\[\n\\hat{p}_{ML} = \\bar{x}\n\\]\nExample 3.5 observed Fisher information\n\\[\n\\begin{split}\nJ_n(\\hat{p}_{ML}) = \\frac{n}{\\bar{x} (1-\\bar{x})}\n\\end{split}\n\\]\nlog-likelihood MLE \n\\[\nl_n(\\hat{p}_{ML} | D) = n \\left( \\bar{x} \\log \\bar{x} + (1-\\bar{x}) \\log(1-\\bar{x}) \\right)\n\\]\nallows us construct quadratic approximation log-likelihood\naround MLE \n\\[\n\\begin{split}\nl_n(p| D) & \\approx  l_n(\\hat{p}_{ML} | D) - \\frac{1}{2} J_n(\\hat{p}_{ML}) (p-\\hat{p}_{ML})^2 \\\\\n   &= n \\left( \\bar{x} \\log \\bar{x} + (1-\\bar{x}) \\log(1-\\bar{x}) - \\frac{(p-\\bar{x})^2}{2 \\bar{x} (1-\\bar{x})}  \\right) \\\\\n&=  C + \\frac{ \\bar{x} p -\\frac{1}{2} p^2}{ \\bar{x} (1-\\bar{x})/n} \\\\\n\\end{split}\n\\]\nconstant \\(C\\) depend \\(p\\), function match approximate log-likelihood MLE corresponding original log-likelihood. \napproximate log-likelihood takes form normal log-likelihood\n(Example 3.2) one observation\n\\(\\hat{p}_{ML}=\\bar{x}\\) \\(N\\left(p, \\frac{\\bar{x} (1-\\bar{x})}{n} \\right)\\).following figure shows log-likelihood function quadratic approximation\nexample data \\(n = 30\\) \\(\\bar{x} = 0.7\\):","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"asymptotic-normality-of-maximum-likelihood-estimates","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.2.3 Asymptotic normality of maximum likelihood estimates","text":"Intuitively, makes sense associate large amount curvature log-likelihood MLE low variance MLE (conversely, low amount curvature high variance).see thatnormality implies quadratic log-likelihood,conversely, taking quadratic approximation log-likelihood implies\napproximate normality, andin quadratic approximation inverse observed Fisher information plays role covariance MLE.suggests following theorem: Asymptotically, MLE normally distributed around true parameter covariance equal inverse observed Fisher information:\\[\\hat{\\boldsymbol \\theta}_{ML} \\overset{}{\\sim}\\underbrace{N_d}_{\\text{multivariate normal}}\\left(\\underbrace{\\boldsymbol \\theta}_{\\text{mean vector}},\\underbrace{\\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML})^{-1}}_{\\text{ covariance matrix}}\\right)\\]theorem distributional properties MLEs greatly enhances usefulness method maximum likelihood. implies regular settings maximum likelihood just method obtaining point estimates also also provides estimates uncertainty.However, need clarify “asymptotic” actually means context theorem:Primarily, means sufficient sample size log-likelihood \\(l_n(\\boldsymbol \\theta)\\)\nsufficiently well approximated quadratic function around \\(\\hat{\\boldsymbol \\theta}_{ML}\\).\nbetter local quadratic approximation better normal approximation!Primarily, means sufficient sample size log-likelihood \\(l_n(\\boldsymbol \\theta)\\)\nsufficiently well approximated quadratic function around \\(\\hat{\\boldsymbol \\theta}_{ML}\\).\nbetter local quadratic approximation better normal approximation!regular model positive definite observed Fisher information matrix guaranteed large sample size \\(n \\rightarrow \\infty\\) thanks central limit theorem).regular model positive definite observed Fisher information matrix guaranteed large sample size \\(n \\rightarrow \\infty\\) thanks central limit theorem).However, \\(n\\) going infinity fact always required normal approximation hold!\nDepending particular model good local fit quadratic log-likelihood\nmay available also finite \\(n\\). trivial example, normal log-likelihood valid \\(n\\).However, \\(n\\) going infinity fact always required normal approximation hold!\nDepending particular model good local fit quadratic log-likelihood\nmay available also finite \\(n\\). trivial example, normal log-likelihood valid \\(n\\).hand, non-regular models (nondifferentiable log-likelihood MLE /singular Fisher information matrix) amount data, even \\(n\\rightarrow \\infty\\), make quadratic approximation work.hand, non-regular models (nondifferentiable log-likelihood MLE /singular Fisher information matrix) amount data, even \\(n\\rightarrow \\infty\\), make quadratic approximation work.Remarks:asymptotic normality MLEs first discussed Fisher (1925)\n5The technical details considerations worked theory locally asymptotically normal (LAN) models pioneered 1960 Lucien LeCam (1924–2000).technical details considerations worked theory locally asymptotically normal (LAN) models pioneered 1960 Lucien LeCam (1924–2000).also methods obtain higher-order (higher quadratic thus non-normal) asymptotic approximations. relate -called saddle point approximations.also methods obtain higher-order (higher quadratic thus non-normal) asymptotic approximations. relate -called saddle point approximations.","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"asymptotic-optimal-efficiency","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.2.4 Asymptotic optimal efficiency","text":"Assume now \\(\\hat{\\boldsymbol \\theta}\\) arbitrary unbiased estimator \\(\\boldsymbol \\theta\\) \nunderlying data generating model regular density \\(f(\\boldsymbol x| \\boldsymbol \\theta)\\).H. Cramér (1893–1985),\nC. R. Rao (1920–)\nothers demonstrated 1945 -called information inequality,\n\\[\n\\text{Var}(\\hat{\\boldsymbol \\theta}) \\geq \\frac{1}{n} \\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta)^{-1}\n\\]\nputs lower bound variance estimator \\(\\boldsymbol \\theta\\).\n(Note \\(d>1\\) matrix inequality, meaning difference matrix positive semidefinite).large sample size \\(n \\rightarrow \\infty\\) \\(\\hat{\\boldsymbol \\theta}_{ML} \\rightarrow \\boldsymbol \\theta\\) observed\nFisher information becomes\n\\(J_n(\\hat{\\boldsymbol \\theta}) \\rightarrow n \\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta)\\)\ntherefore can write asymptotic distribution \\(\\hat{\\boldsymbol \\theta}_{ML}\\) \n\\[\n\\hat{\\boldsymbol \\theta}_{ML} \\overset{}{\\sim} N_d\\left(  \\boldsymbol \\theta,  \\frac{1}{n} \\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta)^{-1}  \\right)\n\\]\nmeans large \\(n\\) regular models \\(\\hat{\\boldsymbol \\theta}_{ML}\\) achieves lowest variance possible according Cramér-Rao information inequality. words, large sample size maximum likelihood optimally efficient thus best available estimator fact MLE!However, see later hold small sample size indeed possible (necessary) improve MLE (e.g. via Bayesian estimation regularisation).","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"quantifying-the-uncertainty-of-maximum-likelihood-estimates","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.3 Quantifying the uncertainty of maximum likelihood estimates","text":"","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"estimating-the-variance-of-mles","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.3.1 Estimating the variance of MLEs","text":"previous section saw MLEs asymptotically normally distributed,\ninverse Fisher information (expected observed) linked asymptotic variance.leads question whether use observed Fisher information\n\\(J_n(\\hat{\\boldsymbol \\theta}_{ML})\\) expected Fisher information MLE\n\\(n \\boldsymbol ^{\\text{Fisher}}( \\hat{\\boldsymbol \\theta}_{ML} )\\) estimate variance MLE?Clearly, \\(n\\rightarrow \\infty\\) can used interchangeably.However, can different finite \\(n\\)\nparticular models exponential families.Also normality may occur well \\(n\\) goes \\(\\infty\\).Therefore one needs choose two, considering also thatthe expected Fisher information MLE average curvature MLE,\nwhereas observed Fisher information actual observed curvature, andthe observed Fisher information naturally occurs quadratic approximation log-likelihood., observed Fisher information estimator variance appropriate\nbased actual observed data also works large \\(n\\) (case yields\nresult using expected Fisher information):\n\\[\n\\widehat{\\text{Var}}(\\hat{\\boldsymbol \\theta}_{ML}) = \\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML})^{-1}\n\\]\nsquare-root estimate standard deviation\n\\[\n\\widehat{\\text{SD}}(\\hat{\\boldsymbol \\theta}_{ML}) = \\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML})^{-1/2}\n\\]\nNote use matrix inversion (inverse) matrix square root.reasons preferring observed Fisher information made mathematically precise classic paper \nEfron Hinkley (1978) 6 .Example 4.3  Estimated variance distribution MLE proportion:Examples 3.1 3.5\nknow MLE\n\\[\n\\hat{p}_{ML} = \\bar{x} = \\frac{k}{n}\n\\]\ncorresponding observed Fisher information\n\\[\nJ_n(\\hat{p}_{ML})=\\frac{n}{\\hat{p}_{ML}(1-\\hat{p}_{ML})}\n\\]\nestimated variance MLE therefore\n\\[\n\\widehat{\\text{Var}}(   \\hat{p}_{ML}  ) = \\frac{\\hat{p}_{ML}(1-\\hat{p}_{ML})}{n}\n\\]\ncorresponding asymptotic normal distribution \n\\[\n\\hat{p}_{ML} \\overset{}{\\sim} N\\left(p,   \\frac{\\hat{p}_{ML}(1-\\hat{p}_{ML})}{n}   \\right)\n\\]Example 4.4  Estimated variance distribution MLE mean parameter normal distribution known variance:Examples 3.2 3.6 know \n\\[\\hat{\\mu}_{ML} =\\bar{x}\\]\ncorresponding observed Fisher information \\(\\hat{\\mu}_{ML}\\) \n\\[J_n(\\hat{\\mu}_{ML})=\\frac{n}{\\sigma^2}\\]estimated variance MLE therefore\n\\[\n\\widehat{\\text{Var}}(\\hat{\\mu}_{ML}) = \\frac{\\sigma^2}{n}\n\\]\ncorresponding asymptotic normal distribution \n\\[\n\\hat{\\mu}_{ML} \\sim N\\left(\\mu,\\frac{\\sigma^2}{n}\\right)\n\\]Note case distribution asymptotic exact, .e. valid\nalso small \\(n\\) (long data \\(x_i\\) actually \\(N(\\mu, \\sigma^2)\\)!).","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"wald-statistic","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.3.2 Wald statistic","text":"Centering MLE \\(\\hat{\\boldsymbol \\theta}_{ML}\\) \\(\\boldsymbol \\theta_0\\) followed \nstandardising \\(\\widehat{\\text{SD}}(\\hat{\\boldsymbol \\theta}_{ML})\\) yields Wald statistic\n(named Abraham Wald, 1902–1950):\n\\[\n\\begin{split}\n\\boldsymbol t(\\boldsymbol \\theta_0) & = \\widehat{\\text{SD}}(\\hat{\\boldsymbol \\theta}_{ML})^{-1}(\\hat{\\boldsymbol \\theta}_{ML}-\\boldsymbol \\theta_0)\\\\\n& = \\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML})^{1/2}(\\hat{\\boldsymbol \\theta}_{ML}-\\boldsymbol \\theta_0)\\\\\n\\end{split}\n\\]\nsquared Wald statistic scalar defined \n\\[\n\\begin{split}\nt(\\boldsymbol \\theta_0)^2 &= \\boldsymbol t(\\boldsymbol \\theta_0)^T \\boldsymbol t(\\boldsymbol \\theta_0) \\\\\n&=\n(\\hat{\\boldsymbol \\theta}_{ML}-\\boldsymbol \\theta_0)^T\n\\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML})\n(\\hat{\\boldsymbol \\theta}_{ML}-\\boldsymbol \\theta_0)\\\\\n\\end{split}\n\\]\nNote literature \\(\\boldsymbol t(\\boldsymbol \\theta_0)\\) \\(t(\\boldsymbol \\theta_0)^2\\) commonly referred Wald statistics. text use qualifier “squared” refer latter.now assume true underlying parameter \\(\\boldsymbol \\theta_0\\). Since MLE asymptotically normal Wald statistic\nasymptotically standard normal distributed:\n\\[\\begin{align*}\n\\begin{array}{cc}\n\\boldsymbol t(\\boldsymbol \\theta_0) \\overset{}{\\sim}\\\\\nt(\\theta_0) \\overset{}{\\sim}\\\\\n\\end{array}\n\\begin{array}{ll}\nN_d(\\boldsymbol 0_d,\\boldsymbol I_d)\\\\\nN(0,1)\\\\\n\\end{array}\n\\begin{array}{ll}\n  \\text{vector } \\boldsymbol \\theta\\\\\n  \\text{scalar } \\theta\\\\\n\\end{array}\n\\end{align*}\\]\nCorrespondingly, squared Wald statistic chi-squared distributed:\n\\[\\begin{align*}\n\\begin{array}{cc}\nt(\\boldsymbol \\theta_0)^2 \\\\\nt(\\theta_0)^2\\\\\n\\end{array}\n\\begin{array}{ll}\n\\overset{}{\\sim}\\chi^2_d\\\\\n\\overset{}{\\sim}\\chi^2_1\\\\\n\\end{array}\n\\begin{array}{ll}\n  \\text{vector } \\boldsymbol \\theta\\\\\n  \\text{scalar } \\theta\\\\\n\\end{array}\n\\end{align*}\\]\ndegree freedom chi-squared distribution dimension \\(d\\)\nparameter vector \\(\\boldsymbol \\theta\\).Example 4.5  Wald statistic proportion:continue Example 4.3.\n\\(\\hat{p}_{ML} = \\bar{x}\\)\n\n\\(\\widehat{\\text{Var}}( \\hat{p}_{ML} ) = \\frac{\\hat{p}_{ML}(1-\\hat{p}_{ML})}{n}\\)\nthus \\(\\widehat{\\text{SD}}( \\hat{p}_{ML} ) =\\sqrt{ \\frac{\\hat{p}_{ML}(1-\\hat{p}_{ML})}{n} }\\)\nget Wald statistic:\\[\nt(p_0) = \\frac{\\bar{x}-p_0}{ \\sqrt{\\bar{x}(1-\\bar{x}) / n }  }\\overset{}{\\sim} N(0,1)\n\\]squared Wald statistic :\n\\[t(p_0)^2 = n \\frac{(\\bar{x}-p_0)^2}{ \\bar{x}(1-\\bar{x})   }\\overset{}{\\sim} \\chi^2_1 \\]Example 4.6  Wald statistic mean parameter normal distribution known variance:continue Example 4.4.\n\\(\\hat{\\mu}_{ML} =\\bar{x}\\) \n\\(\\widehat{\\text{Var}}(\\hat{\\mu}_{ML}) = \\frac{\\sigma^2}{n}\\)\nthus \\(\\widehat{\\text{SD}}(\\hat{\\mu}_{ML}) = \\frac{\\sigma}{\\sqrt{n}}\\)\nget Wald statistic:\\[t(\\mu_0) = \\frac{\\bar{x}-\\mu_0}{\\sigma / \\sqrt{n}}\\sim N(0,1)\\]\nNote one sample \\(t\\)-statistic given \\(\\sigma\\).\nsquared Wald statistic :\n\\[t(\\mu_0)^2 = \\frac{(\\bar{x}-\\mu_0)^2}{\\sigma^2 / n}\\sim \\chi^2_1 \\], instance exact distribution, just asymptotic one.Using Wald statistic squared Wald statistic can test whether particular\n\\(\\mu_0\\) can rejected underlying true parameter, can also\nconstruct corresponding confidence intervals.","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"normal-confidence-intervals-using-the-wald-statistic","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.3.3 Normal confidence intervals using the Wald statistic","text":"asymptotic normality MLEs derived regular models enables us construct \ncorresponding normal confidence interval (CI):example, construct asymptotic normal CI MLE \nscalar parameter \\(\\theta\\) use MLE \\(\\hat{\\theta}_{ML}\\) estimate mean\nstandard deviation \\(\\widehat{\\text{SD}}(\\hat{\\theta}_{ML})\\) computed observed Fisher information:\\[\\text{CI}=[\\hat{\\theta}_{ML} \\pm c_{\\text{normal}} \\widehat{\\text{SD}}(\\hat{\\theta}_{ML})]\\]\\(c_{normal}\\) critical value standard-normal symmetric confidence interval\nchosen achieve desired nominal coverage-\ncritical values computed using inverse standard normal distribution function via\n\\(c_{\\text{normal}}=\\Phi^{-1}\\left(\\frac{1+\\kappa}{2}\\right)\\)\n(cf. refresher section Appendix).example, CI 95% coverage one uses factor 1.96 \n\\[\\text{CI}=[\\hat{\\theta}_{ML} \\pm 1.96\\, \\widehat{\\text{SD}}(\\hat{\\theta}_{ML}) ]\\]normal CI can expressed using Wald statistic follows:\\[\\text{CI}=\\{\\theta_0:  | t(\\theta_0)| < c_{\\text{normal}} \\}\\]Similary, can also expressed using squared Wald statistic:\\[\\text{CI}=\\{\\theta_0:   t(\\boldsymbol \\theta_0)^2 < c_{\\text{chisq}} \\}\\]\nNote form facilitates construction normal confidence intervals\nparameter vector \\(\\boldsymbol \\theta_0\\).following lists containst critical values resulting chi-squared distribution\ndegree freedom \\(m=1\\) three common choices \ncoverage \\(\\kappa\\) normal CI univariate parameter:Example 4.7  Asymptotic normal confidence interval proportion:continue Examples 4.3 4.5.\nAssume observe \\(n=30\\) measurements average \\(\\bar{x} = 0.7\\).\n\\(\\hat{p}_{ML} = \\bar{x} = 0.7\\) \n\\(\\widehat{\\text{SD}}(\\hat{p}_{ML}) = \\sqrt{ \\frac{ \\bar{x}(1-\\bar{x})}{n} } \\approx 0.084\\).symmetric asymptotic normal CI \\(p\\) 95% coverage given \n\\(\\hat{p}_{ML} \\pm 1.96 \\, \\widehat{\\text{SD}}(\\hat{p}_{ML})\\) present data results interval \\([0.536, 0.864]\\).Example 4.8  Normal confidence interval mean:continue Examples 4.4 4.6.\nAssume observe \\(n=25\\) measurements average \\(\\bar{x} = 10\\), normal\nunknown mean variance \\(\\sigma^2=4\\).\\(\\hat{\\mu}_{ML} = \\bar{x} = 10\\) \n\\(\\widehat{\\text{SD}}(\\hat{\\mu}_{ML}) = \\sqrt{ \\frac{ \\sigma^2}{n} } = \\frac{2}{5}\\).symmetric asymptotic normal CI \\(p\\) 95% coverage given \n\\(\\hat{\\mu}_{ML} \\pm 1.96 \\, \\widehat{\\text{SD}}(\\hat{\\mu}_{ML})\\) present data results interval \\([9.216, 10.784]\\).","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"normal-tests-using-the-wald-statistic","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.3.4 Normal tests using the Wald statistic","text":"Finally, recall duality confidence intervals statistical tests. Specifically,\nconfidence interval coverage \\(\\kappa\\) can also used testing follows.every \\(\\theta_0\\) inside CI data allow reject hypothesis \\(\\theta_0\\) true parameter significance level \\(1-\\kappa\\).Conversely, values \\(\\theta_0\\) outside CI can rejected true parameter significance level \\(1-\\kappa\\) .Hence, order test whether \\(\\boldsymbol \\theta_0\\) true underlying parameter value can\ncompute corresponding (squared) Wald statistic, find desired critical\nvalue decide rejection.Example 4.9  Asymptotic normal test proportion:continue Example 4.7.now consider two possible values (\\(p_0=0.5\\) \\(p_0=0.8\\)) potentially true underlying proportion.value \\(p_0=0.8\\) lies inside 95% confidence interval \\([0.536, 0.864]\\). implies reject hypthesis true underlying parameter 5% significance\nlevel. contrast, \\(p_0=0.5\\) outside \nconfidence interval can indeed reject value. words, data plus model\nexclude value statistically implausible.can verified directly computing corresponding (squared) Wald statistics\n(see Example 4.5) comparing relevant critical value (3.84 chi-squared distribution 5% significance level):\\(t(0.5)^2 = \\frac{(0.7-0.5)^2}{0.084^2} = 5.71 > 3.84\\) hence \\(p_0=0.5\\) can rejected.\\(t(0.8)^2 = \\frac{(0.7-0.8)^2}{0.084^2} = 1.43 < 3.84\\) hence \\(p_0=0.8\\) rejected.Note squared Wald statistic boundaries normal confidence interval\nequal critical value.Example 4.10  Normal confidence interval test mean:continue Example 4.8.now consider two possible values (\\(\\mu_0=9.5\\) \\(\\mu_0=11\\)) potentially true underlying mean parameter.value \\(\\mu_0=9.5\\) lies inside 95% confidence interval \\([9.216, 10.784]\\). implies reject hypthesis true underlying parameter 5% significance\nlevel. contrast, \\(\\mu_0=11\\) outside \nconfidence interval can indeed reject value. words, data plus model\nexclude value statistically implausible.can verified directly computing corresponding (squared) Wald statistics\n(see Example 4.6) comparing relevant critical values:\\(t(9.5)^2 = \\frac{(10-9.5)^2}{4/25}= 1.56 < 3.84\\) hence \\(\\mu_0=9.5\\) rejected.\\(t(11)^2 = \\frac{(10-11)^2}{4/25} = 6.25 > 3.84\\) hence \\(\\mu_0=11\\) can rejected.squared Wald statistic boundaries confidence interval\nequals critical value.Note standard one-sample test mean, exact,\napproximation.","code":""},{"path":"quadratic-approximation-and-normal-asymptotics.html","id":"example-of-a-non-regular-model","chapter":"4 Quadratic approximation and normal asymptotics","heading":"4.4 Example of a non-regular model","text":"models allow quadratic approximation log-likelihood function around MLE. case log-likelihood function differentiable MLE. models called non-regular models normal approximation available.Example 4.11  Uniform distribution upper bound \\(\\theta\\):\n\\[x_1,\\dots,x_n \\sim U(0,\\theta)\\]\n\\(x_{[]}\\) denote ordered observations \n\\(0 \\leq x_{[1]} < x_{[2]} < \\ldots < x_{[n]} \\leq \\theta\\) \n\\(x_{[n]} = \\max(x_1,\\dots,x_n)\\).like obtain maximum likelihood estimator\n\\(\\hat{\\theta}_{ML}\\) distribution.probability density function \\(U(0,\\theta)\\) \n\\[f(x|\\theta) =\\begin{cases}\n    \\frac{1}{\\theta} &\\text{} x \\[0,\\theta] \\\\\n    0              & \\text{otherwise.}\n\\end{cases}\n\\]\n\nlog-scale\n\\[\n\\log f(x|\\theta) =\\begin{cases}\n    - \\log \\theta &\\text{} x \\[0,\\theta] \\\\\n    - \\infty              & \\text{otherwise.}\n\\end{cases}\n\\]Since observed data \\(D =\\{x_1, \\ldots, x_n\\}\\) lie interval \\([0,\\theta]\\)\nget log-likelihood function\n\\[\nl_n(\\theta| D) =\\begin{cases}\n    -n\\log \\theta  &\\text{} x_{[n]} \\leq \\theta \\\\\n    - \\infty              & \\text{otherwise}\n\\end{cases}\n\\]Obtaining MLE \\(\\theta\\) straightforward: \\(-n\\log \\theta\\) monotonically decreasing \\(\\theta\\)\n\\(\\theta \\geq x_{[n]}\\) hence log-likelihood function maximum \\(\\hat{\\theta}_{ML}=x_{[n]}\\).However, discontinuity \\(l_n(\\theta| D)\\) \\(x_{[n]}\\) therefore\n\\(l_n(\\theta| D)\\) differentiable \\(\\hat{\\theta}_{ML}\\).\nThus, quadratic approximation around \\(\\hat{\\theta}_{ML}\\)\nobserved Fisher information computed.\nHence, normal approximation distribution \\(\\hat{\\theta}_{ML}\\) valid regardless sample size, .e. even asymptotically \\(n \\rightarrow \\infty\\).Nonetheless, can fact still obtain sampling distribution \\(\\hat{\\theta}_{ML}=x_{[n]}\\). However, via asymptotic arguments instead understanding \\(x_{[n]}\\) order statistic (see https://en.wikipedia.org/wiki/Order_statistic ) following properties:\n\\[\\begin{align*}\n\\begin{array}{cc}\nx_{[n]}\\sim \\theta \\, \\text{Beta}(n,1)\\\\\n\\\\\n\\text{E}(x_{[n]})=\\frac{n}{n+1} \\theta\\\\\n\\\\\n\\text{Var}(x_{[n]})=\\frac{n}{(n+1)^2(n+2)}\\theta^2\\\\\n\\end{array}\n\\begin{array}{ll}\n\\text{\"n-th order statistic\" }\\\\\n\\\\\n\\\\\n\\\\\n\\approx \\frac{\\theta^2}{n^2}\\\\\n\\end{array}\n\\end{align*}\\]Note variance decreases \\(\\frac{1}{n^2}\\) much faster usual \\(\\frac{1}{n}\\) “efficient” estimator. Correspondingly,\n\\(\\hat{\\theta}_{ML}\\) -called “super efficient” estimator.","code":""},{"path":"likelihood-based-confidence-interval-and-likelihood-ratio.html","id":"likelihood-based-confidence-interval-and-likelihood-ratio","chapter":"5 Likelihood-based confidence interval and likelihood ratio","heading":"5 Likelihood-based confidence interval and likelihood ratio","text":"","code":""},{"path":"likelihood-based-confidence-interval-and-likelihood-ratio.html","id":"likelihood-based-confidence-intervals-and-wilks-statistic","chapter":"5 Likelihood-based confidence interval and likelihood ratio","heading":"5.1 Likelihood-based confidence intervals and Wilks statistic","text":"","code":""},{"path":"likelihood-based-confidence-interval-and-likelihood-ratio.html","id":"general-idea-and-definition-of-wilks-statistic","chapter":"5 Likelihood-based confidence interval and likelihood ratio","heading":"5.1.1 General idea and definition of Wilks statistic","text":"Instead relying normal / quadratic approximation, can also use log-likelihood directly find called likelihood confidence intervals:Idea: find \\(\\boldsymbol \\theta_0\\) log-likelihood almost good \\(l_n(\\hat{\\boldsymbol \\theta}_{ML} | D)\\).\n\\[\\text{CI}= \\{\\boldsymbol \\theta_0: l_n(\\hat{\\boldsymbol \\theta}_{ML}| D) - l_n(\\boldsymbol \\theta_0 | D) \\leq \\Delta\\}\\]\n\\(\\Delta\\) tolerated deviation maximum log-likelihood.\nsee determine suitable \\(\\Delta\\).leads naturally Wilks log likelihood ratio statistic \\(W(\\boldsymbol \\theta_0)\\) defined :\n\\[\n\\begin{split}\nW(\\boldsymbol \\theta_0) & = 2 \\log \\left(\\frac{L(\\hat{\\boldsymbol \\theta}_{ML}| D)}{L(\\boldsymbol \\theta_0| D)}\\right) \\\\\n& =2(l_n(\\hat{\\boldsymbol \\theta}_{ML}| D)-l_n(\\boldsymbol \\theta_0 |D))\\\\\n\\end{split}\n\\]\nhelp can write likelihood CI follows:\n\\[\\text{CI}= \\{\\boldsymbol \\theta_0: W(\\boldsymbol \\theta_0) \\leq 2 \\Delta\\}\\]Wilks statistic named Samuel S. Wilks (1906–1964).Advantages using likelihood-based CI:restricted symmetricenables construct multivariate CIs parameter vector easily even non-normal casescontains normal CI special caseQuestion: choose \\(\\Delta\\), .e calibrate likelihood interval?\nEssentially, comparing normal CI!Example 5.1  Wilks statistic proportion:log-likelihood parameter \\(\\theta\\) (cf. Example 3.1)\n\\[\nl_n(\\theta| D) = n ( \\bar{x} \\log \\theta + (1-\\bar{x}) \\log(1-\\theta) )\n\\]\nHence Wilks statistic \n\\[\n\\begin{split}\nW(\\theta_0) & = 2 ( l_n( \\hat{\\theta}_{ML} | D)  -l_n( \\theta_0 | D ) )\\\\\n& = 2 n \\left(  \\bar{x} \\log \\left( \\frac{  \\bar{x}  }{\\theta_0}  \\right)  \n                + (1-\\bar{x}) \\log \\left( \\frac{1-\\bar{x} }{1-\\theta_0}  \\right)  \n    \\right) \\\\\n\\end{split}\n\\]Comparing Example 2.8 see case Wilks\nstatistic essentially (apart scale factor \\(2n\\)) KL divergence two\nBernoulli distributions:\n\\[\nW(\\theta_0) =2 n D_{\\text{KL}}( \\text{Ber}( \\hat{\\theta}_{ML} ), \\text{Ber}(\\theta_0)  )\n\\]Example 5.2  Wilks statistic mean parameter normal model:Wilks statistic \n\\[\nW(\\mu_0)^2 = \\frac{(\\bar{x}-\\mu_0)^2}{\\sigma^2 / n}\n\\]See Worksheet L3 derivation\nWilks statistic directly log-likelihood function.Note squared Wald statistic discussed \nExample 4.6.Comparing Example 2.10 see case Wilks\nstatistic essentially (apart scale factor \\(2n\\)) KL divergence two\nnormal distributions different means variance equal \\(\\sigma^2\\):\n\\[\nW(p_0) =2 n D_{\\text{KL}}( N( \\hat{\\mu}_{ML}, \\sigma^2 ), N(\\mu_0, \\sigma^2)  )\n\\]","code":""},{"path":"likelihood-based-confidence-interval-and-likelihood-ratio.html","id":"quadratic-approximation-of-wilks-statistic-and-squared-wald-statistic","chapter":"5 Likelihood-based confidence interval and likelihood ratio","heading":"5.1.2 Quadratic approximation of Wilks statistic and squared Wald statistic","text":"Recall quadratic approximation log-likelihood function \\(l_n(\\boldsymbol \\theta_0| D)\\) (= second order Taylor series around MLE \\(\\hat{\\boldsymbol \\theta}_{ML}\\)):\\[l_n(\\boldsymbol \\theta_0| D)\\approx l_n(\\hat{\\boldsymbol \\theta}_{ML}| D)-\\frac{1}{2}(\\boldsymbol \\theta_0-\\hat{\\boldsymbol \\theta}_{ML})^T \\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML}) (\\boldsymbol \\theta_0-\\hat{\\boldsymbol \\theta}_{ML})\\]can approximate Wilks statistic:\n\\[\n\\begin{split}\nW(\\boldsymbol \\theta_0) & = 2(l_n(\\hat{\\boldsymbol \\theta}_{ML}| D)-l_n(\\boldsymbol \\theta_0| D))\\\\\n& \\approx (\\boldsymbol \\theta_0-\\hat{\\boldsymbol \\theta}_{ML})^T \\boldsymbol J_n(\\hat{\\boldsymbol \\theta}_{ML})(\\boldsymbol \\theta_0-\\hat{\\boldsymbol \\theta}_{ML})\\\\\n& =t(\\boldsymbol \\theta_0)^2 \\\\\n\\end{split}\n\\]Thus quadratic approximation Wilks statistic yields squared Wald statistic!Conversely, Wilks statistic can understood generalisation squared Wald statistic.Example 5.3  Quadratic approximation Wilks statistic proportion (continued Example 5.1):Taylor series second order (\\(p_0\\) around \\(\\bar{x}\\)) yields\n\\[\n\\log \\left( \\frac{  \\bar{x}  }{p_0} \\right) \\approx -\\frac{p_0-\\bar{x}}{\\bar{x}} + \\frac{ ( p_0-\\bar{x} )^2    }{2  \\bar{x}^2   }\n\\]\n\n\\[\n\\log \\left( \\frac{ 1- \\bar{x}  }{1- p_0} \\right) \\approx \\frac{p_0-\\bar{x}}{1-\\bar{x}} + \\frac{ ( p_0-\\bar{x} )^2    }{2  (1-\\bar{x})^2   }\n\\]\ncan approximate Wilks statistic proportion \n\\[\n\\begin{split}\nW(p_0) & \\approx  2 n \\left(  - (p_0-\\bar{x})  +\\frac{ ( p_0-\\bar{x} )^2    }{2  \\bar{x}  }\n+ (p_0-\\bar{x}) + \\frac{ ( p_0-\\bar{x} )^2    }{2  (1-\\bar{x}) } \\right)   \\\\\n& = n \\left(    \\frac{ ( p_0-\\bar{x} )^2    }{  \\bar{x}  } + \\frac{ ( p_0-\\bar{x} )^2    }{  (1-\\bar{x}) } \\right)  \\\\\n& = n \\left(    \\frac{ ( p_0-\\bar{x} )^2    }{  \\bar{x} (1-\\bar{x})  } \\right)   \\\\\n&= t(p_0)^2 \\,.\n\\end{split}\n\\]\nverifies quadratic approximation Wilks statistic leads\nback squared Wald statistic Example 4.5.Example 5.4  Quadratic approximation Wilks statistic mean parameter normal model\n(continued Example 5.2):normal log-likelihood already quadratic mean parameter (cf. Example 3.2).\nCorrespondingly, Wilks statistic quadratic mean parameter well.\nHence particular case quadratic “approximation” fact exact\nWilks statistic squared Wald statistic identical!Correspondingly, confidence intervals tests based Wilks statistic\nidentical obtained using Wald statistic.","code":""},{"path":"likelihood-based-confidence-interval-and-likelihood-ratio.html","id":"distribution-of-the-wilks-statistic","chapter":"5 Likelihood-based confidence interval and likelihood ratio","heading":"5.1.3 Distribution of the Wilks statistic","text":"connection squared Wald statistic implies asympotically \ndistribution.Hence, \\(\\boldsymbol \\theta_0\\) Wilks statistic distributed asymptotically \n\\[W(\\boldsymbol \\theta_0) \\overset{}{\\sim} \\chi^2_d\\]\n\\(d\\) number parameters \\(\\boldsymbol \\theta\\), .e. dimension model.scalar \\(\\theta\\) (.e. single parameter \\(d=1\\)) becomes\n\\[\nW(\\theta_0) \\overset{}{\\sim} \\chi^2_1\n\\]fact known Wilks’ theorem.","code":""},{"path":"likelihood-based-confidence-interval-and-likelihood-ratio.html","id":"cutoff-values-for-the-likelihood-ci","chapter":"5 Likelihood-based confidence interval and likelihood ratio","heading":"5.1.4 Cutoff values for the likelihood CI","text":"asymptotic distribution \\(W\\) useful choose suitable \\(\\Delta\\) likelihood\nCI — note \\(2 \\Delta = c_{\\text{chisq}}\\) \\(c_{\\text{chisq}}\\) critical value specified coverage \\(\\kappa\\). yields table scalar parameterExample 5.5  Likelihood confidence interval proportion:continue Example 5.1, Example 4.7 asssume data \\(n = 30\\) \\(\\bar{x} = 0.7\\).yields (via numerical root finding) 95% likelihood confidence interval\ninterval \\([0.524, 0.843]\\).\nsimilar identical corresponding\nasymptotic normal interval \\([0.536, 0.864]\\) obtained Example 4.7.following figure illustrate relationship normal CI, likelihood\nCI also shows role quadratic approximation (see also Example 4.2). Note :normal CI symmetric around MLE whereas likelihood CI symmetricthe normal CI identical likelihood CI using quadratic approximation!","code":""},{"path":"likelihood-based-confidence-interval-and-likelihood-ratio.html","id":"likelihood-ratio-test-lrt-using-wilks-statistic","chapter":"5 Likelihood-based confidence interval and likelihood ratio","heading":"5.1.5 Likelihood ratio test (LRT) using Wilks statistic","text":"normal case (Wald statistic normal CIs) one can also construct\ntest using Wilks statistic:\\[\\begin{align*}\n\\begin{array}{ll}\nH_0: \\boldsymbol \\theta= \\boldsymbol \\theta_0\\\\\nH_1: \\boldsymbol \\theta\\neq \\boldsymbol \\theta_0\\\\\n\\end{array}\n\\begin{array}{ll}\n  \\text{ True model } \\boldsymbol \\theta_0\\\\\n  \\text{ True model } \\textbf{} \\boldsymbol \\theta_0\\\\\n\\end{array}\n\\begin{array}{ll}\n\\text{  Null hypothesis}\\\\\n\\text{  Alternative hypothesis}\\\\\n\\end{array}\n\\end{align*}\\]test statistic use Wilks log likelihood ratio \\(W(\\boldsymbol \\theta_0)\\).\nExtreme values test statistic imply evidence \\(H_0\\).Note null model “simple” (= single parameter value)\nwhereas alternative model “composite” (= set parameter values).Remarks:composite alternative \\(H_1\\) represented single point (MLE).Reject \\(H_0\\) large values \\(W(\\boldsymbol \\theta_0)\\)\\(H_0\\) large \\(n\\) statistic \\(W(\\boldsymbol \\theta_0)\\) chi-squared distributed, .e. \\(W(\\boldsymbol \\theta_0) \\overset{}{\\sim} \\chi^2_d\\). allows compute\ncritical values (.e tresholds declared rejection given significance level) also \\(p\\)-values corresponding observed test statistics.Models outside CI rejectedModels inside CI rejected, .e. can’t statistically distinguished best alternative model.statistic equivalent \\(W(\\boldsymbol \\theta_0)\\) likelihood ratio\n\\[\n\\Lambda(\\boldsymbol \\theta_0)  = \\frac{L(\\boldsymbol \\theta_0| D)}{L(\\hat{\\boldsymbol \\theta}_{ML}| D)}\n\\]\ntwo statistics can transformed \\(W(\\boldsymbol \\theta_0) = -2\\log \\Lambda(\\boldsymbol \\theta_0)\\)\n\\(\\Lambda(\\boldsymbol \\theta_0) = e^{ - W(\\boldsymbol \\theta_0) / 2 }\\).\nreject \\(H_0\\) small values \\(\\Lambda\\).can shown likelihood ratio test compare two simple models optimal sense given specified type error (=probability wrongly rejecting \\(H_0\\), .e.\nsigificance level) maximise power (=1- type II error, probability correctly\naccepting \\(H_1\\)). known Neyman-Pearson theorem.Example 5.6  Likelihood test proportion:continue Example 5.5 95% likelihood confidence\ninterval \\([0.524, 0.843]\\).value \\(p_0=0.5\\) outside CI hence can rejected whereas \\(p_0=0.8\\)\ninsided CI hence rejected 5% significance level.Wilks statistic \\(p_0=0.5\\) \\(p_0=0.8\\) takes following values:\\(W(0.5) = 4.94 > 3.84\\) hence \\(p_0=0.5\\) can rejected.\\(W(0.8) = 1.69 < 3.84\\) hence \\(p_0=0.8\\) rejected.Note Wilks statistic boundaries likelihood confidence interval\nequal critical value (3.84 corresponding 5% significance level chi-squared\ndistribution 1 degree freedom).Compare also normal test proportion Example 4.9.","code":""},{"path":"likelihood-based-confidence-interval-and-likelihood-ratio.html","id":"origin-of-likelihood-ratio-statistic","chapter":"5 Likelihood-based confidence interval and likelihood ratio","heading":"5.1.6 Origin of likelihood ratio statistic","text":"likelihood ratio statistic asymptotically linked differences KL divergences two compared models underlying true model.Assume \\(F\\) true (unknown) data generating model \n\\(G_{\\boldsymbol \\theta}\\) family models\nlike compare two candidate models \\(G_A\\) \\(G_B\\) corresponding\nparameters \\(\\boldsymbol \\theta_A\\) \\(\\boldsymbol \\theta_B\\) \nbasis observed data \\(D = \\{x_1, \\ldots, x_n\\}\\).\nKL divergences \\(D_{\\text{KL}}(F, G_A)\\) \\(D_{\\text{KL}}(F, G_B)\\) indicate close\nmodels \\(G_A\\) \\(G_B\\) fit true \\(F\\).\ndifference two divergences way measure relative fit two models,\ncan computed \n\\[\nD_{\\text{KL}}(F, G_B)-D_{\\text{KL}}(F, G_A) = \\text{E}_{F} \\log \\frac{g(x|\\boldsymbol \\theta_A )}{g(x| \\boldsymbol \\theta_B)}\n\\]\nReplacing \\(F\\) empirical distribution \\(\\hat{F}_n\\) leads \nlarge sample approximation\n\\[\n2 n (D_{\\text{KL}}(F, G_B)-D_{\\text{KL}}(F, G_A))  \\approx 2 (l_n(\\boldsymbol \\theta_A| D) - l_n(\\boldsymbol \\theta_B| D))\n\\]\nHence, difference log-likelihoods provides estimate difference\nKL divergence two models involved.Wilks log likelihood ratio statistic\n\\[\nW(\\boldsymbol \\theta_0) = 2 ( l_n( \\hat{\\boldsymbol \\theta}_{ML}| D ) - l_n(\\boldsymbol \\theta_0| D) )\n\\]\nthus compares best-fit distribution \\(\\hat{\\boldsymbol \\theta}_{ML}\\)\nparameter distribution parameter \\(\\boldsymbol \\theta_0\\).specific models Wilks statistic\ncan also written form KL divergence:\n\\[\nW(\\boldsymbol \\theta_0) = 2n D_{\\text{KL}}( F_{\\hat{\\boldsymbol \\theta}_{ML}}, F_{\\boldsymbol \\theta_0})\n\\]\ncase examples 5.1 5.2 also generally exponential\nfamily models, true general.","code":""},{"path":"likelihood-based-confidence-interval-and-likelihood-ratio.html","id":"generalised-likelihood-ratio-test-glrt","chapter":"5 Likelihood-based confidence interval and likelihood ratio","heading":"5.2 Generalised likelihood ratio test (GLRT)","text":"Also known maximum likelihood ratio test (MLRT). Generalised Likelihood Ratio Test (GLRT) works just like standard likelihood ratio test difference now null model \\(H_0\\) also composite model.\\[\\begin{align*}\n\\begin{array}{ll}\nH_0: \\boldsymbol \\theta\\\\omega_0 \\subset \\Omega \\\\\nH_1: \\boldsymbol \\theta\\\\omega_1  = \\Omega \\setminus \\omega_0\\\\\n\\end{array}\n\\begin{array}{ll}\n\\text{ True model lies restricted model space }\\\\\n\\text{ True model restricted model space } \\\\\n\\end{array}\n\\end{align*}\\]\\(H_0\\) \\(H_1\\) now composite hypotheses.\n\\(\\Omega\\) represents unrestricted model space dimension\n(=number free parameters)\n\\(d = |\\Omega|\\). constrained space \\(\\omega_0\\) degree freedom\n\\(d_0 = |\\omega_0|\\) \\(d_0 < d\\).\nNote standard LRT set \\(\\omega_0\\) simple point\n\\(d_0=0\\)\nnull model simple distribution. Thus, LRT contained GLRT\nspecial case!corresponding generalised (log) likelihood ratio statistic given \\[\nW = 2\\log\\left(\\frac{L(\\hat{\\theta}_{ML} |D )}{L(\\hat{\\theta}_{ML}^0 | D )}\\right)\n\\text{ }\n\\Lambda = \\frac{\\underset{\\theta \\\\omega_0}{\\max}\\, L(\\theta| D)}{\\underset{\\theta \\\\Omega}{\\max}\\, L(\\theta | D)}\n\\]\\(L(\\hat{\\theta}_{ML}| D)\\) maximised likelihood assuming full model\n(parameter space \\(\\Omega\\)) \\(L(\\hat{\\theta}_{ML}^0| D)\\) maximised likelihood restricted model (parameter space \\(\\omega_0\\)).\nHence, compute GRLT test statistic need perform two optimisations, one full\nanother restricted model.Remarks:MLE restricted model space \\(\\omega_0\\) taken representative \\(H_0\\).likelihood maximised numerator denominator.restricted model special case full model (.e. two models nested).asymptotic distribution \\(W\\) chi-squared degree freedom depending \\(d\\) \\(d_0\\):\\[W \\overset{}{\\sim} \\text{$\\chi^2_{d-d_0}$}\\]result due Wilks (1938) 7. Note \nassumes true model contained among investigated models.result due Wilks (1938) 7. Note \nassumes true model contained among investigated models.\\(H_0\\) simple hypothesis (.e. \\(d_0=0\\)) standard LRT (corresponding CI) recovered special case GLRT.\\(H_0\\) simple hypothesis (.e. \\(d_0=0\\)) standard LRT (corresponding CI) recovered special case GLRT.Example 5.7  GLRT example:Case-control study: (e.g. “healthy” vs. “disease”)\nobserve normal data \\(D = \\{x_1, \\ldots, x_n\\}\\) two groups sample size \\(n_1\\) \\(n_2\\)\n(\\(n=n_1+n_2\\)), two different means \\(\\mu_1\\) \\(\\mu_2\\) common variance \\(\\sigma^2\\):\\[x_1,\\dots,x_{n_1} \\sim N(\\mu_1, \\sigma^2)\\]\n\n\\[x_{n_1+1},\\dots,x_{n} \\sim N(\\mu_2, \\sigma^2)\\]Question: two means \\(\\mu_1\\) \\(\\mu_2\\) two groups?\\[\\begin{align*}\n\\begin{array}{ll}\nH_0: \\mu_1=\\mu_2  \\text{ (variance unknown, .e. treated nuisance parameter)}\n\\\\\nH_1: \\mu_1\\neq\\mu_2\\\\\n\\end{array}\n\\end{align*}\\]Restricted full models:\\(\\omega_0\\): restricted model two parameters \\(\\mu_0\\) \\(\\sigma^2_0\\)\n(\\(x_{1},\\dots,x_{n} \\sim N(\\mu_0, \\sigma_0^2)\\) ).\\(\\Omega\\): full model three parameters \\(\\mu_1, \\mu_2, \\sigma^2\\).Corresponding log-likelihood functions:Restricted model \\(\\omega_0\\):\n\\[\n\\log L(\\mu_0, \\sigma_0^2 | D) = -\\frac{n}{2} \\log(\\sigma_0^2)\n- \\frac{1}{2\\sigma_0^2} \\sum_{=1}^n (x_i-\\mu_0)^2\n\\]Full model \\(\\Omega\\):\n\\[\n\\begin{split}\n\\log L(\\mu_1, \\mu_2, \\sigma^2 | D) & =\n\\left(-\\frac{n_1}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2}  \\sum_{=1}^{n_1} (x_i-\\mu_1)^2   \\right) + \\\\\n& \\phantom{==}\n\\left(-\\frac{n_2}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2}  \\sum_{=n_1+1}^{n} (x_i-\\mu_2)^2   \\right)\n\\\\\n&= -\\frac{n}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\left( \\sum_{=1}^{n_1} (x_i-\\mu_1)^2 + \\sum_{=n_1+1}^n (x_i-\\mu_2)^2 \\right) \\\\\n\\end{split}\n\\]Corresponding MLEs:\\[\\begin{align*}\n\\begin{array}{ll}\n\\omega_0:\\\\\n\\\\\n\\Omega:\\\\\n\\\\\n\\end{array}\n\\begin{array}{ll}\n\\hat{\\mu}_0 = \\frac{1}{n}\\sum^n_{=1}x_i\\\\\n\\\\\n\\hat{\\mu}_1 = \\frac{1}{n_1}\\sum^{n_1}_{=1}x_i\\\\\n\\hat{\\mu}_2 = \\frac{1}{n_2}\\sum^{n}_{=n_1+1}x_i\\\\\n\\end{array}\n\\begin{array}{ll}\n\\widehat{\\sigma^2_0} = \\frac{1}{n}\\sum^n_{=1}(x_i-\\hat{\\mu}_0)^2\\\\\n\\\\\n\\widehat{\\sigma^2} = \\frac{1}{n}\\left\\{\\sum^{n_1}_{=1}(x_i-\\hat{\\mu}_1)^2+\\sum^n_{=n_1+1}(x_i-\\hat{\\mu}_2)^2\\right\\}\\\\\n\\\\\n\\end{array}\n\\end{align*}\\]Note estimated means related \n\\[\n\\hat{\\mu}_0  = \\frac{n_1}{n} \\hat{\\mu}_1 + \\frac{n_2}{n} \\hat{\\mu}_2\n\\]\noverall mean weighted average two individual group means.Moreover, two estimated variances related \n\\[\n\\begin{split}\n\\widehat{\\sigma^2_0} & = \\widehat{\\sigma^2} + \\frac{n_1 n_2}{n^2} (\\hat{\\mu}_1 - \\hat{\\mu}_2)^2\\\\\n& =  \\widehat{\\sigma^2} \\left( 1+   \\frac{1}{n}     \\frac{(\\hat{\\mu}_1 - \\hat{\\mu}_2)^2}{ \\frac{n}{n_1 n_2} \\widehat{\\sigma^2}}\\right) \\\\\n& = \\widehat{\\sigma^2} \\left( 1 +  \\frac{t^2_{ML}}{n}\\right)\n\\end{split}\n\\]\n\n\\[\nt_{ML} = \\frac{\\hat{\\mu}_1-\\hat{\\mu}_2}{\\sqrt{\\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right) \\widehat{\\sigma^2}}}\n\\]\n(\\(t\\)-statistic based ML variance estimate\n\\(\\widehat{\\sigma^2}\\), see Appendix).example variance decomposition, \\(\\widehat{\\sigma^2_0}\\) estimated total variance,\\(\\widehat{\\sigma^2}\\) estimated within-group variance \\(\\widehat{\\sigma^2}\\frac{t^2_{ML}}{n}= \\frac{n_1 n_2}{n^2} (\\hat{\\mu}_1 - \\hat{\\mu}_2)^2\\) estimated -group variance.\\(\\frac{\\widehat{\\sigma^2}}{ \\widehat{\\sigma^2_0} } = 1 + \\frac{t^2_{ML}}{n}\\)Corresponding maximised log-likelihood:Restricted model:\\[\\log L(\\hat{\\mu}_0,\\widehat{\\sigma^2_0}| D) = -\\frac{n}{2} \\log(\\widehat{\\sigma^2_0}) -\\frac{n}{2} \\]Full model:\\[\n\\log L(\\hat{\\mu}_1,\\hat{\\mu}_2,\\widehat{\\sigma^2}| D) = -\\frac{n}{2} \\log(\\widehat{\\sigma^2}) -\\frac{n}{2}\n\\]Likelihood ratio statistic:\\[\n\\begin{split}\nW & = 2\\log\\left(\\frac{L(\\hat{\\mu}_1,\\hat{\\mu}_2,\\widehat{\\sigma^2} | D)}{L(\\hat{\\mu}_0,\\widehat{\\sigma^2_0} | D)}\\right)\\\\\n& = 2 \\log L\\left(\\hat{\\mu}_1,\\hat{\\mu}_2,\\widehat{\\sigma^2}| D\\right) - 2 \\log L\\left(\\hat{\\mu}_0,\\widehat{\\sigma^2_0}| D\\right) \\\\\n& = n\\log\\left(\\frac{\\widehat{\\sigma^2_0}}{\\widehat{\\sigma^2}} \\right) \\\\\n& = n\\log\\left(1+\\frac{t^2_{ML}}{n}\\right) \\\\\n\\end{split}\n\\]\nlast step uses decomposition total variance\n\\(\\widehat{\\sigma^2_0}\\).can express also terms conventional\ntwo sample \\(t\\)-statistic\n\\[\nt = \\frac{\\hat{\\mu}_1-\\hat{\\mu}_2}{\\sqrt{\\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)\\widehat{\\sigma^2}_{\\text{UB}}  }}\n\\]\nuses unbiased estimate variance\nrather MLE, \\(\\widehat{\\sigma^2}_{\\text{UB}}=\\frac{n}{n-2} \\widehat{\\sigma^2}\\) thus\n\\(t^2/(n-2) = t^2_{ML} / n\\). yields\n\\[\nW=n\\log\\left(1+\\frac{t^2}{n-2}\\right)\n\\]Thus, log-likelihood ratio statistic \\(W\\) monotonic function (one--one transformation!) (squared) two sample \\(t\\)-statistic!Asymptotic distribution:degree freedom full model \\(d=3\\) constrained model \\(d_0=2\\) \ngeneralised log likelihood ratio statistic \\(W\\) distributed asymptotically \\(\\text{$\\chi^2_{1}$}\\).\nHence, reject null model 5% significance level \\(W > 3.84\\).application GLRTsAs shown , two sample \\(t\\) statistic\ncan derived likelihood ratio statistic.generally, turns many commonly used familiar statistical tests test statistics can interpreted GLRTs. shows wide applicability procedure.","code":""},{"path":"optimality-properties-and-conclusion.html","id":"optimality-properties-and-conclusion","chapter":"6 Optimality properties and conclusion","heading":"6 Optimality properties and conclusion","text":"","code":""},{"path":"optimality-properties-and-conclusion.html","id":"properties-of-maximum-likelihood-encountered-so-far","chapter":"6 Optimality properties and conclusion","heading":"6.1 Properties of maximum likelihood encountered so far","text":"MLE special case relative entropy minimisation valid large samples.MLE can seen generalisation least squares (conversely, least squares special case ML).\\[\\begin{align*}\n\\begin{array}{cc}\n\\text{Kullback-Leibler 1951}\\\\\n\\textbf{Entropy learning: minimise  } D_{\\text{KL}}(F_{\\text{true}},F_{\\boldsymbol \\theta})\\\\\n\\downarrow\\\\\n\\text{large } n\\\\\n\\downarrow\\\\\n\\text{Fisher 1922}\\\\\n\\textbf{Maximise Likelihood  } L(\\boldsymbol \\theta|D)\\\\\n\\downarrow\\\\\n\\text{normal model}\\\\\n\\downarrow\\\\\n\\text{Gauss 1805}\\\\\n\\textbf{Minimise squared error  } \\sum_i (x_i-\\theta)^2\\\\\n\\end{array}\n\\end{align*}\\]Given model, derivation MLE basically automatic (optimisation required)!Given model, derivation MLE basically automatic (optimisation required)!MLEs consistent, .e. true underlying model \\(F_{\\text{true}}\\) parameter \\(\\boldsymbol \\theta_{\\text{true}}\\) contained set specified candidates models \\(F_{\\boldsymbol \\theta}\\)\nMLE converge true model.MLEs consistent, .e. true underlying model \\(F_{\\text{true}}\\) parameter \\(\\boldsymbol \\theta_{\\text{true}}\\) contained set specified candidates models \\(F_{\\boldsymbol \\theta}\\)\nMLE converge true model.Correspondingly, MLEs asympotically unbiased.Correspondingly, MLEs asympotically unbiased.However, MLEs necessarily unbiased finite samples\n(e.g. MLE variance parameter normal distribution).However, MLEs necessarily unbiased finite samples\n(e.g. MLE variance parameter normal distribution).maximum likelihood invariant parameter transformations.maximum likelihood invariant parameter transformations.regular situations (local quadratic approximation possible)\nMLEs asympotically normally distributed, asymptotic variance determined \nobserved Fisher information.regular situations (local quadratic approximation possible)\nMLEs asympotically normally distributed, asymptotic variance determined \nobserved Fisher information.regular situations large sample size MLEs asympotically optimally efficient (Cramer-Rao theorem): large samples MLE achieves lowest possible variance possible estimator — -called Cramer-Rao lower bound. variance decreases zero \\(n \\rightarrow \\infty\\) typically rate \\(1/n\\).regular situations large sample size MLEs asympotically optimally efficient (Cramer-Rao theorem): large samples MLE achieves lowest possible variance possible estimator — -called Cramer-Rao lower bound. variance decreases zero \\(n \\rightarrow \\infty\\) typically rate \\(1/n\\).likelihood ratio can used construct optimal tests (sense Neyman-Pearson theorem).likelihood ratio can used construct optimal tests (sense Neyman-Pearson theorem).","code":""},{"path":"optimality-properties-and-conclusion.html","id":"summarising-data-and-the-concept-of-minimal-sufficiency","chapter":"6 Optimality properties and conclusion","heading":"6.2 Summarising data and the concept of (minimal) sufficiency","text":"","code":""},{"path":"optimality-properties-and-conclusion.html","id":"sufficient-statistic","chapter":"6 Optimality properties and conclusion","heading":"6.2.1 Sufficient statistic","text":"Another important concept statistics likelihood theory -called sufficient statistics summarise information available data parameter model.Generally, statistic \\(T(D)\\) function observed data \\(D=\\{x_1, \\ldots, x_n\\}\\).\nstatistic \\(T(D)\\) can type value (scalar, vector, matrix etc. — even function). \\(T(D)\\) called summary statistic describes important aspects data location (e.g. average \\(\\text{avg}(D) =\\bar{x}\\), median) scale (e.g. standard deviation, interquartile range).statistic \\(T(D)\\) said sufficient \nparameter \\(\\boldsymbol \\theta\\) model corresponding likelihood function can written using \\(T(D)\\)\nterms involve \\(\\boldsymbol \\theta\\) \n\\[\nL(\\boldsymbol \\theta| D) = h( T(D) , \\boldsymbol \\theta) \\, k(D) \\,,\n\\]\n\\(h()\\) \\(k()\\) positive-valued functions, equivalently log-scale\n\\[\nl_n(\\boldsymbol \\theta) = \\log h( T(D) , \\boldsymbol \\theta) + \\log k(D) \\,.\n\\]\nknown Fisher-Pearson factorisation.construction, estimation inference \\(\\boldsymbol \\theta\\) based factorised likelihood \\(L(\\boldsymbol \\theta)\\) mediated sufficient statistic \\(T(D)\\) require original data \\(D\\). Instead, sufficient statistic \\(T(D)\\) contains information \\(D\\) required learn parameter \\(\\boldsymbol \\theta\\).Therefore, MLE \\(\\hat{\\boldsymbol \\theta}_{ML}\\) \\(\\boldsymbol \\theta\\) exists unique MLE unique function sufficient statistic \\(T(D)\\). MLE unique can chosen function \\(T(D)\\).\nNote sufficient statistic always exists since data \\(D\\)\nsufficient statistics, \\(T(D) = D\\). Furthermore, sufficient statistics unique since applying one--one transformation \n\\(T(D)\\) yields another sufficient statistic.","code":""},{"path":"optimality-properties-and-conclusion.html","id":"induced-partioning-of-data-space-and-likelihood-equivalence","chapter":"6 Optimality properties and conclusion","heading":"6.2.2 Induced partioning of data space and likelihood equivalence","text":"Every sufficient statistic \\(T(D)\\) induces partitioning space data sets\nclustering hypothetical outcomes statistic \\(T(D)\\) assumes value \\(t\\):\n\\[\\mathcal{X}_t = \\{D: T(D) = t\\}\\]\ndata sets \\(\\mathcal{X}_t\\) equivalent terms sufficient statistic \\(T(D)\\). Note implies \\(T(D)\\)\n1:1 transformation \\(D\\). Instead \\(n\\) data points \\(x_1, \\ldots, x_n\\) one two summaries (mean variance) may sufficient fully convey information data model parameters.\nThus, transforming data \\(D\\) using sufficient statistic \\(T(D)\\) may result substantial data reduction.Two data sets \\(D_1\\) \\(D_2\\) ratio corresponding\nlikelihoods\n\\(L(\\boldsymbol \\theta| D_1 )/L(\\boldsymbol \\theta| D_2)\\) depend \\(\\boldsymbol \\theta\\) (two likelihoods\nproportional constant)\ncalled likelihood equivalent likelihood-based procedure\nlearn \\(\\boldsymbol \\theta\\) draw identical conclusions \\(D_1\\) \\(D_2\\).\ndata sets \\(D_1, D_2 \\\\mathcal{X}_t\\) equivalent respect\nsufficient statistic \\(T\\)\nfollows directly Fisher-Pearson factorisation \nratio\n\\[L(\\boldsymbol \\theta| D_1 )/L(\\boldsymbol \\theta| D_2) = k(D_1)/ k(D_2)\\]\nthus constant regard \\(\\boldsymbol \\theta\\). result, data sets \\(\\mathcal{X}_t\\) likelihood equivalent.\nHowever, converse true: depending sufficient statistics usually many likelihood equivalent data\nsets part set \\(\\mathcal{X}_t\\).","code":""},{"path":"optimality-properties-and-conclusion.html","id":"minimal-sufficient-statistics","chapter":"6 Optimality properties and conclusion","heading":"6.2.3 Minimal sufficient statistics","text":"particular interest therefore find sufficient statistics achieve coarsest partitioning sample space thus may allow highest data reduction.\nSpecifically, minimal sufficient statistic sufficient statistic\nlikelihood equivalent data sets also equivalent statistic.Therefore, check whether sufficient statistic \\(T(D)\\) minimally sufficient need verify whether two likelihood equivalent data sets \\(D_1\\) \\(D_2\\)\nalso follows \\(T(D_1) = T(D_2)\\). holds true\n\\(T\\) minimally sufficient statistic.equivalent non-operational definition minimal sufficient statistic \\(T(D)\\) sufficient statistic can computed sufficient statistic \\(S(D)\\). follows directly: assume sufficient statistic \\(S(D)\\), defines\ncorresponding set \\(\\mathcal{X}_s\\) likelihood equivalent data sets. implication\n\\(D_1, D_2 \\\\mathcal{X}_s\\) necessarily also \\(\\mathcal{X}_t\\), thus\nwhenever \\(S(D_1)=S(D_2)\\) also \\(T(D_1)=T(D_2)\\), therefore\n\\(T(D_1)\\) function \\(S(D_1)\\).trivial important example \nminimal sufficient statistic likelihood function \nsince definition can computed set sufficient statistics. Thus likelihood function \\(L(\\boldsymbol \\theta)\\) captures information \\(\\boldsymbol \\theta\\) available data. words, provides optimal summary observed data regard model. Note Bayesian statistics (discussed Part 2 module) likelihood function used proxy/summary data.","code":""},{"path":"optimality-properties-and-conclusion.html","id":"example-normal-distribution","chapter":"6 Optimality properties and conclusion","heading":"6.2.4 Example: normal distribution","text":"Example 6.1  Sufficient statistics parameters normal distribution:normal model \\(N(\\mu, \\sigma^2)\\)\nparameter vector \\(\\boldsymbol \\theta= (\\mu, \\sigma^2)^T\\) log-likelihood\n\\[\nl_n(\\boldsymbol \\theta) = -\\frac{n}{2} \\log(2 \\pi \\sigma^2)  - \\frac{1}{2 \\sigma^2} \\sum_{=1}^n (x_i-\\mu)^2\n\\]\nOne possible set minimal sufficient statistics \\(\\boldsymbol \\theta\\) \\(\\bar{x}\\)\n\\(\\overline{x^2}\\), can rewrite log-likelihood function\nwithout reference original data \\(x_1, \\ldots, x_n\\) follows\n\\[\nl_n(\\boldsymbol \\theta) = -\\frac{n}{2} \\log(2 \\pi \\sigma^2)\n-\\frac{n}{2 \\sigma^2} (\\overline{x^2} - 2 \\bar{x} \\mu + \\mu^2)\n\\]\nalternative set minimal sufficient statistics \\(\\boldsymbol \\theta\\)\nconsists \\(s^2 = \\overline{x^2} - \\bar{x}^2 = \\widehat{\\sigma^2}_{ML}\\) \n\\(\\bar{x} = \\hat{\\mu}_{ML}\\). log-likelihood written terms \\(s^2\\) \\(\\bar{x}\\) \n\\[\nl_n(\\boldsymbol \\theta) = -\\frac{n}{2} \\log(2 \\pi \\sigma^2)\n-\\frac{n}{2 \\sigma^2} (s^2 + (\\bar{x} - \\mu)^2 )\n\\]Note example dimension parameter\nvector \\(\\boldsymbol \\theta\\) equals dimension minimal sufficient statistic,\nfurthermore, MLEs parameters fact minimal sufficient!","code":""},{"path":"optimality-properties-and-conclusion.html","id":"mles-of-parameters-of-an-exponential-family-are-minimal-sufficient-statistics","chapter":"6 Optimality properties and conclusion","heading":"6.2.5 MLEs of parameters of an exponential family are minimal sufficient statistics","text":"conclusion Example 6.1\nholds true generally: exponential family model (normal distribution particular important case) MLEs parameters minimal sufficient statistics.\nThus, typically substantial dimension reduction raw data sufficient statistics.However, outside exponential families\nMLE necessarily minimal sufficient statistic, may even sufficient statistic.\n(minimal) sufficient statistic dimension \nparameters always exist. classic example Cauchy distribution \nminimal sufficient statistics ordered observations,\nthus MLE parameters constitute sufficient statistics, let alone minimal sufficient statistics.\nHowever, MLE course still function minimal sufficient statistic.summary, likelihood function acts perfect data summariser\n(.e. minimally sufficient statistic),\nexponential families (e.g. normal distribution) \nMLEs parameters \\(\\hat{\\boldsymbol \\theta}_{ML}\\) minimal sufficient.Finally, sufficiency clearly useful concept data reduction one needs keep mind always reference specific model. Therefore, unless one strongly believes certain model generally good idea keep (discard!) original data.","code":""},{"path":"optimality-properties-and-conclusion.html","id":"concluding-remarks-on-maximum-likelihood","chapter":"6 Optimality properties and conclusion","heading":"6.3 Concluding remarks on maximum likelihood","text":"","code":""},{"path":"optimality-properties-and-conclusion.html","id":"remark-on-kl-divergence","chapter":"6 Optimality properties and conclusion","heading":"6.3.1 Remark on KL divergence","text":"Finding model \\(F_{\\boldsymbol \\theta}\\) best approximates underlying true model \\(F_0\\)\ndone minimising relative entropy \\(D_{\\text{KL}}(F_0,F_{\\boldsymbol \\theta})\\). large sample size \\(n\\)\nmay approximate \\(F_0\\) empirical distribution \\(\\hat{F}_0\\),\nminimising \\(D_{\\text{KL}}(\\hat{F}_0,F_{\\boldsymbol \\theta})\\) yields method maximum likelihood, discussed earlier.However, since KL divergence symmetric fact two ways minimise divergence\nfixed \\(F_0\\) family \\(F_{\\boldsymbol \\theta}\\), different properties:forward KL, approximation KL: \\(\\min_{\\boldsymbol \\theta} D_{\\text{KL}}(F_0,F_{\\boldsymbol \\theta})\\)\nNote keep first argument fixed minimise KL changing second argument.\nalso called “M (Moment) projection”. zero avoiding property:\n\\(f_{\\boldsymbol \\theta}(x)>0 \\text{ whenever } f_0(x)>0\\).\nprocedure mean-seeking inclusive, .e. multiple modes density \\(F_0\\) fitted unimodal density \\(F_{\\hat{\\boldsymbol \\theta}}\\) seek cover modes.forward KL, approximation KL: \\(\\min_{\\boldsymbol \\theta} D_{\\text{KL}}(F_0,F_{\\boldsymbol \\theta})\\)Note keep first argument fixed minimise KL changing second argument.also called “M (Moment) projection”. zero avoiding property:\n\\(f_{\\boldsymbol \\theta}(x)>0 \\text{ whenever } f_0(x)>0\\).procedure mean-seeking inclusive, .e. multiple modes density \\(F_0\\) fitted unimodal density \\(F_{\\hat{\\boldsymbol \\theta}}\\) seek cover modes.reverse KL, inference KL: \\(\\min_{\\boldsymbol \\theta} D_{\\text{KL}}(F_{\\boldsymbol \\theta},F_0)\\)\nNote keep second argument fixed minimise KL changing first argument.\nalso called “(Information) projection”. zero forcing property:\n\\(f_{\\boldsymbol \\theta}(x)=0 \\text{ whenever } f_0(x)=0\\).\nprocedure mode-seeking exclusive, .e. multiple modes density \\(F_0\\) fitted unimodal density \\(F_{\\hat{\\boldsymbol \\theta}}\\) seek one mode exclusion others.reverse KL, inference KL: \\(\\min_{\\boldsymbol \\theta} D_{\\text{KL}}(F_{\\boldsymbol \\theta},F_0)\\)Note keep second argument fixed minimise KL changing first argument.also called “(Information) projection”. zero forcing property:\n\\(f_{\\boldsymbol \\theta}(x)=0 \\text{ whenever } f_0(x)=0\\).procedure mode-seeking exclusive, .e. multiple modes density \\(F_0\\) fitted unimodal density \\(F_{\\hat{\\boldsymbol \\theta}}\\) seek one mode exclusion others.Maximum likelihood based “forward KL”, whereas Bayesian updating Variational Bayes\napproximations use “reverse KL”.","code":""},{"path":"optimality-properties-and-conclusion.html","id":"what-happens-if-n-is-small","chapter":"6 Optimality properties and conclusion","heading":"6.3.2 What happens if \\(n\\) is small?","text":"long list optimality properties ML\nclear large sample size \\(n\\) best estimator typically MLE.However, small sample size indeed possible (necessary) improve MLE (e.g. via Bayesian estimation regularisation). ideas discussed Part II.Likelihood overfit!Alternative methods need used:regularised/penalised likelihoodBayesian methodswhich essentially two sides coin.Classic example simple non-ML estimator better MLE:\nStein’s example / Stein paradox (C. Stein, 1955):Problem setting: estimation mean multivariate caseProblem setting: estimation mean multivariate caseMaximum likelihood estimation breaks ! \\(\\rightarrow\\) average (=MLE) worse terms MSE Stein estimator.Maximum likelihood estimation breaks ! \\(\\rightarrow\\) average (=MLE) worse terms MSE Stein estimator.small \\(n\\) asymptotic distributions MLE LRT accurate, inference situations distributions may need obtained simulation\n(e.g. parametric nonparametric bootstrap).small \\(n\\) asymptotic distributions MLE LRT accurate, inference situations distributions may need obtained simulation\n(e.g. parametric nonparametric bootstrap).","code":""},{"path":"optimality-properties-and-conclusion.html","id":"model-selection","chapter":"6 Optimality properties and conclusion","heading":"6.3.3 Model selection","text":"CI sets models statistically distinguishable best ML modelin doubt, choose simplest model compatible databetter prediction, avoids overfittingUseful model exploration model building.Note , construction, model parameters always higher likelihood, implying likelihood favours complex modelsNote , construction, model parameters always higher likelihood, implying likelihood favours complex modelsComplex model may overfit!Complex model may overfit!comparison models penalised likelihood Bayesian approaches may necessaryFor comparison models penalised likelihood Bayesian approaches may necessaryModel selection small samples high dimension challengingModel selection small samples high dimension challengingRecall aim statistics rejecting models (easy large sample size model rejected!)Recall aim statistics rejecting models (easy large sample size model rejected!)Instead, aim model building, .e. find model explains data well predicts well!Instead, aim model building, .e. find model explains data well predicts well!Typically, best-fit ML model, rather simpler model close enough best / complex model.Typically, best-fit ML model, rather simpler model close enough best / complex model.","code":""},{"path":"conditioning-and-bayes-rule.html","id":"conditioning-and-bayes-rule","chapter":"7 Conditioning and Bayes rule","heading":"7 Conditioning and Bayes rule","text":"chapter review conditional probabilities. Conditional probability essential Bayesian statistical modelling.","code":""},{"path":"conditioning-and-bayes-rule.html","id":"conditional-probability","chapter":"7 Conditioning and Bayes rule","heading":"7.1 Conditional probability","text":"Assume two random variables \\(x\\) \\(y\\) joint density (joint PMF) \\(p(x,y)\\).\ndefinition \\(\\int_{x,y} p(x,y) dx dy = 1\\).marginal densities individual \\(x\\) \\(y\\) given \\(p(x) = \\int_y p(x,y) dy\\)\n\\(p(y) = \\int_x f(x,y) dx\\). Thus, computing marginal densities variable removed\njoint density integrating possible states variable.\nfollows also \\(\\int_x p(x) dx = 1\\) \\(\\int_y p(y) dy = 1\\), .e. \nmarginal densities also integrate 1.alternative integrating random variable joint density \\(p(x,y)\\)\nmay wish keep fixed value, say keep \\(y\\) fixed \\(y_0\\).\ncase \\(p(x, y=y_0)\\) proportional conditional density (PMF)\ngiven ratio\n\\[\np(x | y=y_0) = \\frac{p(x, y=y_0)}{p(y=y_0)}\n\\]\ndenominator \\(p(y=y_0) = \\int_x p(x, y=y_0) dx\\) \nneeded ensure \\(\\int_x p(x | y=y_0) dx = 1\\), thus renormalises\n\\(p(x, y=y_0)\\) proper density.simplify notation, specific value variable conditioned often left \njust write \\(p(x | y)\\).","code":""},{"path":"conditioning-and-bayes-rule.html","id":"bayes-theorem","chapter":"7 Conditioning and Bayes rule","heading":"7.2 Bayes’ theorem","text":"Thomas Bayes (1701-1761) \nfirst state Bayes’ theorem\nconditional probabilities.Using definition conditional probabilities\nsee joint density can written \nproduct marginal conditional density two different ways:\n\\[\np(x,y) = p(x| y) p(y) = p(y | x) p(x)\n\\]directly leads Bayes’ theorem:\n\\[\np(x | y) = p(y | x) \\frac{ p(x) }{ p(y)}\n\\]\nrule relates two possible conditional densities (conditional probability mass functions) two random variables \\(x\\) \\(y\\). thus allows reverse ordering conditioning.Bayes’s theorem published 1763 death Richard Price (1723-1791):Pierre-Simon Laplace independently published Bayes’ theorem 1774 fact first routinely apply statistical calculations.","code":""},{"path":"conditioning-and-bayes-rule.html","id":"conditional-mean-and-variance","chapter":"7 Conditioning and Bayes rule","heading":"7.3 Conditional mean and variance","text":"mean \\(\\text{E}(x| y)\\) variance \\(\\text{Var}(x|y)\\) conditional distribution \ndensity \\(p(x|y)\\) called conditional mean conditional variance.law total expectation states \n\\[\n\\text{E}(x) = \\text{E}( \\text{E}(x| y) )\n\\]law total variance states \n\\[\n\\text{Var}(x) = \\text{Var}(\\text{E}(x| y)) + \\text{E}(\\text{Var}(x|y))\n\\]\nfirst term “explained” “-group” variance, second “unexplained”\n“mean within group” variance.Example 7.1  Mean variance mixture model:Assume \\(K\\) groups indicated discrete variable \\(y = 1, 2, \\ldots, K\\) probability \\(p(y) = \\pi_y\\). group\nobservations \\(x\\) follow density \\(p(x|y)\\) conditional mean \\(E(x|y) = \\mu_y\\) conditional variance \\(\\text{Var}(x| y)= \\sigma^2_y\\). joint density \\(x\\) \\(y\\) \n\\(p(x, y) = \\pi_y p(x|y)\\).\nmarginal density \\(x\\) \n\\(\\sum_{y=1}^K \\pi_y p(x|y)\\). called mixture model.total mean \\(\\text{E}(x) = \\mu_0\\) equal \\(\\sum_{y=1}^K \\pi_y \\mu_y\\).total variance \\(\\text{Var}(x) = \\sigma^2_0\\) equal \n\\[\n\\sum_{y=1}^K \\pi_y (\\mu_y - \\mu_0)^2 + \\sum_{y=1}^K \\pi_y \\sigma^2_y\n\\]","code":""},{"path":"conditioning-and-bayes-rule.html","id":"conditional-entropy-and-entropy-chain-rules","chapter":"7 Conditioning and Bayes rule","heading":"7.4 Conditional entropy and entropy chain rules","text":"entropy joint distribution find \n\\[\n\\begin{split}\nH( P_{x,y}) &= -\\text{E}_{P_{x,y}} \\log p(x, y) \\\\\n&= -\\text{E}_{P_x} \\text{E}_{P_{y| x}} (\\log p(x) + \\log p(y| x)\\\\\n&= -\\text{E}_{P_x} \\log p(x) - \\text{E}_{P_x} \\text{E}_{P_{y| x}} \\log p(y| x)\\\\\n&= H(P_{x}) + H(P_{y| x} ) \\\\\n\\end{split}\n\\]\nthus decomposes entropy marginal distribution \nconditional entropy defined \n\\[\nH(P_{y| x} ) = - \\text{E}_{P_x} \\text{E}_{P_{y| x}} \\log p(y| x)\n\\]\nNote simplify notation convention expectation \\(\\text{E}_{P_{x}}\\) variable \\(x\\) condition (\\(x\\)) implicitly assumed.Similarly, cross-entropy get\n\\[\n\\begin{split}\nH(Q_{x,y} , P_{x, y}) &= -\\text{E}_{Q_{x,y}} \\log  p(x, y) \\\\\n&= -\\text{E}_{Q_x} \\text{E}_{Q_{y| x}} \\log \\left(\\, p(x)\\, p(y| x)\\, \\right)\\\\\n  &= -\\text{E}_{Q_x} \\log p(x)    -\\text{E}_{Q_x} \\text{E}_{Q_{y| x}}  \\log  p(y| x)         \\\\\n&= H(Q_x, P_x)  +  H(Q_{y|x}, P_{y|x})\n\\end{split}\n\\]\nconditional cross-entropy defined \n\\[\nH(Q_{y|x}, P_{y|x})= -\\text{E}_{Q_x} \\text{E}_{Q_{y| x}}  \\log  p(y| x)\n\\]\nNote implicit expectation \\(\\text{E}_{Q_x}\\) \\(x\\) implied notation.KL divergence joint distributions can decomposed follows:\n\\[\n\\begin{split}\nD_{\\text{KL}}(Q_{x,y} , P_{x, y}) &= \\text{E}_{Q_{x,y}} \\log \\left(\\frac{ q(x, y) }{ p(x, y) }\\right)\\\\\n&= \\text{E}_{Q_x} \\text{E}_{Q_{y| x}} \\log \\left(\\frac{ q(x) q(y| x) }{ p(x) p(y| x) }\\right)\\\\\n&= \\text{E}_{Q_x} \\log \\left(\\frac{ q(x) }{ p(x) }\\right)      + \\text{E}_{Q_x} \\text{E}_{Q_{y| x}}  \\log \\left(\\frac{  q(y| x) }{ p(y| x) }\\right)          \\\\\n&= D_{\\text{KL}}(Q_{x} , P_{x}) +   D_{\\text{KL}}(Q_{y| x} , P_{y|x}) \\\\\n\\end{split}\n\\]\nconditional KL divergence conditional relative entropy defined \n\\[\nD_{\\text{KL}}(Q_{y| x} , P_{y|x})  = \\text{E}_{Q_x} \\text{E}_{Q_{y| x}}  \\log \\left(\\frac{  q(y| x) }{ p(y| x) }\\right)\n\\]\n(expectation \\(\\text{E}_{Q_{x}}\\) usually dropped convenience).\nconditional relative entropy can also computed conditional (cross-)entropies \n\\[\nD_{\\text{KL}}(Q_{y| x} , P_{y|x}) = H(Q_{y|x}, P_{y|x})\n-  H(Q_{y| x})\n\\]decompositions entropy, cross-entropy relative entropy known entropy chain rules.","code":""},{"path":"conditioning-and-bayes-rule.html","id":"entropy-bounds-for-the-marginal-variables","chapter":"7 Conditioning and Bayes rule","heading":"7.5 Entropy bounds for the marginal variables","text":"chain rule KL divergence\ndirectly shows \n\\[\n\\begin{split}\n\\underbrace{D_{\\text{KL}}(Q_{x,y} , P_{x, y})}_{\\text{upper bound}} &= D_{\\text{KL}}(Q_{x} , P_{x}) + \\underbrace{  D_{\\text{KL}}(Q_{y| x} , P_{y|x})   }_{\\geq 0}\\\\\n&\\geq D_{\\text{KL}}(Q_{x} , P_{x})\n\\end{split}\n\\]\nmeans KL divergence joint distributions\nforms upper bound KL divergence marginal distributions, difference given conditional KL divergence \\(D_{\\text{KL}}(Q_{y| x} , P_{y|x})\\).Equivalently, can state upper bound marginal cross-entropy:\n\\[\n\\begin{split}\n\\underbrace{H(Q_{x,y} , P_{x, y}) - H(Q_{y| x} )}_{\\text{upper bound}} &= H(Q_{x}, P_{x})  + \\underbrace{ D_{\\text{KL}}(Q_{y| x} , P_{y|x}) }_{\\geq 0}\\\\\n& \\geq H(Q_{x}, P_{x}) \\\\\n\\end{split}\n\\]\nInstead upper bound may well express lower bound negative marginal cross-entropy\n\\[.\n\\begin{split}\n- H(Q_{x}, P_{x}) &= \\underbrace{ - H(Q_{x} Q_{y| x} , P_{x, y})  + H(Q_{y| x} )}_{\\text{lower bound}}  + \\underbrace{ D_{\\text{KL}}(Q_{y| x} , P_{y|x})}_{\\geq 0}\\\\\n& \\geq F\\left( Q_{x}, Q_{y| x},  P_{x, y}\\right)\\\\\n\\end{split}\n\\]Since entropy KL divergence closedly linked maximum likelihood bounds play major role statistical learning\nmodels unobserved latent variables (\\(y\\)).\nform basis important methods EM algorithm well variational Bayes.","code":""},{"path":"models-with-latent-variables-and-missing-data.html","id":"models-with-latent-variables-and-missing-data","chapter":"8 Models with latent variables and missing data","heading":"8 Models with latent variables and missing data","text":"","code":""},{"path":"models-with-latent-variables-and-missing-data.html","id":"complete-data-log-likelihood-versus-observed-data-log-likelihood","chapter":"8 Models with latent variables and missing data","heading":"8.1 Complete data log-likelihood versus observed data log-likelihood","text":"frequently case need employ models \nvariables observable corresponding data missing.example consider two random variables \\(x\\) \\(y\\) joint density\n\\[\np(x, y| \\boldsymbol \\theta)\n\\]\nparameters \\(\\boldsymbol \\theta\\). observe data \\(D_x = \\{ x_1, \\ldots, x_n\\}\\)\n\\(D_y = \\{ y_1, \\ldots, y_n\\}\\) \\(n\\) samples can use complete data log-likelihood\n\\[\nl_n(\\boldsymbol \\theta| D_x, D_y) = \\sum_{=1}^n  \\log p(x_i, y_i| \\boldsymbol \\theta)\n\\]\nestimate \\(\\boldsymbol \\theta\\). Recall \n\\[\nl_n(\\boldsymbol \\theta| D_x, D_y) =-n H(\\hat{Q}_{x,y}, P_{x, y|\\boldsymbol \\theta})\n\\]\n\\(\\hat{Q}_{x,y}\\) empirical joint distribution based \\(D_x\\) \\(D_y\\) \n\\(P_{x, y|\\boldsymbol \\theta}\\) joint model, maximising complete data log-likelihood minimises\ncross-entropy \\(H(\\hat{Q}_{x,y}, P_{x, y|\\boldsymbol \\theta})\\).Now assume \\(y\\) observable hence -called latent variable. don’t observations \\(D_y\\) therefore use complete data likelihood.\nInstead, maximum likelihood estimation missing data\nneed use observed data log-likelihood.joint density obtain marginal density \\(x\\) integrating unobserved variable \\(y\\):\n\\[\np(x | \\boldsymbol \\theta) = \\int_y  p(x, y| \\boldsymbol \\theta) dy\n\\]\nUsing marginal model compute observed data log-likelihood\n\\[\nl_n(\\boldsymbol \\theta| D_x) = \\sum_{=1}^n  \\log p(x_i| \\boldsymbol \\theta) =\\sum_{=1}^n \\log \\int_y  p(x_i, y| \\boldsymbol \\theta) dy\n\\]\nNote data \\(D_x\\) used.Maximum likelihood estimation based marginal model proceeds usual maximising corresponding\nobserved data likelihood function \n\\[\nl_n(\\boldsymbol \\theta| D_x) = -n H(\\hat{Q}_{x}, P_{x|\\boldsymbol \\theta})\n\\]\n\\(\\hat{Q}_{x}\\) empirical distribution based \\(D_x\\) \\(P_{x|\\boldsymbol \\theta}\\)\nmodel family. Hence, maximising observed data log-likelihood minimises cross-entropy\n\\(H(\\hat{Q}_{x}, P_{x|\\boldsymbol \\theta})\\).Example 8.1  Two group normal mixture model:Assume two groups labelled \\(y=1\\) \\(y=2\\) (thus variable \\(y\\) discrete). data \\(x\\) observed group normal means \\(\\mu_1\\) \\(\\mu_2\\) variances\n\\(\\sigma^2_1\\) \\(\\sigma^2_2\\), respectively.\nprobability group \\(1\\) \\(\\pi_1 = p\\) probability group \\(2\\) \\(\\pi_2=1-p\\).\ndensity joint model \\(x\\) \\(y\\) \n\\[\np(x, y| \\boldsymbol \\theta)  = \\pi_y N(x| \\mu_y, \\sigma_y)\n\\]\nmodel parameters \\(\\boldsymbol \\theta= (p, \\mu_1, \\mu_2, \\sigma^2_1, \\sigma^2_2)^T\\)\ncan inferred complete data comprised \\(D_x = \\{x_1, \\ldots, x_n\\}\\) group allocations \\(D_y=\\{y_1, \\ldots, y_n\\}\\) sample using complete data log-likelihood\n\\[\nl_n(\\boldsymbol \\theta| D_x, D_y  ) =\\sum_{=1}^n  \\log \\pi_{y_i} + \\sum_{=1}^n \\log  N(x_i| \\mu_{y_i}, \\sigma_{y_i})\n\\]However, typically know class allocation \\(y\\) thus need use marginal\nmodel \\(x\\) alone density\n\\[\n\\begin{split}\np(x| \\boldsymbol \\theta) &= \\sum_{y=1}^2 \\pi_y N(\\mu_y, \\sigma^2_y) \\\\\n&= p N(x| \\mu_1, \\sigma^2_1) + (1-p)  N(x | \\mu_2, \\sigma^2_2)\\\\\n\\end{split}\n\\]\nexample two-component mixture model.\ncorresponding observed data log-likelihood \n\\[\nl_n(\\boldsymbol \\theta| D_x ) = \\sum_{=1}^n  \\log \\sum_{y=1}^2 \\pi_y N(x |\\mu_y, \\sigma^2_y)\n\\]\nNote form observed data log-likelihood complex \ncomplete data log-likelihood contains logarithm sum simplified.\nused estimate model parameters \\(\\boldsymbol \\theta\\) \\(D_x\\) without\nrequiring knowledge class allocations \\(D_y\\).Example 8.2  Alternative computation observed data likelihood:alternative way arrive observed data likelihood marginalise complete data likelihood.\n\\[\nL_n(\\boldsymbol \\theta| D_x, D_y) = \\prod_{=1}^n p(x_i, y_i| \\boldsymbol \\theta)\n\\]\n\n\\[\nL_n(\\boldsymbol \\theta| D_x) = \\int_{y_1, \\ldots, y_n} \\prod_{=1}^n p(x_i, y_i| \\boldsymbol \\theta) dy_1 \\ldots dy_n\n\\]\nintegration (sum) multiplication can interchanged per Generalised Distributive Law leading \n\\[\nL_n(\\boldsymbol \\theta| D_x) =  \\prod_{=1}^n \\int_{y} p(x_i, y| \\boldsymbol \\theta) dy\n\\]\nconstructing likelihood marginal density.","code":""},{"path":"models-with-latent-variables-and-missing-data.html","id":"estimation-of-the-unobservable-latent-states-using-bayes-theorem","chapter":"8 Models with latent variables and missing data","heading":"8.2 Estimation of the unobservable latent states using Bayes theorem","text":"estimating marginal model straightforward obtain \nprobabilistic prediction state latent variables \\(y_1, \\ldots, y_n\\).\nSince\n\\[\np(x, y | \\boldsymbol \\theta) = p( x|\\boldsymbol \\theta) \\, p(y | x, \\boldsymbol \\theta) =  p( y|\\boldsymbol \\theta) \\, p(x | y, \\boldsymbol \\theta)\n\\]\ngiven estimate \\(\\hat{\\boldsymbol \\theta}\\) able compute observation \\(x_i\\)\n\\[\np(y_i | x_i , \\hat{\\boldsymbol \\theta}) = \\frac{p(x_i, y_i | \\hat{\\boldsymbol \\theta} ) }{p(x_i|\\hat{\\boldsymbol \\theta})}\n=\\frac{  p( y_i|\\hat{\\boldsymbol \\theta}) \\, p(x_i | y_i, \\hat{\\boldsymbol \\theta})     }{p(x_i|\\hat{\\boldsymbol \\theta})}\n\\]\nprobabilities / densities states \\(y_i\\)\n(note application Bayes’ theorem).Example 8.3  Latent states two group normal mixture model:Continuing Example 8.1 assume marginal model fitted \nparameter values \\(\\hat{\\boldsymbol \\theta} = (\\hat{p},\\hat{\\mu}_1, \\hat{\\mu}_2, \\widehat{\\sigma^2_1}, \\widehat{\\sigma^2_2} )^T\\).\nsample \\(x_i\\) can get\nprobabilistic prediction group assocation sample \n\\[\np(y_i | x_i, \\hat{\\boldsymbol \\theta}) = \\frac{\\hat{\\pi}_{y_i} N(x_i| \\hat{\\mu}_{y_i}, \\widehat{\\sigma^2_{y_i}})}{\\hat{p} N(x_i| \\hat{\\mu}_1, \\widehat{\\sigma^2_1}) + (1-\\hat{p})  N(x_i | \\hat{\\mu}_2,  \\widehat{\\sigma^2_2})}\n\\]","code":""},{"path":"models-with-latent-variables-and-missing-data.html","id":"em-algorithm","chapter":"8 Models with latent variables and missing data","heading":"8.3 EM Algorithm","text":"Computing maximising observed data log-likelihood can difficult\nintegration unobserved variable (summation case discrete latent variable). contrast, complete data log-likelihood function may easier compute.widely used EM algorithm, formally described Dempster others (1977) also used , addresses problem maximises observed data log-likelihood indirectly iterative procedure comprising two steps:First (“E” step), missing data \\(D_y\\) imputed using Bayes’ theorem. provides probabilities (“soft allocations”) possible state latent variable.Subsequently (“M” step), expected complete data log-likelihood function computed,\nexpectation taken regard distribution latent states, \nmaximised regard \\(\\boldsymbol \\theta\\) estimate model parameters.EM algorithm leads exact estimates observed data log-likelihood optimised directly. Therefore EM algorithm fact approximation, just different way find MLEs.EM algorithm application clustering discussed detail module MATH38161 Multivariate Statistics Machine Learning.nutshell, justication EM algorithm follows entropy chain rules corresponding bounds, \\(D_{\\text{KL}}(Q_{x,y} , P_{x, y}) \\geq D_{\\text{KL}}(Q_{x} , P_{x})\\) (see previous chapter). Given observed data \\(x\\) know empirical distribution \\(\\hat{Q}_x\\).\nHence, minimising \\(D_{\\text{KL}}( \\hat{Q}_{x} Q_{y| x}, P_{x, y}^{\\boldsymbol \\theta})\\) iterativelywith regard \\(Q_{y| x}\\) (“E” step) andwith regard parameters \\(\\boldsymbol \\theta\\) \\(P_{x, y}^{\\boldsymbol \\theta}\\) (“M” step”)one minimises \\(D_{\\text{KL}}(\\hat{Q}_{x} , P_{x}^{\\boldsymbol \\theta})\\) regard parameters \\(P_{x}^{\\boldsymbol \\theta}\\).Interestingly, “E” step first argument KL divergence optimised (“” projection) “M” step second argument (“M” projection).Alternatively, instead bounding marginal KL divergence one can also either minimise upper bound cross-entropy maximise lower bound negative cross-entropy.\nthree procedures yield EM algorithm.Note optimisation entropy bound “E” step\nrequires variational calculus since argument distribution!\nEM algorithm therefore fact special case variational Bayes algorithm\nsince provides estimates \\(\\boldsymbol \\theta\\) also yields distribution latent states means calculus variations.Finally, see can learn unobservable states means Bayes theorem. extending principle learning parameters models arrive Bayesian learning.","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"essentials-of-bayesian-statistics","chapter":"9 Essentials of Bayesian statistics","heading":"9 Essentials of Bayesian statistics","text":"","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"principle-of-bayesian-learning","chapter":"9 Essentials of Bayesian statistics","heading":"9.1 Principle of Bayesian learning","text":"","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"from-prior-to-posterior-distribution","chapter":"9 Essentials of Bayesian statistics","heading":"9.1.1 From prior to posterior distribution","text":"Bayesian statistical learning applies Bayes’ theorem update state knowledge parameter light data.Ingredients:\\(\\boldsymbol \\theta\\) parameter(s) interest, unknown fixed.prior distribution density \\(p(\\boldsymbol \\theta)\\) describing uncertainty (randomness!) \\(\\boldsymbol \\theta\\)data generating process \\(p(x | \\boldsymbol \\theta)\\)Note model underlying Bayesian approach joint distribution\n\\[\np(\\boldsymbol \\theta, x) = p(\\boldsymbol \\theta) p(x | \\boldsymbol \\theta)\n\\]\nprior distribution parameters well data generating process specified.Question: new information form new observation \\(x\\) arrives - uncertainty \\(\\boldsymbol \\theta\\) change?Answer: use Bayes’ theorem update prior density posterior density.\\[\n\\underbrace{p(\\boldsymbol \\theta| x)}_{\\text{posterior} } = \\underbrace{p(\\boldsymbol \\theta)}_{\\text{prior}} \\frac{p(x | \\boldsymbol \\theta) }{ p(x)}\n\\]denominator Bayes formula need compute \\(p(x)\\).\nobtained \\[\n\\begin{split}\np(x) &= \\int_{\\boldsymbol \\theta} p(x , \\boldsymbol \\theta) d\\boldsymbol \\theta\\\\\n&= \\int_{\\boldsymbol \\theta} p(x | \\boldsymbol \\theta) p(\\boldsymbol \\theta) d\\boldsymbol \\theta\\\\\n\\end{split}\n\\]\n.e. marginalisation parameter \\(\\boldsymbol \\theta\\) joint\ndistribution \\(\\boldsymbol \\theta\\) \\(x\\).\n(discrete \\(\\boldsymbol \\theta\\) replace integral sum).\nDepending context quantity either called thenormalisation constant ensures posterior density \\(p(\\boldsymbol \\theta| x)\\)\nintegrates one.prior predictive density data \\(x\\) given model \\(M\\) seeing data. emphasise implicit conditioning\nmodel may write \\(p(x| M)\\). Since parameters integrated \\(M\\) fact refers model class.marginal likelihood underlying model (class) \\(M\\) given data \\(x\\). emphasise may write \\(L(M| x)\\). Sometimes also called model likelihood.","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"zero-forcing-property","chapter":"9 Essentials of Bayesian statistics","heading":"9.1.2 Zero forcing property","text":"easy see Bayes rule prior density/probability zero parameter value \\(\\boldsymbol \\theta\\) posterior density/probability remain zero \\(\\boldsymbol \\theta\\), regardless data collected. zero-forcing property Bayes update rule called Cromwell’s rule Dennis Lindley (1923–2013). Therefore, assigning prior density/probability 0 event avoided.Note implies assigning prior probability 1 avoided, .","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"bayesian-update-and-likelihood","chapter":"9 Essentials of Bayesian statistics","heading":"9.1.3 Bayesian update and likelihood","text":"independent identically distributed data \\(D = \\{x_1, \\ldots, x_n\\}\\) observed Bayesian posterior computed \\[\n\\underbrace{p(\\boldsymbol \\theta| D) }_{\\text{posterior} } = \\underbrace{p(\\boldsymbol \\theta)}_{\\text{prior}} \\frac{ L(\\boldsymbol \\theta| D) }{ p(D)}\n\\]\ninvolving likelihood \\(L(\\boldsymbol \\theta| D) = \\prod_{=1}^n p(x_i | \\boldsymbol \\theta)\\)\nmarginal likelihoood \\(p(D) = \\int_{\\boldsymbol \\theta} p(\\boldsymbol \\theta) L(\\boldsymbol \\theta| D) d\\boldsymbol \\theta\\) \\(\\boldsymbol \\theta\\) integrated .marginal likelihood serves standardising factor posterior density \\(\\boldsymbol \\theta\\) integrates 1:\n\\[\n\\int_{\\boldsymbol \\theta} p(\\boldsymbol \\theta| D) d\\boldsymbol \\theta= \\frac{1}{p(D)} \\int_{\\boldsymbol \\theta} p(\\boldsymbol \\theta) L(\\boldsymbol \\theta| D) d\\boldsymbol \\theta= 1\n\\]\nUnfortunately, integral compute marginal likelihood typically analytically intractable requires\nnumerical integration /approximation.Comparing likelihood Bayes procedures note thatconducting Bayesian statistical analysis requires integration respectively averaging (compute marginal likelihood)contrast likelihood analysis requires optimisation (find maximum likelihood).","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"sequential-updates","chapter":"9 Essentials of Bayesian statistics","heading":"9.1.4 Sequential updates","text":"Note Bayesian update procedure can repeated : can use posterior new prior update data. Thus, may also update posterior density sequentially, data points \\(x_1, \\ldots, x_n\\) arriving one , computing first \\(p(\\boldsymbol \\theta| x_1)\\), \\(p(\\boldsymbol \\theta| x_1, x_2)\\) reach \\(p(\\boldsymbol \\theta| x_1, \\ldots, x_n) = p(\\boldsymbol \\theta| D)\\).example, first update \n\\[\np(\\boldsymbol \\theta| x_1) =  p(\\boldsymbol \\theta)   \\frac{p(x_1 | \\boldsymbol \\theta)  }{p(x_1)}\n\\]\n\\(p(x_1) =\\int_{\\boldsymbol \\theta} p(x_1 | \\boldsymbol \\theta) p(\\boldsymbol \\theta) d\\boldsymbol \\theta\\).\nsecond update yields\n\\[\n\\begin{split}\np(\\boldsymbol \\theta| x_1, x_2) &=  p(\\boldsymbol \\theta| x_1)   \\frac{p(x_2 | \\boldsymbol \\theta, x_1)  }{p(x_2| x_1)}\\\\\n&= p(\\boldsymbol \\theta| x_1)   \\frac{p(x_2 | \\boldsymbol \\theta)  }{p(x_2| x_1)}\\\\\n&=  p(\\boldsymbol \\theta) \\frac{  p(x_1 | \\boldsymbol \\theta)    p(x_2 | \\boldsymbol \\theta)  }{p(x_1) p(x_2| x_1)}\\\\\n\\end{split}\n\\]\n\\(p(x_2| x_1) = \\int_{\\boldsymbol \\theta} p(x_2 | \\boldsymbol \\theta) p(\\boldsymbol \\theta| x_1) d\\boldsymbol \\theta\\).\nfinal step \n\\[\n\\begin{split}\np(\\boldsymbol \\theta| D)  = p(\\boldsymbol \\theta| x_1, \\ldots, x_n) &=   p(\\boldsymbol \\theta) \\frac{ \\prod_{=1}^n p(x_i | \\boldsymbol \\theta)  }{ p(D)  }\\\\\n\\end{split}\n\\]\nmarginal likelihood factorising \n\\[\np(D) = \\prod_{=1}^n p(x_i| x_{<})\n\\]\n\n\\[\np(x_i| x_{<}) = \\int_{\\boldsymbol \\theta} p(x_i | \\boldsymbol \\theta) p(\\boldsymbol \\theta| x_{<}) d\\boldsymbol \\theta\n\\]\nlast factor posterior predictive density new data \\(x_i\\) seeing data \\(x_1, \\ldots, x_{-1}\\) (given model class \\(M\\)).\nstraightforward understand probability new \\(x_i\\) depends previously observed data points — uncertainty model parameter \\(\\boldsymbol \\theta\\) depends much data already observed. Therefore marginal likelihood \\(p(D)\\) simply product\nmarginal densities \\(p(x_i)\\) \\(x_i\\) instead product conditional densities \\(p(x_i| x_{<})\\).parameter fully known uncertainty \\(\\boldsymbol \\theta\\) observations\n\\(x_i\\) independent. leads back standard likelihood condition particular \\(\\boldsymbol \\theta\\) likelihood product \\(p(D| \\boldsymbol \\theta) = \\prod_{=1}^n p(x_i| \\boldsymbol \\theta)\\).","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"summaries-of-posterior-distributions-and-credible-intervals","chapter":"9 Essentials of Bayesian statistics","heading":"9.1.5 Summaries of posterior distributions and credible intervals","text":"Bayesian estimate full complete posterior distribution!However, useful summarise aspects posterior distribution:Posterior mean \\(\\text{E}(\\boldsymbol \\theta| D)\\)Posterior variance \\(\\text{Var}(\\boldsymbol \\theta| D)\\)Posterior mode\netc.particular mean posterior distribution often taken Bayesian point estimate.posterior distribution also allows define credible regions credible intervals.\nBayesian equivalent confidence intervals constructed \nfinding areas highest probability mass (say 95%) posterior distribution.Bayesian credible intervals (unlike frequentist confidence counterparts) thus easy interpret - simply correspond area parameter space can find parameter given specified probability.\ncontrast, frequentist statistics make sense assign \nprobability parameter value!Note typically many credible intervals given specified coverage \\(\\alpha\\) (say 95%). Therefore, may need criteria\nconstruct intervals.univariate parameter \\(\\theta\\) two-sided equal-tail credible interval obtained finding corresponding lower \\(1-\\alpha/2\\)\nupper \\(\\alpha/2\\) quantiles. Typically type credible interval easy compute. However, note density values left right boundary points interval typically different.\nAlso generalise well multivariate parameter \\(\\boldsymbol \\theta\\).alternative, highest posterior density (HPD) credible interval coverage \\(\\alpha\\) found identifying shortest interval (.e. smallest support) given \\(\\alpha\\)\nprobability mass. point within HDP credible interval higher density point outside HDP credible interval. Correspondingly, density\nboundary HPD credible interval constant taking value everywhere along boundary.Bayesian HPD credible interval constructed similar fashion likelihood-based confidence interval, starting mode posterior density looking common threshold value density define boundary credible interval. posterior density multiple modes HPD interval may disjoint. HPD intervals also well defined multivariate \\(\\boldsymbol \\theta\\) boundaries given contour lines posterior density resulting threshold value.Worksheet B1 examples types credible intervals given compared visually.","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"practical-application-of-bayes-statistics-on-the-computer","chapter":"9 Essentials of Bayesian statistics","heading":"9.1.6 Practical application of Bayes statistics on the computer","text":"seen Bayesian learning conceptually straightforward:Specify prior uncertainty \\(p(\\boldsymbol \\theta\\)) parameters interest \\(\\boldsymbol \\theta\\).Specify data generating process specified parameter: \\(p(x | \\boldsymbol \\theta)\\).Apply Bayes’ theorem update prior uncertainty light\nnew data.practise, however, computing posterior distribution can computationally demanding, especially\ncomplex models.reason specialised software packages developed computational Bayesian modelling, example:Bayesian statistics R: https://cran.r-project.org/web/views/Bayesian.htmlBayesian statistics R: https://cran.r-project.org/web/views/Bayesian.htmlStan probabilistic programming language (interfaces R, Python, Julia languages) — https://mc-stan.org/Stan probabilistic programming language (interfaces R, Python, Julia languages) — https://mc-stan.org/Bayesian statistics Python:\nPyMC using Aesara/JAX backend,\nNumPyro using JAX backend,\nTensorFlow Probability JAX using JAX backend,\nPyMC3 using Theano backend,\nPyro using PyTorch backend,\nTensorFlow Probability using Tensorflow backend.Bayesian statistics Python:\nPyMC using Aesara/JAX backend,\nNumPyro using JAX backend,\nTensorFlow Probability JAX using JAX backend,\nPyMC3 using Theano backend,\nPyro using PyTorch backend,\nTensorFlow Probability using Tensorflow backend.Bayesian statistics Julia: Turing.jlBayesian statistics Julia: Turing.jlBayesian hierarchical modelling BUGS, JAGS NIMBLE.Bayesian hierarchical modelling BUGS, JAGS NIMBLE.addition numerical procedures sample posterior distribution also many procedures aiming approximate Bayesian posterior, employing Laplace approximation, integrated nested Laplace approximation (INLA), variational Bayes etc.","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"some-background-on-bayesian-statistics","chapter":"9 Essentials of Bayesian statistics","heading":"9.2 Some background on Bayesian statistics","text":"","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"bayesian-interpretation-of-probability","chapter":"9 Essentials of Bayesian statistics","heading":"9.2.1 Bayesian interpretation of probability","text":"","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"what-makes-you-bayesian","chapter":"9 Essentials of Bayesian statistics","heading":"9.2.1.1 What makes you “Bayesian”?","text":"use Bayes’ theorem therefore automatically Bayesian? !!Bayes’ theorem mathematical fact probability theory.\nHence, Bayes’ theorem valid everyone, whichever form \nstatistical learning subscribing (frequentist ideas,\nlikelihood methods, entropy learning, Bayesian learning).discuss now key difference Bayesian frequentist\nstatistical learning lies differences interpretation probability,\nmathematical formalism probability (includes Bayes’ theorem).","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"mathematics-of-probability","chapter":"9 Essentials of Bayesian statistics","heading":"9.2.1.2 Mathematics of probability","text":"mathematics probability modern foundation developed Andrey Kolmogorov (1903–1987). book Foundations Theory Probability (1933) establishes probability terms set theory/ measure theory. theory provides coherent mathematical framework work probabilities.However, Kolmogorov’s theory provide interpretation probability!\\(\\rightarrow\\) Kolmogorov framework basis frequentist Bayesian interpretation probability.","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"interpretations-of-probability","chapter":"9 Essentials of Bayesian statistics","heading":"9.2.1.3 Interpretations of probability","text":"Essentially, two major commonly used interpretation probability statistics - frequentist interpretation Bayesian interpretation.: Frequentist interpretationprobability = frequency (event long-running series identically repeated experiments)ontological view probability (.e. probability “exists” identical something can observed.).also restrictive view probability. example, frequentist probability\nused describe events occur single time.\nFrequentist probability thus can applied asymptotically, large samples!B: Bayesian probability“Probability exist” — famous quote Bruno de Finetti (1906–1985), Bayesian statistician.mean?Probability description state knowledge uncertainty.Probability thus epistemological quantity assigned changes rather something inherent property object.Note require repeated experiments.\nBayesian interpretation probability valid regardless sample size number repetitions experiment.Hence, key difference frequentist Bayesian approaches use Bayes’ theorem.\nRather whether consider probability ontological (frequentist) epistemological entity (Bayesian).","code":""},{"path":"essentials-of-bayesian-statistics.html","id":"historical-developments","chapter":"9 Essentials of Bayesian statistics","heading":"9.2.2 Historical developments","text":"Bayesian statistics named Thomas Bayes (1701-1761). paper 8 introducing famous theorem published death (1763).Pierre-Simon Laplace (1749-1827) first practically use Bayes’ theorem statistical calculations, also independently discovered Bayes’ theorem 1774 9This activity called “inverse probability” “Bayesian statistics”.activity called “inverse probability” “Bayesian statistics”.1900 1940 classical mathematical statistics developed field heavily influenced dominated R.. Fisher (invented likelihood theory ANOVA, among things - also working biology professor genetics). Fisher much opposed Bayesian statistics.1900 1940 classical mathematical statistics developed field heavily influenced dominated R.. Fisher (invented likelihood theory ANOVA, among things - also working biology professor genetics). Fisher much opposed Bayesian statistics.1931 Bruno de Finetti publishes “representation theorem”. shows joint distribution sequence exchangeable events (.e. ordering can permuted) can represented mixture distribution can constructed via Bayes’ theorem. (Note exchangeability weaker condition ..d.)\ntheorem often used justification Bayesian statistics (along -called Dutch book argument, also de Finetti).1931 Bruno de Finetti publishes “representation theorem”. shows joint distribution sequence exchangeable events (.e. ordering can permuted) can represented mixture distribution can constructed via Bayes’ theorem. (Note exchangeability weaker condition ..d.)\ntheorem often used justification Bayesian statistics (along -called Dutch book argument, also de Finetti).1933 publication Andrey Kolmogorov’s book probability theory.1933 publication Andrey Kolmogorov’s book probability theory.1946 Cox theorem Richard T. Cox (1898–1991): aim generalise classical logic TRUE/FALSE statements continuous measures uncertainty inevitably leads probability theory Bayesian learning! justification Bayesian statistics later popularised Edwin T. Jaynes (1922–1998) various books (1959, 2003).1946 Cox theorem Richard T. Cox (1898–1991): aim generalise classical logic TRUE/FALSE statements continuous measures uncertainty inevitably leads probability theory Bayesian learning! justification Bayesian statistics later popularised Edwin T. Jaynes (1922–1998) various books (1959, 2003).1955 Stein Paradox - Charles M. Stein (1920–2016) publishes paper Stein estimator — estimator mean dominates ML estimator (.e. sample average). Stein estimator better terms MSE ML estimator, puzzling time easy understand Bayesian perspective.1955 Stein Paradox - Charles M. Stein (1920–2016) publishes paper Stein estimator — estimator mean dominates ML estimator (.e. sample average). Stein estimator better terms MSE ML estimator, puzzling time easy understand Bayesian perspective.1950s use term “Bayesian statistics” became prevalent —\nsee Fienberg (2006) 10Only 1950s use term “Bayesian statistics” became prevalent —\nsee Fienberg (2006) 10Due advances personal computing 1970 onwards Bayesian learning become pervasive!Computers allow complex (numerical) calculations needed Bayesian statistics .Metropolis-Hastings algorithm published 1970 (allows sample posterior distribution without explicitly computing marginal likelihood).Development regularised estimation techniques penalised likelihood regression (e.g. ridge regression 1970).penalised likelihood via KL divergence model selection (Akaike 1973).lot work interpreting Stein estimators empirical Bayes estimators (Efron Morris 1975)regularisation originally meant make singular systems/matrices invertible, turned regularisation also Bayesian interpretation.Reference priors (Bernardo 1979) proposed default priors models multiple parameters.EM algorithm (published 1977) uses Bayes theorem imputing distribution latent variables.Another boost 1990/2000s science (e.g. genomics) many complex high-dimensional data set becoming norm, exception.Classical statistical methods used setting (overfitting!) new methods developed high-dimensional data analysis, many direct link Bayesian statistics1996 lasso (L1 regularised) regression invented Robert Tibshirani.Machine learning methods non-parametric extremely highly parametric models (neural network) require either explicit implicit regularisation.Many Bayesians field, many using variational Bayes techniques may viewed generalisation EM algorithm also linked methods used statistical physics.","code":""},{"path":"bayesian-learning-in-practise.html","id":"bayesian-learning-in-practise","chapter":"10 Bayesian learning in practise","heading":"10 Bayesian learning in practise","text":"chapter discuss three basic problems, namely estimate proportion, mean variance Bayesian framework.","code":""},{"path":"bayesian-learning-in-practise.html","id":"estimating-a-proportion-using-the-beta-binomial-model","chapter":"10 Bayesian learning in practise","heading":"10.1 Estimating a proportion using the beta-binomial model","text":"","code":""},{"path":"bayesian-learning-in-practise.html","id":"binomial-likelihood","chapter":"10 Bayesian learning in practise","heading":"10.1.1 Binomial likelihood","text":"order apply Bayes’ theorem first need find suitable\nlikelihood. use Bernoulli model Example 3.1:Repeated Bernoulli experiment (binomial model):Bernoulli data generating process:\n\\[\nx  \\sim \\text{Ber}(\\theta)\n\\]\\(x \\\\{0, 1\\}\\) (e.g. “success” vs. “failure”)“success” indicated outcome \\(x=1\\) “failure” \\(x=0\\)Parameter: \\(\\theta\\) probability “success”probability mass function (PMF): \\(\\text{Pr}(x=1) = \\theta\\), \\(\\text{Pr}(x=0) = 1-\\theta\\)Mean: \\(\\text{E}(x) = \\theta\\)Variance \\(\\text{Var}(x) = \\theta (1-\\theta)\\)Binomial model \\(\\text{Bin}(n,\\theta)\\) (sum \\(n\\) Bernoulli experiments):\\(y \\\\{0, 1, \\ldots, n\\} = \\sum_{=1}^n x_i\\)Mean: \\(\\text{E}(y) = n \\theta\\)Variance: \\(\\text{Var}(y) = n \\theta (1-\\theta)\\)Mean standardised \\(y\\): \\(\\text{E}(y/n) = \\theta\\)Variance standardised \\(y\\): \\(\\text{Var}(y/n) = \\frac{\\theta (1-\\theta)}{n}\\)Maximum likelihood estimate \\(\\theta\\):conduct \\(n\\) Bernoulli trials observe data \\(D = \\{x_1, \\ldots, x_n\\}\\)\naverage \\(\\bar{x}\\) \\(n_1\\) successes \\(n_2 = n-n_1\\) failures.Binomial likelihood:\n\\[\nL(\\theta|D) = \\begin{pmatrix} n \\\\ n_1 \\end{pmatrix} \\theta^{n_1} (1-\\theta)^{n_2}\n\\]\nNote binomial coefficient arises ordering \\(x_i\\) \nirrelevant may discarded contain parameter \\(\\theta\\).Example 3.1 know maximum likelihood estimate \nproportion \\(\\theta\\) frequency\n\\[\\hat{\\theta}_{ML} = \\frac{n_1}{n} = \\bar{x}\\]\nThus, MLE \\(\\hat{\\theta}_{ML}\\) can expressed average\n(individual data points). seemingly trivial\nfact important Bayesian estimation \\(\\theta\\) using linear shrinkage, \nbecome evident .","code":""},{"path":"bayesian-learning-in-practise.html","id":"beta-prior-distribution","chapter":"10 Bayesian learning in practise","heading":"10.1.2 Beta prior distribution","text":"Bayesian statistics need specify data generating process\nalso prior distribution parameters likelihood function.Therefore, need explicitly specify prior uncertainty \\(\\theta\\).parameter \\(\\theta\\) support \\([0,1]\\). Therefore may use beta distribution\n\\(\\text{Beta}(\\alpha_1, \\alpha_2)\\) prior \\(\\theta\\) (see Appendix properties distribution). see beta distribution \nnatural choice prior conjunction binomial likelihood.parameters prior\n(\\(\\alpha_1 \\geq 0\\) \\(\\alpha_2 \\geq 0\\)) also known hyperparameters\nmodel distinguish parameters likelihood function (\\(\\theta\\)).write prior distribution\n\\[\n\\theta \\sim \\text{Beta}(\\alpha_1, \\alpha_2)\n\\]\ndensity\n\\[\np(\\theta) = \\frac{1}{B(\\alpha_1, \\alpha_2)} \\theta^{\\alpha_1-1} (1-\\theta)^{\\alpha_2-1}\n\\]terms mean parameterisation \\(\\text{Beta}(\\mu_0, k_0)\\) corresponds :prior concentration parameter set \\(k_0 = \\alpha_1 + \\alpha_2\\)prior mean parameter set \\(\\mu_0 = \\alpha_1 / k_0\\).prior mean therefore\n\\[\n\\text{E}(\\theta) = \\mu_0\n\\]\nprior variance\n\\[\n\\text{Var}(\\theta)  = \\frac{\\mu_0 (1-\\mu_0)}{k_0 + 1}\n\\]important actually mean \\(\\theta\\) random.\nmeans model uncertainty \\(\\theta\\) using beta-distributed random variable. flexibility beta distribution allows accommodate large variety possible scenarios prior knowledge using just two parameters.Note mean variance beta prior mean variance standardised\nbinomial variable \\(y/n\\) form. indication binomial\nlikelihood beta prior well matched — see discussion “conjugate priors”.","code":""},{"path":"bayesian-learning-in-practise.html","id":"computing-the-posterior-distribution","chapter":"10 Bayesian learning in practise","heading":"10.1.3 Computing the posterior distribution","text":"observing data \\(D = \\{x_1, \\ldots, x_n\\}\\) \\(n_1\\) “successes”\n\\(n_2 = n-n_1\\) “failures”\ncan compute posterior\ndensity \\(\\theta\\) using Bayes’ theorem:\n\\[\np(\\theta| D) = \\frac{p(\\theta) L(\\theta | D) }{p(D)}\n\\]Applying Bayes’ theorem results posterior distribution:\n\\[\n\\theta| D \\sim \\text{Beta}(\\alpha_1+n_2, \\alpha_2+n_2)\n\\]\ndensity\n\\[\np(\\theta| D) = \\frac{1}{B(\\alpha_1+n_1, \\alpha_2+n_2)} \\theta^{\\alpha_1+n_1-1} (1-\\theta)^{\\alpha_2+n_2-1}\n\\]\n(proof see Worksheet B1.)corresponding mean parameterisation \\(\\text{Beta}(\\mu_1, k_1)\\) results following updates:concentration parameter updated \\(k_1 = k_0+n\\)mean parameter updated \n\\[\n\\mu_1 = \\frac{\\alpha_1 + n_1}{k_1}\n\\]\ncan written \n\\[\n\\begin{split}\n\\mu_1 & =  \\frac{\\alpha_1}{k_1}  + \\frac{n_1}{k_1}\\\\\n    & =  \\frac{k_0}{k_1} \\frac{\\alpha_1}{k_0}   + \\frac{n}{k_1} \\frac{n_1}{n}\\\\\n    & = \\lambda \\mu_0 + (1-\\lambda) \\hat{\\theta}_{ML}\\\\\n\\end{split}\n\\]\n\\(\\lambda = \\frac{k_0}{k_1}\\). Hence, \\(\\mu_1\\) \nconvex combination prior mean MLE.Therefore, posterior mean \n\\[\n\\text{E}(\\theta | D) = \\mu_1\n\\]\nposterior variance \n\\[\n\\text{Var}(\\theta | D)\n= \\frac{\\mu_1 (1-\\mu_1)}{k_1+1 }\n\\]","code":""},{"path":"bayesian-learning-in-practise.html","id":"properties-of-bayesian-learning","chapter":"10 Bayesian learning in practise","heading":"10.2 Properties of Bayesian learning","text":"beta-binomial model, even though one simplest possible models, already allows observe number important features properties Bayesian learning. Many apply also models see later.","code":""},{"path":"bayesian-learning-in-practise.html","id":"prior-acting-as-pseudodata","chapter":"10 Bayesian learning in practise","heading":"10.2.1 Prior acting as pseudodata","text":"expression mean variance can see \nconcentration parameter \\(k_0=\\alpha_1 + \\alpha_2\\) behaves like \nimplicit sample size connected prior information \\(\\theta\\).Specifically, \\(\\alpha_1\\) \\(\\alpha_2\\) act pseudocounts influence\nposterior mean posterior variance, exactly way conventional\nobservations.example, larger \\(k_0\\) (thus larger \\(\\alpha_1\\) \\(\\alpha_2\\)) smaller posterior variance, variance decreasing proportional inverse \\(k_0\\). prior highly concentrated, .e. low variance large precision (=inverse variance) implicit data size \\(k_0\\) large. Conversely, prior large variance, prior vague implicit data size \\(k_0\\) small.Hence, prior effect one add data — without actually adding data! precisely prior acts regulariser prevents overfitting, increases effective sample size.Another interpretation prior summarises data\nmay available previously observations.","code":""},{"path":"bayesian-learning-in-practise.html","id":"linear-shrinkage-of-mean","chapter":"10 Bayesian learning in practise","heading":"10.2.2 Linear shrinkage of mean","text":"beta-binomial model posterior mean convex combination (.e. weighted average) ML estimate prior mean can seen update formula\n\\[\n\\mu_1 = \\lambda \\mu_0 + (1-\\lambda) \\hat{\\theta}_{ML}\n\\]\nweight \\(\\lambda \\[0,1]\\)\n\\[\n\\lambda = \\frac{k_0}{k_1} \\,.\n\\]\nThus, posterior mean \\(\\mu_1\\) linearly adjusted \\(\\hat{\\theta}_{ML}\\). factor \\(\\lambda\\) called shrinkage intensity — note ratio “prior sample size” (\\(k_0\\)) “effective total sample size” (\\(k_1\\)).adjustment MLE called shrinkage, \\(\\hat{\\theta}_{ML}\\) “shrunk” towards prior mean \\(\\mu_0\\) (often called “target”, sometimes target zero, terminology “shrinking” makes sense).adjustment MLE called shrinkage, \\(\\hat{\\theta}_{ML}\\) “shrunk” towards prior mean \\(\\mu_0\\) (often called “target”, sometimes target zero, terminology “shrinking” makes sense).shrinkage intensity zero (\\(\\lambda = 0\\)) ML point estimator recovered. happens \\(\\alpha_1=0\\) \\(\\alpha_2=0\\) \\(n \\rightarrow \\infty\\).\nRemark: using maximum likelihood estimate \\(\\theta\\) (moderate small \\(n\\)) Bayesian posterior mean estimation using beta-binomial model prior \\(\\alpha_1=0\\) \\(\\alpha_2=0\\). prior extremely “u-shaped” implicit prior ML estimation. use prior intentionally?shrinkage intensity zero (\\(\\lambda = 0\\)) ML point estimator recovered. happens \\(\\alpha_1=0\\) \\(\\alpha_2=0\\) \\(n \\rightarrow \\infty\\).Remark: using maximum likelihood estimate \\(\\theta\\) (moderate small \\(n\\)) Bayesian posterior mean estimation using beta-binomial model prior \\(\\alpha_1=0\\) \\(\\alpha_2=0\\). prior extremely “u-shaped” implicit prior ML estimation. use prior intentionally?shrinkage intensity large (\\(\\lambda \\rightarrow 1\\)) posterior mean corresponds prior.\nhappens \\(n=0\\) \\(k_0\\) large (implying prior sharply concentrated around prior mean).shrinkage intensity large (\\(\\lambda \\rightarrow 1\\)) posterior mean corresponds prior.\nhappens \\(n=0\\) \\(k_0\\) large (implying prior sharply concentrated around prior mean).Since ML estimate \\(\\hat{\\theta}_{ML}\\) unbiased Bayesian point estimate biased (finite \\(n\\)!). bias induced prior mean deviating true mean. also true generally Bayesian learning typically produces biased estimators (asymptotically unbiased like ML).Since ML estimate \\(\\hat{\\theta}_{ML}\\) unbiased Bayesian point estimate biased (finite \\(n\\)!). bias induced prior mean deviating true mean. also true generally Bayesian learning typically produces biased estimators (asymptotically unbiased like ML).fact posterior mean linear combination MLE prior mean coincidence. fact, true distributions exponential families, see e.g. Diaconis Ylvisaker (1979)11.\nCrucially, exponential families can always parameterised corresponding MLEs expressed averages functions data (technically: MLE mean parameter EF average canonical statistic). conjunction particular type prior (conjugate priors, always existing exponential families, see ) allows write update prior posterior mean linear adjustment MLE.fact posterior mean linear combination MLE prior mean coincidence. fact, true distributions exponential families, see e.g. Diaconis Ylvisaker (1979)11.\nCrucially, exponential families can always parameterised corresponding MLEs expressed averages functions data (technically: MLE mean parameter EF average canonical statistic). conjunction particular type prior (conjugate priors, always existing exponential families, see ) allows write update prior posterior mean linear adjustment MLE.Furthermore, possible (indeed quite useful computational reasons!) formulate Bayes learning assuming first second moments (.e. without full distributions) terms linear shrinkage, see e.g. Hartigan (1969)12. resulting theory called “Bayes linear statistics” (Goldstein Wooff, 2007)13.Furthermore, possible (indeed quite useful computational reasons!) formulate Bayes learning assuming first second moments (.e. without full distributions) terms linear shrinkage, see e.g. Hartigan (1969)12. resulting theory called “Bayes linear statistics” (Goldstein Wooff, 2007)13.","code":""},{"path":"bayesian-learning-in-practise.html","id":"conjugacy-of-prior-and-posterior-distribution","chapter":"10 Bayesian learning in practise","heading":"10.2.3 Conjugacy of prior and posterior distribution","text":"beta-binomial model estimating proportion \\(\\theta\\) choice beta distribution prior distribution along binomial likelihood resulted beta distribution posterior distribution well.prior posterior belong distributional family prior called conjugate prior. case prior functional form likelihood. Therefore one also says prior conjugate likelihood.can shown conjugate priors exist likelihood functions \nbased data generating models exponential families.beta-binomial model likelihood based binomial distribution following form\n(terms depending parameter \\(\\theta\\) shown):\n\\[\n\\theta^{n_1} (1-\\theta)^{n_2}\n\\]\nform beta prior (, showing terms depending \\(\\theta\\)):\n\\[\n\\theta^{\\alpha_1-1} (1-\\theta)^{\\alpha_2-1}\n\\]\nSince posterior proportional product prior\nlikelihood posterior exactly form \nprior:\n\\[\n\\theta^{\\alpha_1+n_1-1} (1-\\theta)^{\\alpha_2+n_2-1}\n\\]\nChoosing prior distribution family conjugate likelihood\ngreatly simplifies Bayesian analysis since Bayes formula can written form update formula parameters beta distribution:\n\\[\n\\alpha_1 \\rightarrow \\alpha_1 + n_1  = \\alpha_1 + n \\hat{\\theta}_{ML}\n\\]\n\\[\n\\alpha_2 \\rightarrow \\alpha_2 + n_2 = \\alpha_2 + n (1-\\hat{\\theta}_{ML})\n\\]Thus, conjugate prior distributions convenient choices. However, application must ensured prior distribution flexible enough encapsulate prior information may available. cases case alternative priors used (likely require compute posterior distribution numerically rather analytically).","code":""},{"path":"bayesian-learning-in-practise.html","id":"large-sample-limits-of-mean-and-variance","chapter":"10 Bayesian learning in practise","heading":"10.2.4 Large sample limits of mean and variance","text":"\\(n\\) large \\(n >> \\alpha, \\beta\\) \\(\\lambda \\rightarrow 0\\)\nhence posterior mean variance become asympotically\\[\n\\text{E}(\\theta| D)  \\overset{}{=} \\frac{n_1 }{n} = \\hat{\\theta}_{ML}\n\\]\n\n\\[\n\\text{Var}(\\theta| D) \\overset{}{=}   \\frac{\\hat{\\theta}_{ML} (1-\\hat{\\theta}_{ML})}{n}\n\\]Thus, sample size large Bayes’ estimator turns ML estimator! Specifically,\nposterior mean becomes ML point estimate, posterior variance equal asymptotic variance computed via observed Fisher information.Thus, large \\(n\\) data dominate details prior (settings hyperparameters \\(\\alpha_1\\) \\(\\alpha_2\\)) become irrelevant!","code":""},{"path":"bayesian-learning-in-practise.html","id":"asymptotic-normality-of-the-posterior-distribution","chapter":"10 Bayesian learning in practise","heading":"10.2.5 Asymptotic normality of the posterior distribution","text":"Also known Bayesian Central Limit Theorem (CLT).regularity conditions (regular likelihood positive prior probability \nparameter values, finite number parameters, etc.) large sample size Bayesian posterior distribution converges normal distribution\ncentred around MLE variance MLE:\\[\n\\text{large $n$:  }  p(\\boldsymbol \\theta| D) \\N(\\hat{\\boldsymbol \\theta}_{ML}, \\text{Var}(\\hat{\\boldsymbol \\theta}_{ML}) )\n\\]posterior mean variance converging MLE variance MLE\nlarge sample size, also posterior distribution converges sampling distribution!holds generally many regular cases, just simple case .Bayesian CLT generally known\nBernstein-von Mises theorem (discovered around 1920–30), special cases already known Laplace.Worksheet B1 asymptotic convergence posterior distribution normal distribution demonstrated graphically.","code":""},{"path":"bayesian-learning-in-practise.html","id":"posterior-variance-for-finite-n","chapter":"10 Bayesian learning in practise","heading":"10.2.6 Posterior variance for finite \\(n\\)","text":"Bayesian posterior can obtain Bayesian point estimate\nproportion \\(\\theta\\) computing posterior mean\n\\[\n\\text{E}(\\theta | D) = \\frac{\\alpha_1+n_1}{k_1} = \\hat{\\theta}_{\\text{Bayes}}\n\\]\nalong posterior variance\n\\[\n\\text{Var}(\\theta | D) = \\frac{\\hat{\\theta}_{\\text{Bayes}} (1-\\hat{\\theta}_{\\text{Bayes}})}{k_1+1}\n\\]Asymptotically large \\(n\\) posterior mean becomes maximum likelihood estimate (MLE), \nposterior variance becomes asymptotic variance MLE.\nThus, large \\(n\\) Bayesian point estimate indistinguishable MLE\nshares favourable properties.addition, finite sample size posterior variance typically smaller asymptotic\nposterior variance (large \\(n\\)) prior variance, showing combining information\navailable prior data leads efficient estimate.","code":""},{"path":"bayesian-learning-in-practise.html","id":"estimating-the-mean-using-the-normal-normal-model","chapter":"10 Bayesian learning in practise","heading":"10.3 Estimating the mean using the normal-normal model","text":"","code":""},{"path":"bayesian-learning-in-practise.html","id":"normal-likelihood","chapter":"10 Bayesian learning in practise","heading":"10.3.1 Normal likelihood","text":"Example 3.2 estimated mean parameter \nmaximum likelihood assume data-generating model normal distribution\nunknown mean \\(\\mu\\) known variance \\(\\sigma^2\\):\n\\[\nx \\sim N(\\mu, \\sigma^2)\n\\]\nobserve \\(n\\) samples \\(D = \\{x_1, \\ldots x_n\\}\\).\nyields using maximum likelihood estimate \\(\\hat{\\mu}_{ML} = \\bar{x}\\).note MLE \\(\\hat\\mu_{ML}\\) expressed average data points,\nenables linear shrinkage seen .","code":""},{"path":"bayesian-learning-in-practise.html","id":"normal-prior-distribution","chapter":"10 Bayesian learning in practise","heading":"10.3.2 Normal prior distribution","text":"normal distribution conjugate distribution mean parameter \nnormal likelihood, use normal prior posterior \\(\\mu\\) normal well.model uncertainty \\(\\mu\\) use normal distribution form\n\\(N(\\mu, \\sigma^2/k)\\) mean parameter \\(\\mu\\) concentration\nparameter \\(k > 0\\) (remember \\(\\sigma^2\\) given also used likelihood).Specifically, use normal prior distribution mean\n\\[\n\\mu \\sim N\\left(\\mu_0, \\frac{\\sigma^2}{k_0}\\right)\n\\]prior concentration parameter set \\(k_0\\)prior mean parameter set \\(\\mu_0\\)Hence prior mean \n\\[\n\\text{E}(\\mu) =  \\mu_0\n\\]\nprior variance\n\\[\n\\text{Var}(\\mu)  = \\frac{\\sigma^2}{k_0}\n\\]\nconcentration parameter \\(k_0\\) corresponds implied sample size prior.\nNote \\(k_0\\) need integer value.","code":""},{"path":"bayesian-learning-in-practise.html","id":"normal-posterior-distribution","chapter":"10 Bayesian learning in practise","heading":"10.3.3 Normal posterior distribution","text":"observing data \\(D\\) posterior distribution\nalso normal updated parameters \\(\\mu=\\mu_1\\) \\(k_1\\)\n\\[\n\\mu | D \\sim N\\left(\\mu_1, \\frac{\\sigma^2}{k_1}\\right)\n\\]posterior concentration parameter updated \\(k_1 = k_0 +n\\)posterior mean parameter updated \n\\[\n\\mu_1 = \\lambda \\mu_0 + (1-\\lambda) \\hat\\mu_{ML}\n\\]\n\\(\\lambda = \\frac{k_0}{k_1}\\).\ncan seen linear shrinkage \n\\(\\hat\\mu_{ML}\\) towards prior mean \\(\\mu_0\\).(proof see Worksheet B2.)posterior mean \n\\[\n\\text{E}(\\mu | D) = \\mu_1\n\\]\nposterior variance \n\\[\n\\text{Var}(\\mu | D)  = \\frac{\\sigma^2}{k_1}\n\\]","code":""},{"path":"bayesian-learning-in-practise.html","id":"large-sample-asymptotics","chapter":"10 Bayesian learning in practise","heading":"10.3.4 Large sample asymptotics","text":"\\(n\\) large \\(n >> k_0\\) shrinkage intensity \\(\\lambda \\rightarrow 0\\)\n\\(k_1 \\rightarrow n\\). result\n\\[\n\\text{E}(\\mu |  D) \\overset{}{=}  \\hat\\mu_{ML}\n\\]\n\\[\n\\text{Var}(\\mu |  D) \\overset{}{=} \\frac{\\sigma^2}{n}\n\\]\n.e. recover MLE asymptotic variance!Note finite \\(n\\) posterior variance \\(\\frac{\\sigma^2}{n+k_0}\\) smaller\nasymptotic variance \\(\\frac{\\sigma^2}{n}\\) MLE prior variance \\(\\frac{\\sigma^2}{k_0}\\).","code":""},{"path":"bayesian-learning-in-practise.html","id":"estimating-the-variance-using-the-inverse-gamma-normal-model","chapter":"10 Bayesian learning in practise","heading":"10.4 Estimating the variance using the inverse-gamma-normal model","text":"","code":""},{"path":"bayesian-learning-in-practise.html","id":"normal-likelihood-1","chapter":"10 Bayesian learning in practise","heading":"10.4.1 Normal likelihood","text":"data generating model use\nnormal distribution\n\\[\nx  \\sim N(\\mu, \\sigma^2)\n\\]\nunknown variance \\(\\sigma^2\\) known mean \\(\\mu\\). yields maximum likelihood estimate variance\n\\[\n\\widehat{\\sigma^2}_{ML}= \\frac{1}{n}\\sum_{=1}^n (x_i-\\mu)^2\n\\]Note , , MLE average (quadratic function \nindividual data points). enables linear shrinkage MLE seen .","code":""},{"path":"bayesian-learning-in-practise.html","id":"ig-prior-distribution","chapter":"10 Bayesian learning in practise","heading":"10.4.2 IG prior distribution","text":"model uncertainty variance use inverse-gamma (IG) distribution, also known\ninverse Wishart (IW) distribution (see Appendix details distribution).\nIG distribution conjugate variance parameter normal likelihood, hence prior posterior distribution IG.\nuse Wishart parameterisation may equally well call \ninverse Wishart (IW) prior, whole model IW-normal model.Specifically, prior distribution \\(\\sigma^2\\) assume using\nmean parameter \\(\\mu\\) concentration parameter \\(\\kappa\\):\n\\[\n\\sigma^2 \\sim  W^{-1}_1(\\psi=\\kappa_0 \\sigma^2_0, \\nu=\\kappa_0+2)\n\\]prior concentration parameter set \\(\\kappa_0\\)prior mean parameter set \\(\\sigma^2_0\\)corresponding prior mean \n\\[\n\\text{E}(\\sigma^2) = \\sigma^2_0\n\\]\nprior variance \n\\[\n\\text{Var}(\\sigma^2) = \\frac{2 \\sigma_0^4}{\\kappa_0-2}\n\\]\n(note \\(\\kappa_0 > 2\\) variance exist)","code":""},{"path":"bayesian-learning-in-practise.html","id":"ig-posterior-distribution","chapter":"10 Bayesian learning in practise","heading":"10.4.3 IG posterior distribution","text":"observing \\(D = \\{ x_1 \\ldots, x_n\\}\\) posterior distribution \nalso IG updated parameters:\n\\[\n\\sigma^2| D \\sim W^{-1}_1(\\psi=\\kappa_1 \\sigma^2_1, \\nu=\\kappa_1+2)\n\\]posterior concentration parameter updated \\(\\kappa_1 = \\kappa_0+n\\)posterior mean parameter update follows standard linear shrinkage rule:\n\\[\n\\sigma^2_1 =  \\lambda \\sigma^2_0 + (1-\\lambda) \\widehat{\\sigma^2}_{ML}\n\\]\n\\(\\lambda=\\frac{\\kappa_0}{\\kappa_1}\\).posterior mean \n\\[\n\\text{E}(\\sigma^2 | D) = \\sigma^2_1\n\\]\nposterior variance\n\\[\n\\text{Var}(\\sigma^2 | D) = \\frac{ 2 \\sigma^4_1}{\\kappa_1-2}\n\\]","code":""},{"path":"bayesian-learning-in-practise.html","id":"large-sample-asymptotics-1","chapter":"10 Bayesian learning in practise","heading":"10.4.4 Large sample asymptotics","text":"large sample size \\(n\\) \\(n >> \\kappa_0\\)\nshrinkage intensity vanishes\n(\\(\\lambda \\rightarrow 0\\)) therefore \\(\\sigma^2_1 \\rightarrow \\widehat{\\sigma^2}_{ML}\\). also find \\(\\kappa_1-2 \\rightarrow n\\).results asymptotic posterior mean\n\\[\n\\text{E}(\\sigma^2 |  D) \\overset{}{=}  \\widehat{\\sigma^2}_{ML}\n\\]\nasymptotic\nposterior variance\n\\[\n\\text{Var}(\\sigma^2 |  D) \\overset{}{=} \\frac{2 (\\widehat{\\sigma^2}_{ML})^2}{n}\n\\]\nThus recover MLE \\(\\sigma^2\\) asymptotic variance.","code":""},{"path":"bayesian-learning-in-practise.html","id":"other-equivalent-update-rules","chapter":"10 Bayesian learning in practise","heading":"10.4.5 Other equivalent update rules","text":"update rule prior posterior inverse gamma distribution \nstated mean parameterisation:\\(\\kappa_0 \\rightarrow \\kappa_1 = \\kappa_0+n\\)\\(\\sigma^2_0 \\rightarrow \\sigma^2_1 = \\lambda \\sigma^2_0 + (1-\\lambda) \\widehat{\\sigma^2}_{ML}\\) \n\\(\\lambda=\\frac{\\kappa_0}{\\kappa_1}\\)advantage mean inverse gamma distribution\nupdated directly, prior posterior variance also\nstraightforward compute.update rule can also expressed terms parameterisations.\nterms conventional parameters \\(\\alpha\\) \\(\\beta\\) inverse gamma\ndistribution update rule \\(\\alpha_0 \\rightarrow \\alpha_1 = \\alpha_0 +\\frac{n}{2}\\)\\(\\beta_0 \\rightarrow \\beta_1 = \\beta_0 + \\frac{n}{2} \\widehat{\\sigma^2}_{ML} = \\beta_0 + \\frac{1}{2} \\sum_{=1}^n (x_i-\\mu)^2\\)parameters \\(\\psi\\) \\(\\nu\\) univariate inverse Wishart distribution\nupdate rule \\(\\nu_0 \\rightarrow \\nu_1 = \\nu_0 +n\\)\\(\\psi_0 \\rightarrow \\psi_1 = \\psi_0 + n \\widehat{\\sigma^2}_{ML} = \\psi_0 + \\sum_{=1}^n (x_i-\\mu)^2\\)parameters \\(\\tau^2\\) \\(\\nu\\) scaled inverse chi-squared\ndistribution update rule \\(\\nu_0 \\rightarrow \\nu_1 = \\nu_0 +n\\)\\(\\tau^2_0 \\rightarrow \\tau^2_1 = \\frac{\\nu_0}{\\nu_1} \\tau^2_0 + \\frac{n}{\\nu_1} \\widehat{\\sigma^2}_{ML}\\)(See Worksheet B3 proof equivalence update rules.)","code":""},{"path":"bayesian-learning-in-practise.html","id":"estimating-the-precision-using-the-gamma-normal-model","chapter":"10 Bayesian learning in practise","heading":"10.5 Estimating the precision using the gamma-normal model","text":"","code":""},{"path":"bayesian-learning-in-practise.html","id":"mle-of-the-precision","chapter":"10 Bayesian learning in practise","heading":"10.5.1 MLE of the precision","text":"Instead estimating variance \\(\\sigma^2\\) may wish estimate precision \\(w1/\\sigma^2\\), .e. inverse variance.data generating model \nnormal distribution\n\\[\nx  \\sim N(\\mu, 1/w)\n\\]\nunknown precision \\(w\\) known mean \\(\\mu\\). yields maximum likelihood estimate\n(easily derived thanks invariance principle)\n\\[\n\\hat{w}_{ML} =  \\frac{ 1}{\\widehat{\\sigma^2}_{ML} } = \\frac{1}{\\frac{1}{n}\\sum_{=1}^n (x_i-\\mu)^2}\n\\]\nCrucially, MLE precision \\(w\\) average (instead, function average).\nconsequence, seen , posterior mean \\(w\\) written linear adjustment MLE.","code":""},{"path":"bayesian-learning-in-practise.html","id":"gamma-wishart-prior","chapter":"10 Bayesian learning in practise","heading":"10.5.2 Gamma (Wishart) prior","text":"modelling variance used inverse gamma (inverse Wishart) distribution prior posterior distributions. Thus, order model precision therefore now use gamma (Wishart) distribution.Specifically, use Wishart distribution mean parameterisation (see Appendix):\n\\[\nw \\sim  W_1(s^2 = w_0/k_0, k=k_0)\n\\]prior concentration parameter set \\(k_0\\)prior mean parameter set \\(w_0\\)corresponding prior mean \n\\[\n\\text{E}(w) = w_0\n\\]\nprior variance \n\\[\n\\text{Var}(\\sigma^2) = 2 w_0^2/ k_0\n\\]","code":""},{"path":"bayesian-learning-in-practise.html","id":"gamma-wishart-posterior","chapter":"10 Bayesian learning in practise","heading":"10.5.3 Gamma / Wishart posterior","text":"observing \\(D = \\{ x_1 \\ldots, x_n\\}\\) posterior distribution \nalso gamma resp. Wishart updated parameters:\\[\nw | D \\sim   W_1(s^2 = w_1/k_1, k=k_1)\n\\]posterior concentration parameter updated \\(k_1 = k_0+n\\)posterior mean parameter update follows update:\n\\[\n\\frac{1}{w_1} =  \\lambda \\frac{1}{w_0}  + (1-\\lambda)  \\frac{1}{\\hat{w}_{ML}}\n\\]\n\\(\\lambda = \\frac{k_0}{k_1}\\).\nCrucially, linear update applied inverse precision\nprecision . MLE precision parameter expressed average.Equivalent update rules inverse scale parameter \\(s^2\\)\n\\[\n\\frac{1}{s^2_1} =  \\frac{1}{s^2_0}  + n \\widehat{\\sigma^2}_{ML}\n\\]\nrate parameter \\(\\beta = 1/(2 s^2)\\) gamma distribution\n\\[\n\\beta_1 =  \\beta_0 + \\frac{n}{2} \\widehat{\\sigma^2}_{ML}\n\\]\nform find often textbooks.posterior mean \n\\[\n\\text{E}(w | D) = w_1\n\\]\nposterior variance\n\\[\n\\text{Var}(w | D) = 2 w_1^2/ k_1\n\\]","code":""},{"path":"bayesian-model-comparison.html","id":"bayesian-model-comparison","chapter":"11 Bayesian model comparison","heading":"11 Bayesian model comparison","text":"","code":""},{"path":"bayesian-model-comparison.html","id":"marginal-likelihood-as-model-likelihood","chapter":"11 Bayesian model comparison","heading":"11.1 Marginal likelihood as model likelihood","text":"","code":""},{"path":"bayesian-model-comparison.html","id":"simple-and-composite-models","chapter":"11 Bayesian model comparison","heading":"11.1.1 Simple and composite models","text":"introduction Bayesian learning already encountered marginal likelihood \\(p(D | M)\\) model class \\(M\\) denominator Bayes’ rule:\n\\[\np(\\boldsymbol \\theta| D, M) =  \\frac{p(\\boldsymbol \\theta| M)  p(D | \\boldsymbol \\theta, M) }{p(D | M)}\n\\]\nComputing marginal likelihood different simple composite models.model called “simple” directly corresponds specific distribution,\nsay, normal distribution fixed mean variance, binomial distribution given probability two classes. Thus, simple model point model space described parameters distribution family (e.g.\n\\(\\mu\\) \\(\\sigma^2\\) normal family \\(N(\\mu, \\sigma^2\\)). simple model \\(M\\) density\n\\(p(D | M)\\) corresponds standard likelihood \\(M\\) free parameters.hand, model “composite” composed simple models. can finite set, can comprised infinite number simpple models. Thus composite model\nrepresent model class.\nexample, normal distribution given mean unspecified variance, binomial model unspecified class probability, composite model.\\(M\\) composite model, underlying simple models indexed \nparameter \\(\\boldsymbol \\theta\\), likelihood model \nobtained marginalisation \\(\\boldsymbol \\theta\\):\n\\[\n\\begin{split}\np(D | M) &= \\int_{\\boldsymbol \\theta} p(D | \\boldsymbol \\theta, M) p(\\boldsymbol \\theta| M) d\\boldsymbol \\theta\\\\\n             &= \\int_{\\boldsymbol \\theta} p(D , \\boldsymbol \\theta| M) d\\boldsymbol \\theta\\\\\n\\end{split}\n\\]\n.e. integrate parameter values \\(\\boldsymbol \\theta\\).distribution parameter \\(\\boldsymbol \\theta\\) model strongly concentrated around specific value \\(\\boldsymbol \\theta_0\\) composite model degenerates simple point model, marginal likelihood becomes\nlikelihood parameter \\(\\boldsymbol \\theta_0\\) model.Example 11.1  Beta-binomial distribution:Assume likelihood binomial mean parameter \\(\\theta\\). \\(\\theta\\) follows\nBeta distribution marginal likelihood \\(\\theta\\) integrated \nbeta-binomial distribution (see also Worksheet B3).\nexample compound probability distribution.","code":""},{"path":"bayesian-model-comparison.html","id":"log-marginal-likelihood-as-penalised-maximum-log-likelihood","chapter":"11 Bayesian model comparison","heading":"11.1.2 Log-marginal likelihood as penalised maximum log-likelihood","text":"rearranging Bayes’ rule see \n\\[\n\\log p(D | M) =  \\log p(D | \\boldsymbol \\theta, M) - \\log  \\frac{ p(\\boldsymbol \\theta| D, M) }{p(\\boldsymbol \\theta| M)  }\n\\]\nvalid \\(\\boldsymbol \\theta\\).Assuming concentration posterior around MLE \\(\\hat{\\boldsymbol \\theta}_{\\text{ML}}\\) \\(p(\\hat{\\boldsymbol \\theta}_{\\text{ML}} | D, M)> p(\\hat{\\boldsymbol \\theta}_{\\text{ML}}| M)\\)\nthus\n\\[\n\\log p(D | M) =  \\underbrace{\\log p(D | \\hat{\\boldsymbol \\theta}_{\\text{ML}}, M)}_{\\text{maximum log-likelihood}}\n- \\underbrace{ \\log  \\frac{ p( \\hat{\\boldsymbol \\theta}_{\\text{ML}} | D, M) }{p( \\hat{\\boldsymbol \\theta}_{\\text{ML}}| M)  } }_{\\text{penalty > 0}}\n\\]\nTherefore, log-marginal likelihood essentially penalised version maximum log-likelihood, penalty depends concentration posterior\naround MLE","code":""},{"path":"bayesian-model-comparison.html","id":"model-complexity-and-occams-razor","chapter":"11 Bayesian model comparison","heading":"11.1.3 Model complexity and Occams razor","text":"Intriguingly, penality implicit log-marginal likelihood linked complexity model, particular number parameters \\(M\\).\nsee directly Schwarz approximation \nlog-marginal likelihood discussed .Thus, averaging \\(\\boldsymbol \\theta\\) marginal likelihood effect automatically penalising complex models.\nTherefore, comparing models using marginal likelihood complex model may ranked simpler models.\ncontrast, selecting model comparing maximum likelihood directly model highest number parameters always wins simpler models.\nHence, penalisation implicit marginal likelihood prevents overfitting\noccurs maximum likelihood.principle preferring less complex model called Occam’s razor\nlaw parsimony.choosing models simpler model often preferable complex model, simpler model typically better suited explaining currently observed data well future data, whereas complex model typically excel fitting current data perform poorly prediction.","code":""},{"path":"bayesian-model-comparison.html","id":"the-bayes-factor-for-comparing-two-models","chapter":"11 Bayesian model comparison","heading":"11.2 The Bayes factor for comparing two models","text":"","code":""},{"path":"bayesian-model-comparison.html","id":"definition-of-the-bayes-factor","chapter":"11 Bayesian model comparison","heading":"11.2.1 Definition of the Bayes factor","text":"Bayes factor ratio likelihoods\ntwo models:\n\\[\nB_{12} = \\frac{p(D | M_1)}{p(D | M_2)}\n\\]log-Bayes factor\n\\(\\log B_{12}\\)\nalso called weight evidence \\(M_1\\) \\(M_2\\).","code":""},{"path":"bayesian-model-comparison.html","id":"bayes-theorem-in-terms-of-the-bayes-factor","chapter":"11 Bayesian model comparison","heading":"11.2.2 Bayes theorem in terms of the Bayes factor","text":"like compare two models \\(M_1\\) \\(M_2\\). seeing data \\(D\\) can check Prior odds (= ratio prior probabilities models \\(M_1\\) \\(M_2\\)):\\[\\frac{\\text{Pr}(M_1)}{\\text{Pr}(M_2)}\\]seeing data \\(D = \\{x_1, \\ldots, x_n\\}\\) arrive Posterior odds (= ratio posterior probabilities):\n\\[\\frac{\\text{Pr}(M_1 | D)}{\\text{Pr}(M_2  | D)}\\]Using Bayes Theorem \\(\\text{Pr}(M_i | D) = \\text{Pr}(M_i) \\frac{p(D | M_i) }{p(D)}\\) can rewrite \nposterior odds \n\\[\n\\underbrace{\\frac{\\text{Pr}(M_1 | D)}{\\text{Pr}(M_2 | D)}}_{\\text{posterior odds}} = \\underbrace{\\frac{p(D | M_1)}{p(D | M_2)}}_{\\text{Bayes factor $B_{12}$}} \\,\n\\underbrace{\\frac{\\text{Pr}(M_1)}{\\text{Pr}(M_2)}}_{\\text{prior odds}}\n\\]Bayes factor multiplicative factor updates prior odds posterior odds.log scale see \\[\n\\text{log-posterior odds = weight evidence + log-prior odds}\n\\]","code":""},{"path":"bayesian-model-comparison.html","id":"scale-for-the-bayes-factor","chapter":"11 Bayesian model comparison","heading":"11.2.3 Scale for the Bayes factor","text":"Following Harold Jeffreys (1961) 14 one may interpret strength Bayes factor follows:recently, Kass Raftery (1995) 15 proposed use following slightly modified scale:","code":""},{"path":"bayesian-model-comparison.html","id":"bayes-factor-versus-likelihood-ratio","chapter":"11 Bayesian model comparison","heading":"11.2.4 Bayes factor versus likelihood ratio","text":"\\(M_1\\) \\(M_2\\) simple models Bayes factor identical likelihood ratio two models.However, one two models composite Bayes factor \ngeneralised likelihood ratio differ:\nBayes factor representative composite model \nmodel average simple models indexed \\(\\boldsymbol \\theta\\), weights\ntaken prior distribution simple models contained \\(M\\). contrast, generalised likelihood ratio statistic representative composite model chosen maximisation.Thus, composite models, Bayes factor equal corresponding generalised likelihood ratio statistic. fact, key difference Bayes factor penalised version likelihood ratio, penality\ndepending difference complexity (number parameters) two models","code":""},{"path":"bayesian-model-comparison.html","id":"approximate-computations","chapter":"11 Bayesian model comparison","heading":"11.3 Approximate computations","text":"marginal likelihood Bayes factor can difficult compute\npractise. Therefore, number approximations developed.\nimportant -called Schwarz (1978) approximation log-marginal likelihood. used approximate log-Bayes factor also yields\nBIC (Bayesian information criterion) can interpreted penalised maximum\nlikelihood.","code":""},{"path":"bayesian-model-comparison.html","id":"schwarz-1978-approximation-of-log-marginal-likelihood","chapter":"11 Bayesian model comparison","heading":"11.3.1 Schwarz (1978) approximation of log-marginal likelihood","text":"logarithm marginal likelihood model can approximated\nfollowing Schwarz (1978) 16 follow:\n\\[\n\\log p(D | M) \\approx l_n^M(\\hat{\\boldsymbol \\theta}_{ML}^{M}) - \\frac{1}{2} d_M \\log n  \n\\]\n\\(d_M\\) dimension model \\(M\\) (number parameters \\(\\boldsymbol \\theta\\) belonging \\(M\\)) \\(n\\) sample size\n\\(\\hat{\\boldsymbol \\theta}_{ML}^{M}\\) MLE.\nsimple model \\(d_M=0\\) \napproximation case marginal likelihood equals likelihood.formula can obtained quadratic approximation likelihood assuming large \\(n\\) assuming prior locally uniform around MLE. Schwarz (1978) approximation therefore special case Laplace approximation.Note approximation maximum log-likelihood minus penalty depends model complexity (measured dimension \\(d\\)), hence example penalised ML! Also note distribution parameter \\(\\boldsymbol \\theta\\) required approximation.","code":""},{"path":"bayesian-model-comparison.html","id":"bayesian-information-criterion-bic","chapter":"11 Bayesian model comparison","heading":"11.3.2 Bayesian information criterion (BIC)","text":"BIC (Bayesian information criterion) model \\(M\\) \napproximated log-marginal likelihood times factor -2:\\[\nBIC(M) = -2 l_n^M(\\hat{\\boldsymbol \\theta}_{ML}^{M}) + d_M \\log n\n\\]Thus, comparing models one aimes maximise marginal likelihood , approximation, minimise BIC.reason factor “-2” simply quantity \nscale Wilks log likelihood ratio. people / software packages also use factor “2”.","code":""},{"path":"bayesian-model-comparison.html","id":"approximating-the-weight-of-evidence-log-bayes-factor-with-bic","chapter":"11 Bayesian model comparison","heading":"11.3.3 Approximating the weight of evidence (log-Bayes factor) with BIC","text":"Using BIC (twice) log-Bayes factor can approximated \n\\[\n\\begin{split}\n2 \\log B_{12} &\\approx -BIC(M_1) + BIC(M_2) \\\\\n&=2 \\left( l_n^{M_{1}}(\\hat{\\boldsymbol \\theta}_{ML}^{M_{1}}) - l_n^{M_{2}}(\\hat{\\boldsymbol \\theta}_{ML}^{M_{2}}) \\right) - \\log(n) (d_{M_{1}}-d_{M_{2}}) \\\\\n\\end{split}\n\\]\n.e. penalised log-likelihood ratio model \\(M_1\\) vs. \\(M_2\\).","code":""},{"path":"bayesian-model-comparison.html","id":"bayesian-testing-using-false-discovery-rates","chapter":"11 Bayesian model comparison","heading":"11.4 Bayesian testing using false discovery rates","text":"introduce False Discovery Rates (FDR) Bayesian method \ndistinguish null model alternative model. closely linked classical\nfrequentist multiple testing procedures.","code":""},{"path":"bayesian-model-comparison.html","id":"setup-for-testing-a-null-model-h_0-versus-an-alternative-model-h_a","chapter":"11 Bayesian model comparison","heading":"11.4.1 Setup for testing a null model \\(H_0\\) versus an alternative model \\(H_A\\)","text":"consider two models:\\(H_0:\\) null model, density \\(f_0(x)\\) distribution \\(F_0(x)\\)\\(H_A:\\) alternative model, density \\(f_A(x)\\) distribution \\(F_A(x)\\)Aim: given observations \\(x_1, \\ldots, x_n\\) like decide \\(x_i\\) whether\nbelongs \\(H_0\\) \\(H_A\\).done critical decision threshold \\(x_c\\): \\(x_i > x_c\\) \\(x_i\\) called “significant” otherwise called “significant”.classical statistics one widely used approach find decision threshold computing \\(p\\)-values \\(x_i\\)\n(uses null model alternative model), thresholding \\(p\\)-values certain level (say 5%). \\(n\\) large often test modified adjusting \\(p\\)-values threshold (e.g. Bonferroni correction).Note procedure ignores information may alternative model!","code":""},{"path":"bayesian-model-comparison.html","id":"test-errors","chapter":"11 Bayesian model comparison","heading":"11.4.2 Test errors","text":"","code":""},{"path":"bayesian-model-comparison.html","id":"true-and-false-positives-and-negatives","chapter":"11 Bayesian model comparison","heading":"11.4.2.1 True and false positives and negatives","text":"decision threshold \\(x_c\\) can distinguish following errors:False positives (FP), “false alarm”, type error: \\(x_i\\) belongs null called “significant”False negative (FN), “miss”, type II error: \\(x_i\\) belongs alternative, called “significant”addition :True positives (TP), “hits”: belongs alternative called “significant”True negatives (TN), “correct rejections”: belongs null called “significant”","code":""},{"path":"bayesian-model-comparison.html","id":"specificity-and-sensitivity","chapter":"11 Bayesian model comparison","heading":"11.4.2.2 Specificity and Sensitivity","text":"counts TP, TN, FN, FP can derive quantities:True Negative Rate TNR, specificity: \\(TNR= \\frac{TN}{TN+FP} = 1- FPR\\) FPR=False Positive Rate = \\(1-\\alpha_I\\)True Negative Rate TNR, specificity: \\(TNR= \\frac{TN}{TN+FP} = 1- FPR\\) FPR=False Positive Rate = \\(1-\\alpha_I\\)True Positive Rate TPR, sensitivity, power, recall: \\(TPR= \\frac{TP}{TP+FN} = 1- FNR\\) FNR=False negative rate = \\(1-\\alpha_{II}\\)True Positive Rate TPR, sensitivity, power, recall: \\(TPR= \\frac{TP}{TP+FN} = 1- FNR\\) FNR=False negative rate = \\(1-\\alpha_{II}\\)Accuracy: \\(ACC = \\frac{TP+TN}{TP+TN+FP+FN}\\)Accuracy: \\(ACC = \\frac{TP+TN}{TP+TN+FP+FN}\\)Another common way choose decision threshold \\(x_d\\) classical statistics balance sensitivity/power vs. specificity (maximising power specificity, equivalently, minimising false positive false negative rates). ROC curves plot TPR/sensitivity vs. FPR = 1-specificity.","code":""},{"path":"bayesian-model-comparison.html","id":"fdr-and-fndr","chapter":"11 Bayesian model comparison","heading":"11.4.2.3 FDR and FNDR","text":"possible link observed counts TP, FP, TN, FN:False Discovery Rate (FDR): \\(FDR = \\frac{FP}{FP+TP}\\)False Nondiscovery Rate (FNDR): \\(FNDR = \\frac{FN}{TN+FN}\\)Positive predictive value (PPV), True Discovery Rate (TDR), precision: \\(PPV = \\frac{TP}{FP+TP} = 1-FDR\\)Negative predictive value (NPV): \\(NPV = \\frac{TN}{TN+FN} = 1-FNDR\\)order choose decision threshold natural balance FDR FDNR (PPV NPV), minimising FDR FNDR maximising PPV NPV.machine learning common use “precision-recall plots” plot precision (=PPV, TDR)\nvs. recall (=power, sensitivity).","code":""},{"path":"bayesian-model-comparison.html","id":"bayesian-perspective","chapter":"11 Bayesian model comparison","heading":"11.4.3 Bayesian perspective","text":"","code":""},{"path":"bayesian-model-comparison.html","id":"two-component-mixture-model","chapter":"11 Bayesian model comparison","heading":"11.4.3.1 Two component mixture model","text":"Bayesian perspective problem choosing decision threshold related computing posterior probability\n\\[\\text{Pr}(H_0 | x_i) , \\]\n.e. probability null model given observation \\(x_i\\), equivalently\ncomputing\n\\[\\text{Pr}(H_A | x_i) = 1- \\text{Pr}(H_0 | x_i)\\]\nprobability alternative model given observation \\(x_i\\).done assuming mixture model\n\\[\nf(x) = \\pi_0 f_0(x) + (1-\\pi_0) f_A(x)\n\\]\n\\(\\pi_0 = \\text{Pr}(H_0)\\) prior probability \\(H_0\\) .\n\\(\\pi_A = 1- \\pi_0 = \\text{Pr}(H_A)\\) prior probabiltiy \\(H_A\\).Note weights \\(\\pi_0\\) can fact estimated observations fitting mixture distribution\nobservations \\(x_1, \\ldots, x_n\\) (effectively empirical Bayes method prior informed data).","code":""},{"path":"bayesian-model-comparison.html","id":"local-fdr","chapter":"11 Bayesian model comparison","heading":"11.4.3.2 Local FDR","text":"posterior probability null model given data point given \n\\[\\text{Pr}(H_0 | x_i) = \\frac{\\pi_0 f_0(x_i)}{f(x_i)} = LFDR(x_i)\\]\nquantity also known local FDR local False Discovery Rate.given one-sided setup local FDR large (close 1) small \\(x\\), \nbecome close 0 large \\(x\\). common decision rule given thresholding\nlocal false discovery rates: \\(LFDR(x_i) < 0.1\\) \\(x_i\\) called significant.","code":""},{"path":"bayesian-model-comparison.html","id":"q-values","chapter":"11 Bayesian model comparison","heading":"11.4.3.3 q-values","text":"correspondence \\(p\\)-values one can also define tail-area based false discovery rates:\n\\[\nFdr(x_i) = \\text{Pr}(H_0 | X > x_i) = \\frac{\\pi_0 F_0(x_i)}{F(x_i)}\n\\]called q-values, simply False Discovery Rates (FDR). Intriguingly, also frequentist\ninterpretation adjusted p-values (using Benjamini-Hochberg adjustment procedure).","code":""},{"path":"bayesian-model-comparison.html","id":"software","chapter":"11 Bayesian model comparison","heading":"11.4.4 Software","text":"number R packages compute (local) FDR values:example:locfdrqvaluefdrtooland many .Using FDR values screening especially useful high-dimensional settings\n(e.g. analysing genomic high-throughput data).FDR values Bayesian well frequentist interpretation, providing evidence \ngood classical statistical methods Bayesian interpretation.","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"choosing-priors-in-bayesian-analysis","chapter":"12 Choosing priors in Bayesian analysis","heading":"12 Choosing priors in Bayesian analysis","text":"","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"choosing-a-prior","chapter":"12 Choosing priors in Bayesian analysis","heading":"12.1 Choosing a prior","text":"","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"prior-as-part-of-the-model","chapter":"12 Choosing priors in Bayesian analysis","heading":"12.1.1 Prior as part of the model","text":"essential Bayesian analysis specify prior\nuncertainty model parameters. Note simply part modelling process! Thus Bayesian approach data analyst needs explicit modelling assumptions.Typically, choosing suitable prior distribution consider overall form (shape domain) distribution well key characteristics mean variance. learned precision (inverse variance)\nprior may often viewed implied sample size.large sample size \\(n\\) posterior mean converges maximum likelihood estimate (posterior distribution normal distribution centered around MLE), large \\(n\\) may ignore specifying prior.However, small \\(n\\) essential prior specified. non-Bayesian approaches prior still either implicit (maximum likelihood estimation) specified via penality (penalised maximum likelihood estimation).","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"some-guidelines","chapter":"12 Choosing priors in Bayesian analysis","heading":"12.1.2 Some guidelines","text":"question remains good ways choose prior? Two useful ways :Use weakly informative prior. means idea (even vague) suitable values parameter interest, use corresponding prior (example moderate variance) model uncertainty. acknowledges uninformative priors also aims prior dominate likelihood (.e. data). result weakly regularised estimator. Note often desirable prior adds information (little) can act regulariser.Use weakly informative prior. means idea (even vague) suitable values parameter interest, use corresponding prior (example moderate variance) model uncertainty. acknowledges uninformative priors also aims prior dominate likelihood (.e. data). result weakly regularised estimator. Note often desirable prior adds information (little) can act regulariser.Empirical Bayes methods can often used determine one hyperparameters (.e. parameters prior) observed data. several ways , one tune shrinkage parameter \\(\\lambda\\) achieve minimum MSE. discuss .Empirical Bayes methods can often used determine one hyperparameters (.e. parameters prior) observed data. several ways , one tune shrinkage parameter \\(\\lambda\\) achieve minimum MSE. discuss .Furthermore, also exist many proposals advocating -called “uninformative priors” “objective priors”.\nHowever, actually unformative priors, since prior distribution looks uninformative (.e. “flat”) one coordinate system can informative another — simple consequence rule transformation \nprobability densities. result, often suggested objective priors fact improper, .e. actually probability distributions!","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"default-priors-or-uninformative-priors","chapter":"12 Choosing priors in Bayesian analysis","heading":"12.2 Default priors or uninformative priors","text":"Objective default priors attempts 1) automatise specification prior 2) find uniformative priors.","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"jeffreys-prior","chapter":"12 Choosing priors in Bayesian analysis","heading":"12.2.1 Jeffreys prior","text":"well-known non-informative prior given proposal \nHarold Jeffreys (1891–1989) \n1946 17.Specifically, prior constructed expected Fisher information thus promises automatic construction objective uninformative priors using likelihood:\n\\[\np(\\boldsymbol \\theta) \\propto \\sqrt{\\det \\boldsymbol ^{\\text{Fisher}}(\\boldsymbol \\theta)}\n\\]reasoning underlying prior invariance transformation coordinate system parameters.Beta-Binomial model Jeffreys prior corresponds \\(\\text{Beta}(\\frac{1}{2}, \\frac{1}{2})\\). Note uniform distribution U-shaped prior.normal-normal model corresponds flat improper prior \\(p(\\mu) =1\\).IG-normal model Jeffreys prior improper prior \\(p(\\sigma^2) = \\frac{1}{\\sigma^2}\\).already illustrates main problem type prior – namely often improper, .e. prior distribution actually probability distribution (.e. density integrate 1).Another issue Jeffreys priors usually conjugate complicates update prior posterior.Furthermore, multiple parameters (\\(\\boldsymbol \\theta\\) vector) Jeffreys priors usually lead sensible priors.","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"reference-priors","chapter":"12 Choosing priors in Bayesian analysis","heading":"12.2.2 Reference priors","text":"alternative Jeffreys priors -called reference priors developed Bernardo (1979) 18.\ntype priors aims choose prior maximal “correlation” data parameter. precisely, mutual information \\(\\theta\\) \\(x\\) maximised (.e. expected KL divergence posterior prior distribution). underlying motivation data parameters maximally linked (thereby minimising influence prior).univariate settings reference priors identical Jeffreys priors. However, reference prior also provide reasonable priors multivariate settings.Jeffreys’ reference prior approach choice prior expectation data, .e. specific data set hand (can seen positive negative!).","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"empirical-bayes","chapter":"12 Choosing priors in Bayesian analysis","heading":"12.3 Empirical Bayes","text":"empirical Bayes data analysist specifies family prior distribution\n(say Beta distribution free parameters), data hand used find optimal choise hyper-parameters (hence name “empirical”). Thus hyper-parameters specified estimated.","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"type-ii-maximum-likelihood","chapter":"12 Choosing priors in Bayesian analysis","heading":"12.3.1 Type II maximum likelihood","text":"particular, assuming data \\(D\\), likelihood \\(p(D|\\boldsymbol \\theta)\\) model parameters \\(\\boldsymbol \\theta\\) well prior\n\\(p(\\boldsymbol \\theta| \\lambda)\\) \\(\\boldsymbol \\theta\\) hyper-parameter \\(\\lambda\\) marginal likelihood now depends \\(\\lambda\\):\n\\[\np(D | \\lambda) = \\int_{\\boldsymbol \\theta}  p(D|\\boldsymbol \\theta) p(\\boldsymbol \\theta| \\lambda) d\\boldsymbol \\theta\n\\]\ncan therefore use maximum (marginal) likelihood find optimal values \\(\\lambda\\) given data.Since maximum-likelihood used second level step (hyper-parameters) type empirical Bayes also often called “type II maximum likelihood”.","code":""},{"path":"choosing-priors-in-bayesian-analysis.html","id":"shrinkage-estimation-using-empirical-risk-minimisation","chapter":"12 Choosing priors in Bayesian analysis","heading":"12.3.2 Shrinkage estimation using empirical risk minimisation","text":"alternative (related) way estimate hyper-parameters minimising empirical risk.examples Bayesian estimation considered far\nposterior mean parameter interest obtained\nlinear shrinkage\n\\[\n\\hat\\theta_{\\text{shrink}} = \\text{E}( \\theta | D) = \\lambda \\theta_0 + (1-\\lambda) \\hat\\theta_{\\text{ML}}\n\\]\nMLE \\(\\hat\\theta_{\\text{ML}}\\) towards \nprior mean \\(\\theta_0\\), shrinkage intensity \\(\\lambda=\\frac{k_0}{k_0}\\)\ndetermined ration prior posterior concentration parameters \\(k_0\\) \\(k_1\\).resulting point estimate \\(\\hat\\theta_{\\text{shrink}}\\) called shrinkage estimate\nconvex combination \\(\\theta_0\\) \\(\\hat\\theta_{\\text{ML}}\\). prior mean \\(\\theta_0\\) also called “target”.hyperparameter setting \\(k_0\\) (linked precision prior) equivalently \nshrinkage intensity \\(\\lambda\\).optimal value \\(\\lambda\\) can obtained minimising mean squared error \nestimator \\(\\hat\\theta_{\\text{shrink}}\\).particular, construction, target \\(\\theta_0\\) low even zero variance\nnon-vanishing potentially large bias, whereas MLE \\(\\hat\\theta_{\\text{ML}}\\) low zero bias substantial variance. combinining two estimators opposite properties aim achieve\nbias-variance tradeoff resulting estimator \\(\\hat\\theta_{\\text{shrink}}\\) lower MSE either\n\\(\\theta_0\\) \\(\\hat\\theta_{\\text{ML}}\\).Specifically, aim find\n\\[\n\\lambda^{\\star} = \\underset{\\lambda}{\\arg \\min \\ }  \n\\text{E}\\left( ( \\theta - \\hat\\theta_{\\text{shrink}} )^2\\right)\n\\]turns can minimised without knowing actual true value \\(\\theta\\)\nresult unbiased \\(\\hat\\theta_{\\text{ML}}\\) \n\\[\n\\lambda^{\\star} = \\frac{\\text{Var}(\\hat\\theta_{\\text{ML}})}{\\text{E}( (\\hat\\theta_{\\text{ML}} - \\theta_0)^2 )}\n\\]\nHence, shrinkage intensity small variance MLE small /target\nMLE differ substantially. hand, variance MLE large /target close MLE shrinkage intensity large.Choosing shrinkage parameter optimising expected risk (mean squared error) also form empirical Bayes.Example 12.1  James-Stein estimator:Empirical risk minimisation estimate shrinkage parameter normal-normal model\nsingle observation yields James-Stein estimator (1955).Specifically, James Stein propose following estimate \nmultivariate mean \\(\\boldsymbol \\mu\\) using single sample \\(\\boldsymbol x\\)\ndrawn multivariate normal \\(N_d(\\boldsymbol \\mu, \\boldsymbol )\\):\n\\[\n\\hat{\\boldsymbol \\mu}_{JS} = \\left(1-\\frac{d-2}{||\\boldsymbol x||^2}\\right) \\boldsymbol x\n\\]\n, recognise \\(\\hat{\\boldsymbol \\mu}_{ML} = \\boldsymbol x\\), \\(\\boldsymbol \\mu_0=0\\) shrinkage intensity \\(\\lambda^{\\star}=\\frac{d-2}{||\\boldsymbol x||^2}\\).Efron Morris (1972) Lindley Smith (1972)\nlater generalised James-Stein estimator case\nmultiple observations \\(\\boldsymbol x_1, \\ldots \\boldsymbol x_n\\)\ntarget \\(\\boldsymbol \\mu_0\\), yielding empirical Bayes estimate \\(\\mu\\) based normal-normal model.","code":""},{"path":"optimality-properties-and-summary.html","id":"optimality-properties-and-summary","chapter":"13 Optimality properties and summary","heading":"13 Optimality properties and summary","text":"","code":""},{"path":"optimality-properties-and-summary.html","id":"bayesian-statistics-in-a-nutshell","chapter":"13 Optimality properties and summary","heading":"13.1 Bayesian statistics in a nutshell","text":"Bayesian statistics explicitly models uncertainty parameters\ninterest probabilityIn light new evidence (observed data) uncertainty updated, .e. prior distribution combined via Bayes rule likelihood form posterior distributionIf posterior distribution family prior \\(\\rightarrow\\) conjugate prior.exponential family Bayesian update mean always expressible\nlinear shrinkage MLE.large sample size posterior mean becomes maximum likelihood estimator prior playes role.Conversely, small sample size data available posterior stays close prior..","code":""},{"path":"optimality-properties-and-summary.html","id":"advantages","chapter":"13 Optimality properties and summary","heading":"13.1.1 Advantages","text":"Adding prior information regularisation properties. important complex models many parameters, e.g., estimation covariance matrix (avoid singularity).Improves small-sample accuracy (e.g. MSE)Bayesian estimators tend perform better MLEs - surprising use\nobserved data plus extra information available prior.Bayesian credible intervals conceptually much simple frequentist\nconfidence intervals.","code":""},{"path":"optimality-properties-and-summary.html","id":"frequentist-properties-of-bayesian-estimators","chapter":"13 Optimality properties and summary","heading":"13.1.2 Frequentist properties of Bayesian estimators","text":"Bayesian point estimator (e.g. posterior mean) can also assessed frequentist properties.First, construction due introducing prior Bayesian estimator biased \nfinite \\(n\\) even MLE unbiased.Second, intriguingly turns sampling variance Bayes point estimator (confused posterior variance!) can smaller variance MLE. depends choice shrinkage parameter \\(\\lambda\\) also determines posterior variance.result, Bayesian estimators may smaller MSE (=squared bias + variance) ML estimator finite \\(n\\).statistical decision theory called theorem admissibility Bayes rules.\nstates mild conditions every admissible estimation rule (.e. one dominates \nestimators regard expected loss, MSE) fact Bayes estimator prior.Unfortunately, theorem tell prior needed achive optimality, however optimal estimator can often found tuning hyperparameters.","code":""},{"path":"optimality-properties-and-summary.html","id":"specifying-the-prior-problem-or-advantage","chapter":"13 Optimality properties and summary","heading":"13.1.3 Specifying the prior — problem or advantage?","text":"Bayesian statistics data analyst needs explicit modelling assumptions:Model = data generating process (likelihood) + prior uncertainty (prior distribution)Note alternative statistical methods can often interpreted Bayesian methods assuming specific implicit prior!example, likelihood estimation binomial model equivalent Bayes estimation using Beta-Binomial model \\(\\text{Beta}(0,0)\\) prior (=Haldane prior).\nHowever, choosing prior explicitly model, interestingly analysts rather use \nflat prior \\(\\text{Beta}(1,1)\\) (=Laplace prior) implicit sample size \\(k_0=2\\) transformation-invariant prior \\(\\text{Beta}(1/2, 1/2)\\) (=Jeffreys prior) implicit sample size \\(k_0=1\\) rather Haldane prior!\\(\\rightarrow\\) aware implicit priors!!Better acknowledge prior used (even implicit!)\nspecific assumptions enforced Bayesian approach.Specifying prior thus best understood intrinsic part model specification.\nhelps improve inference may ignored lots data.","code":""},{"path":"optimality-properties-and-summary.html","id":"optimality-of-bayesian-inference","chapter":"13 Optimality properties and summary","heading":"13.2 Optimality of Bayesian inference","text":"optimality Bayesian model making use full model specification (likelihood plus prior) can shown number different perspectives. Correspondingly,\nmany theorems prove (least indicate) optimality:Richard Cox’s theorem: generalising classical logic invariably leads Bayesian inference.Richard Cox’s theorem: generalising classical logic invariably leads Bayesian inference.de Finetti’s representation theorem: joint distribution exchangeable observations can always expressed weighted mixture prior distribution parameter model. implies existence prior distribution requirement Bayesian approach.de Finetti’s representation theorem: joint distribution exchangeable observations can always expressed weighted mixture prior distribution parameter model. implies existence prior distribution requirement Bayesian approach.Frequentist decision theory: admissible decision rules Bayes rules!Frequentist decision theory: admissible decision rules Bayes rules!Entropy perspective: posterior density (function!) obtained result optimising entropy criterion. Bayesian updating may thus viewed variational optimisation problem. Specifically, Bayes theorem minimal update new information arrives form observations\n(see ).Entropy perspective: posterior density (function!) obtained result optimising entropy criterion. Bayesian updating may thus viewed variational optimisation problem. Specifically, Bayes theorem minimal update new information arrives form observations\n(see ).Remark: exist number (often somewhat esoteric) suggestions propagating uncertainty “fuzzy logic”, imprecise probabilities, etc. contradict Bayesian learning thus direct violation theorems.","code":""},{"path":"optimality-properties-and-summary.html","id":"connection-with-entropy-learning","chapter":"13 Optimality properties and summary","heading":"13.3 Connection with entropy learning","text":"Bayesian update rule general form learning new information arrives form data. actually even general principle Bayesian update rule just special case: principle minimal information update (e.g. Jaynes 1959, 2003) principle minimum information discrimination (MDI) (Kullback 1959).can summarised follows: Change beliefs much necessary coherent new evidence!principle “inertia beliefs” new information arrives uncertainty parameter minimally adjusted, much needed account new information.\nimplement principle KL divergence natural measure quantify \nchange underlying beliefs. known entropy learning.Bayes rule emerges special case entropy learning:KL divergence joint posterior \\(Q_{x,\\boldsymbol \\theta}\\) joint prior distribution \\(P_{x,\\boldsymbol \\theta}\\) computed, posterior\ndistribution \\(Q_{\\boldsymbol \\theta|x}\\) free parameter.conditional distribution \\(Q_{\\boldsymbol \\theta|x}\\) found minimising KL divergence \\(D_{\\text{KL}}(Q_{x,\\boldsymbol \\theta}, P_{x,\\boldsymbol \\theta})\\).optimal solution variational optimisation problem given Bayes’ rule!application KL divergence example reverse KL optimisation (aka \\(\\)-projection, see Part notes). Intringuingly, explains zero forcing property Bayes’ rule (general property \\(\\)-projection).Applying entropy learning therefore includes Bayesian learning special case:information arrives form data \\(\\rightarrow\\) update prior Bayes’ theorem (Bayesian learning).Interestingly, entropy learning lead update rules types information:information arrives form another distribution \\(\\rightarrow\\) update using R. Jeffrey’s rule conditioning (1965).information arrives form another distribution \\(\\rightarrow\\) update using R. Jeffrey’s rule conditioning (1965).information presented form constraints \\(\\rightarrow\\) Kullback’s principle minimum MDI (1959), E. T. Jaynes maximum entropy (MaxEnt) principle (1957).information presented form constraints \\(\\rightarrow\\) Kullback’s principle minimum MDI (1959), E. T. Jaynes maximum entropy (MaxEnt) principle (1957).shows () fundamentally important KL divergence statistics. leads likelihood inference (via forward KL) also Bayesian learning, well forms information updating (via reverse KL).Furthermore, Bayesian statistics relative entropy useful choose priors (e.g. reference priors) also helps (Bayesian) experimental design quantify information provided experiment.","code":""},{"path":"optimality-properties-and-summary.html","id":"conclusion","chapter":"13 Optimality properties and summary","heading":"13.4 Conclusion","text":"Bayesian statistics offers coherent framework statistical learning data, methods forestimationtestingmodel buildingThere number theorems show “optimal” estimators (defined various ways) Bayesian.conceptually simple — can computationally involved!provides coherent generalisation classical TRUE/FALSE logic (therefore suffer inconsistencies prevalent frequentist statistics).Bayesian statistics non-asymptotic theory, works sample size.\nAsympotically (large \\(n\\)) consistent converges true model (like ML!).\nBayesian reasoning can also applied events take place — assumption hypothetical infinitely many repetitions frequentist statistics needed.Moreover, many classical (frequentist) procedures may viewed approximations Bayesian methods estimators, using classical approaches correct application domain perfectly line Bayesian framework.Bayesian estimation inference also automatically regularises (via prior) important complex models problem overfitting.","code":""},{"path":"overview-over-regression-modelling.html","id":"overview-over-regression-modelling","chapter":"14 Overview over regression modelling","heading":"14 Overview over regression modelling","text":"","code":""},{"path":"overview-over-regression-modelling.html","id":"general-setup","chapter":"14 Overview over regression modelling","heading":"14.1 General setup","text":"\\(y\\): response variable, also known outcome label\\(y\\): response variable, also known outcome label\\(x_1, x_2, x_3, \\ldots, x_d\\): predictor variables, also known covariates covariables\\(x_1, x_2, x_3, \\ldots, x_d\\): predictor variables, also known covariates covariablesThe relationship outcomes predictor variables assumed follow\n\\[\ny = f(x_1,x_2,\\dots,x_d) + \\varepsilon\n\\]\n\\(f\\) regression function (density) \\(\\varepsilon\\) represents noise.relationship outcomes predictor variables assumed follow\n\\[\ny = f(x_1,x_2,\\dots,x_d) + \\varepsilon\n\\]\n\\(f\\) regression function (density) \\(\\varepsilon\\) represents noise.","code":""},{"path":"overview-over-regression-modelling.html","id":"objectives","chapter":"14 Overview over regression modelling","heading":"14.2 Objectives","text":"Understand relationship response \\(y\\) predictor variables \\(x_i\\) learning regression function \\(f\\) observed data (training data). estimated regression function \\(\\hat{f}\\).Understand relationship response \\(y\\) predictor variables \\(x_i\\) learning regression function \\(f\\) observed data (training data). estimated regression function \\(\\hat{f}\\).Prediction outcomes\n\\[\\underbrace{\\hat{y}}_{\\substack{\\text{predicted response} \\\\ \\text{using fitted $\\hat{f}$}}} = \\hat{f}(x_1,x_2,\\dots,x_d)\\]\ninstead fitted function \\(\\hat{f}\\) known regression function \\(f\\) used denote \n\\[\\underbrace{y^{\\star}}_{\\substack{\\text{predicted response} \\\\ \\text{using known $f$}}} = f(x_1,x_2,\\dots,x_d)\n\\]Prediction outcomes\n\\[\\underbrace{\\hat{y}}_{\\substack{\\text{predicted response} \\\\ \\text{using fitted $\\hat{f}$}}} = \\hat{f}(x_1,x_2,\\dots,x_d)\\]instead fitted function \\(\\hat{f}\\) known regression function \\(f\\) used denote \n\\[\\underbrace{y^{\\star}}_{\\substack{\\text{predicted response} \\\\ \\text{using known $f$}}} = f(x_1,x_2,\\dots,x_d)\n\\]Variable importance\ncovariates relevant predicting outcome?\nallows better understand data model\\(\\rightarrow\\) variable selection\n(build simpler model predictive capability)\nVariable importancewhich covariates relevant predicting outcome?allows better understand data model\\(\\rightarrow\\) variable selection\n(build simpler model predictive capability)","code":""},{"path":"overview-over-regression-modelling.html","id":"regression-as-a-form-of-supervised-learning","chapter":"14 Overview over regression modelling","heading":"14.3 Regression as a form of supervised learning","text":"Regression modelling special case supervised learning.supervised learning make use labelled data, .e. \\(\\boldsymbol x_i\\) associated label\n\\(y_i\\). Thus, data consists pairs \\((\\boldsymbol x_1, y_1),(\\boldsymbol x_2 ,y_2),\\dots,(\\boldsymbol x_n ,y_n)\\).supervision part supervised learning refers fact labels given.regression typically label \\(y_i\\) continuous called response.hand, label \\(y_i\\) discrete/categorical supervised learning called classification.\\[\\begin{align*}\n\\begin{array}{ll}\n\\\\\n\\text{Supervised Learning}\\\\\n\\\\\n\\end{array}\n\\begin{array}{ll}\n\\longrightarrow \\text{Discrete } y\\\\\n\\\\\n\\longrightarrow \\text{Continuous } y\\\\\n\\end{array}\n\\begin{array}{ll}\n\\longrightarrow \\text{Classification Methods}\\\\\n\\\\\n\\longrightarrow \\text{Regression Methods}\\\\\n\\end{array}\n\\end{align*}\\]Another important type statistical learning unsupervised learning labels \\(y\\)\ninferred data \\(\\boldsymbol x\\) (also known clustering). Furthermore, also semi-supervised learning labels partly known.Note regression models (e.g. logistic regression) discrete\nresponse performing classification, one may argue “supervised learning”=“generalised regression”.","code":""},{"path":"overview-over-regression-modelling.html","id":"various-regression-models-used-in-statistics","chapter":"14 Overview over regression modelling","heading":"14.4 Various regression models used in statistics","text":"course study linear multiple regression.\nHowever, aware linear model fact just special cases much general\nregression approaches.General regression model:\n\\[y = f(x_1,\\dots,x_d) + \\text{\"noise\"}\\]function \\(f\\) estimated nonparametrically\n- splines\n- Gaussian processesThe function \\(f\\) estimated nonparametrically\n- splines\n- Gaussian processesGeneralised Additive Models (GAM):\n- function \\(f\\) assumed sum individual functions \\(f_i(x_i)\\)Generalised Additive Models (GAM):\n- function \\(f\\) assumed sum individual functions \\(f_i(x_i)\\)Generalised Linear Models (GLM):\n- \\(f\\) transformed linear predictor \\(h(\\sum b_i x_i)\\), noise assumed exponential familyGeneralised Linear Models (GLM):\n- \\(f\\) transformed linear predictor \\(h(\\sum b_i x_i)\\), noise assumed exponential familyLinear Model (LM):\n- linear predictor \\(\\sum b_i x_i\\), normal noiseLinear Model (LM):\n- linear predictor \\(\\sum b_i x_i\\), normal noiseIn R linear model implemented function lm(), generalised linear models\nfunction glm(). Generalised additive models available package\n“mgcv”.following focus linear regression model continuous response.","code":""},{"path":"linear-regression.html","id":"linear-regression","chapter":"15 Linear Regression","heading":"15 Linear Regression","text":"","code":""},{"path":"linear-regression.html","id":"the-linear-regression-model","chapter":"15 Linear Regression","heading":"15.1 The linear regression model","text":"module assume \\(f\\) linear function:\n\\[f(x_1, \\ldots, x_d) = \\beta_0 + \\sum^{d}_{j=1} \\beta_j x_j = y^{\\star}\\]vector notation:\n\\[\nf(\\boldsymbol x) = \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x= y^{\\star}\n\\]\n\\(\\boldsymbol \\beta=\\begin{pmatrix} \\beta_1 \\\\ \\vdots \\\\ \\beta_d \\end{pmatrix}\\) \\(\\boldsymbol x=\\begin{pmatrix} x_1 \\\\ \\vdots \\\\ x_d \\end{pmatrix}\\)Therefore, linear regression model \n\\[\n\\begin{split}\ny &= \\beta_0 + \\sum^{d}_{j=1} \\beta_j x_j + \\varepsilon\\\\\n  &= \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x+\\varepsilon \\\\\n  &= y^{\\star} +\\varepsilon\n\\end{split}\n\\]\n:\\(\\beta_0\\) intercept\\(\\boldsymbol \\beta= (\\beta_1,\\ldots,\\beta_d)^T\\) regression coefficients\\(\\boldsymbol x= (x_1,\\ldots,x_d)^T\\) predictor vector containing predictor variables","code":""},{"path":"linear-regression.html","id":"interpretation-of-regression-coefficients-and-intercept","chapter":"15 Linear Regression","heading":"15.2 Interpretation of regression coefficients and intercept","text":"regression coefficient \\(\\beta_i\\) corresponds slope (first partial derivative) regression function direction \\(x_i\\). words,\ngradient \\(f(\\boldsymbol x)\\) regression coefficients: \\(\\nabla f(\\boldsymbol x) = \\boldsymbol \\beta\\)intercept \\(\\beta_0\\) offset origin (\\(x_1=x_2=\\ldots=x_d=0\\)):","code":""},{"path":"linear-regression.html","id":"different-types-of-linear-regression","chapter":"15 Linear Regression","heading":"15.3 Different types of linear regression:","text":"Simple linear regression: \\(y=\\beta_0 + \\beta x + \\varepsilon\\) (=single predictor)Multiple linear regression: \\(y =\\beta_0 + \\sum^{d}_{j=1} \\beta_j x_j + \\varepsilon\\) (= multiple predictor variables)Multivariate regression: multivariate response \\(\\boldsymbol y\\)","code":""},{"path":"linear-regression.html","id":"distributional-assumptions-and-properties","chapter":"15 Linear Regression","heading":"15.4 Distributional assumptions and properties","text":"General assumptions:treat \\(y\\) \\(x_1, \\ldots, x_d\\) primary observables can described random variables.treat \\(y\\) \\(x_1, \\ldots, x_d\\) primary observables can described random variables.\\(\\beta_0, \\boldsymbol \\beta\\) parameters inferred observations\n\\(y\\) \\(x_1, \\ldots,x_d\\).\\(\\beta_0, \\boldsymbol \\beta\\) parameters inferred observations\n\\(y\\) \\(x_1, \\ldots,x_d\\).Specifically, assume response predictors mean (cov)variance:\nResponse:\\(\\text{E}(y) = \\mu_y\\)\\(\\text{Var}(y) = \\sigma_y^2\\)\nvariance response \\(\\text{Var}(y)\\) also called total variation .\nPredictors:\\(\\text{E}(x_i) = \\mu_{x_i}\\) (\\(\\text{E}(\\boldsymbol x) = \\boldsymbol \\mu_{\\boldsymbol x}\\))\\(\\text{Var}(x_i) = \\sigma^2_{x_i}\\) \\(\\text{Cor}(x_i, x_j) = \\rho_{ij}\\) (\\(\\text{Var}(\\boldsymbol x) = \\boldsymbol \\Sigma_{\\boldsymbol x}\\))\nsignal variance \\(\\text{Var}(y^{\\star})=\\text{Var}(\\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x) = \\boldsymbol \\beta^T \\boldsymbol \\Sigma_{\\boldsymbol x} \\boldsymbol \\beta\\) also called explained variation.\nSpecifically, assume response predictors mean (cov)variance:Response:\\(\\text{E}(y) = \\mu_y\\)\\(\\text{Var}(y) = \\sigma_y^2\\)\nvariance response \\(\\text{Var}(y)\\) also called total variation .Response:\\(\\text{E}(y) = \\mu_y\\)\\(\\text{Var}(y) = \\sigma_y^2\\)\nvariance response \\(\\text{Var}(y)\\) also called total variation .Predictors:\\(\\text{E}(x_i) = \\mu_{x_i}\\) (\\(\\text{E}(\\boldsymbol x) = \\boldsymbol \\mu_{\\boldsymbol x}\\))\\(\\text{Var}(x_i) = \\sigma^2_{x_i}\\) \\(\\text{Cor}(x_i, x_j) = \\rho_{ij}\\) (\\(\\text{Var}(\\boldsymbol x) = \\boldsymbol \\Sigma_{\\boldsymbol x}\\))\nsignal variance \\(\\text{Var}(y^{\\star})=\\text{Var}(\\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x) = \\boldsymbol \\beta^T \\boldsymbol \\Sigma_{\\boldsymbol x} \\boldsymbol \\beta\\) also called explained variation.Predictors:\\(\\text{E}(x_i) = \\mu_{x_i}\\) (\\(\\text{E}(\\boldsymbol x) = \\boldsymbol \\mu_{\\boldsymbol x}\\))\\(\\text{Var}(x_i) = \\sigma^2_{x_i}\\) \\(\\text{Cor}(x_i, x_j) = \\rho_{ij}\\) (\\(\\text{Var}(\\boldsymbol x) = \\boldsymbol \\Sigma_{\\boldsymbol x}\\))\nsignal variance \\(\\text{Var}(y^{\\star})=\\text{Var}(\\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x) = \\boldsymbol \\beta^T \\boldsymbol \\Sigma_{\\boldsymbol x} \\boldsymbol \\beta\\) also called explained variation.assume \\(y\\) \\(\\boldsymbol x\\) jointly distributed correlation \\(\\text{Cor}(y, x_j) = \\rho_{y,x_{j}}\\)\npredictor variable \\(x_j\\) response \\(y\\).assume \\(y\\) \\(\\boldsymbol x\\) jointly distributed correlation \\(\\text{Cor}(y, x_j) = \\rho_{y,x_{j}}\\)\npredictor variable \\(x_j\\) response \\(y\\).contrast \\(y\\) \\(\\boldsymbol x\\) noise variable \\(\\varepsilon\\) indirectly observed\nvia difference \\(\\varepsilon = y - y^{\\star}\\). denote mean variance noise \n\\(\\text{E}(\\varepsilon)\\) \\(\\text{Var}(\\varepsilon)\\).\nnoise variance \\(\\text{Var}(\\varepsilon)\\) also called unexplained variation \nresidual variance. residual standard error \\(\\text{SD}(\\varepsilon)\\).contrast \\(y\\) \\(\\boldsymbol x\\) noise variable \\(\\varepsilon\\) indirectly observed\nvia difference \\(\\varepsilon = y - y^{\\star}\\). denote mean variance noise \n\\(\\text{E}(\\varepsilon)\\) \\(\\text{Var}(\\varepsilon)\\).\nnoise variance \\(\\text{Var}(\\varepsilon)\\) also called unexplained variation \nresidual variance. residual standard error \\(\\text{SD}(\\varepsilon)\\).Identifiability assumptions:statistical analysis like able separate signal (\\(y^{\\star}\\))\nnoise (\\(\\varepsilon\\)). achieve require distributional assumptions\nensure identifiability avoid confounding:Assumption 1: \\(\\varepsilon\\) \\(y^{\\star}\\) \nindependent. implies \\(\\text{Var}(y) = \\text{Var}(y^{\\star}) + \\text{Var}(\\varepsilon)\\), equivalently\n\\(\\text{Var}(\\varepsilon) = \\text{Var}(y) - \\text{Var}(y^{\\star})\\).\nThus, assumption implies decomposition variance, .e. \ntotal variation \\(\\text{Var}(y)\\) equals sum explained variation\\(\\text{Var}(y^{\\star})\\)\nunexplained variation\\(\\text{Var}(\\varepsilon)\\).Assumption 1: \\(\\varepsilon\\) \\(y^{\\star}\\) \nindependent. implies \\(\\text{Var}(y) = \\text{Var}(y^{\\star}) + \\text{Var}(\\varepsilon)\\), equivalently\n\\(\\text{Var}(\\varepsilon) = \\text{Var}(y) - \\text{Var}(y^{\\star})\\).Thus, assumption implies decomposition variance, .e. \ntotal variation \\(\\text{Var}(y)\\) equals sum explained variation\\(\\text{Var}(y^{\\star})\\)\nunexplained variation\\(\\text{Var}(\\varepsilon)\\).Assumption 2: \\(\\text{E}(\\varepsilon)=0\\). allows identify intercept \\(\\beta_0\\) implies \\(\\text{E}(y) = \\text{E}(y^{\\star})\\).Assumption 2: \\(\\text{E}(\\varepsilon)=0\\). allows identify intercept \\(\\beta_0\\) implies \\(\\text{E}(y) = \\text{E}(y^{\\star})\\).Optional assumptions (often always):noise \\(\\varepsilon\\) normally distributedThe response \\(y\\) predictor\nvariables \\(x_i\\) continuous variablesThe response predictor variables jointly normally distributedFurther properties:result independence assumption 1) can choose two three\nvariances freely:\ngenerative perspective choose signal variance \\(\\text{Var}(y^{\\star})\\) (equivalently variances \\(\\text{Var}(x_j)\\)) noise variance \\(\\text{Var}(\\varepsilon)\\), \nvariance response \\(\\text{Var}(y)\\) follows.\nobservational perspective observe variance reponse\n\\(\\text{Var}(y)\\) variances \\(\\text{Var}(x_j)\\), error variance \\(\\text{Var}(\\varepsilon)\\) follows.\ngenerative perspective choose signal variance \\(\\text{Var}(y^{\\star})\\) (equivalently variances \\(\\text{Var}(x_j)\\)) noise variance \\(\\text{Var}(\\varepsilon)\\), \nvariance response \\(\\text{Var}(y)\\) follows.observational perspective observe variance reponse\n\\(\\text{Var}(y)\\) variances \\(\\text{Var}(x_j)\\), error variance \\(\\text{Var}(\\varepsilon)\\) follows.see later regression coefficients \\(\\beta_j\\) depend correlations response \\(y\\) predictor variables \\(x_j\\).\nThus, choice regression coefficients implies specific correlation pattern,\nvice versa (fact, use correlation pattern infer regression coefficients data!).","code":""},{"path":"linear-regression.html","id":"regression-in-data-matrix-notation","chapter":"15 Linear Regression","heading":"15.5 Regression in data matrix notation","text":"can also write regression terms actual observed data (rather terms random variables):Data matrix predictors:\n\\[\\boldsymbol X= \\begin{pmatrix} x_{11} & \\dots & x_{1d} \\\\ \\vdots & \\ddots & \\vdots \\\\ x_{n1} & \\dots & x_{nd} \\end{pmatrix}\\]Note statistics convention: \\(n\\) rows \\(\\boldsymbol X\\) contain samples, \\(d\\) columns contain variables.Response data vector: \\((y_1,\\dots,y_n)^T = \\boldsymbol y\\)regression equation written data matrix notation:\\[\\underbrace{\\boldsymbol y}_{n\\times 1} = \\underbrace{\\boldsymbol 1_n \\beta_0}_{n\\times 1} + \\underbrace{\\boldsymbol X}_{n \\times d} \\underbrace{\\boldsymbol \\beta}_{d\\times 1}+\\underbrace{\\boldsymbol \\varepsilon}_{\\underbrace{n\\times 1}_{\\text{residuals}}}\\]\\(\\boldsymbol 1_n = \\begin{pmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}\\) column vector length \\(n\\) (size \\(n \\times 1\\)).Note regression coefficients now multiplied \ndata matrix (compare original vector notation transpose regression coefficients come \nvector predictors).observed noise values (.e. realisations random variable \\(\\varepsilon\\)) called residuals.","code":""},{"path":"linear-regression.html","id":"centering-and-vanishing-of-the-intercept-beta_0","chapter":"15 Linear Regression","heading":"15.6 Centering and vanishing of the intercept \\(\\beta_0\\)","text":"\\(\\boldsymbol x\\) \\(y\\) centered, .e. \\(\\text{E}(\\boldsymbol x) = \\boldsymbol \\mu_{\\boldsymbol x}= 0\\) \\(\\text{E}(y) = \\mu_{y} = 0\\),\nintercept \\(\\beta_0\\) disappears:regression equation \n\\[y=\\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x+\\varepsilon\\]\n\\(E(\\varepsilon)\\). Taking expectation sides get\n\\(\\mu_{y} = \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol \\mu_{\\boldsymbol x}\\)\ntherefore\n\\[\n\\beta_0 = \\mu_{y}- \\boldsymbol \\beta^T \\boldsymbol \\mu_{\\boldsymbol x}\n\\]\nzero mean response \\(\\mu_{y}\\) \nmean predictors \\(\\boldsymbol \\mu_{\\boldsymbol x}\\) vanish.\nConversely, assume intercept vanishes (\\(\\beta_0=0\\)) possible general \\(\\boldsymbol \\beta\\) \\(\\boldsymbol \\mu_{\\boldsymbol x}=0\\) \\(\\mu_{y}=0\\).Thus, linear model always possible transform \\(y\\) \\(\\boldsymbol x\\) (data \\(\\boldsymbol y\\) \\(\\boldsymbol X\\)) intercept vanishes. simplify equations therefore often set \\(\\beta_0=0\\).","code":""},{"path":"linear-regression.html","id":"objectives-in-data-analysis-using-linear-regression","chapter":"15 Linear Regression","heading":"15.7 Objectives in data analysis using linear regression","text":"Understand functional relationship: find estimates intercept (\\(\\hat{\\beta}_0\\)) regression coefficients (\\(\\hat{\\beta}_j\\)), well associated errors.Understand functional relationship: find estimates intercept (\\(\\hat{\\beta}_0\\)) regression coefficients (\\(\\hat{\\beta}_j\\)), well associated errors.Prediction:\nKnown coefficients \\(\\beta_0\\) \\(\\boldsymbol \\beta\\):\n\\(y^{\\star} = \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x\\)\nEstimated coefficients \\(\\hat{\\beta}_0\\) \\(\\hat{\\beta}\\) (note “hat”!):\n\\(\\hat{y} =\\hat{\\beta}_0 + \\sum^{d}_{j=1} \\hat{\\beta}_j x_j = \\hat{\\beta}_0 + \\hat{\\boldsymbol \\beta}^T \\boldsymbol x\\)\npoint prediction find corresponding prediction error!Prediction:Known coefficients \\(\\beta_0\\) \\(\\boldsymbol \\beta\\):\n\\(y^{\\star} = \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x\\)Estimated coefficients \\(\\hat{\\beta}_0\\) \\(\\hat{\\beta}\\) (note “hat”!):\n\\(\\hat{y} =\\hat{\\beta}_0 + \\sum^{d}_{j=1} \\hat{\\beta}_j x_j = \\hat{\\beta}_0 + \\hat{\\boldsymbol \\beta}^T \\boldsymbol x\\)point prediction find corresponding prediction error!Variable importance: predictors \\(x_j\\) relevant?\\(\\rightarrow\\) test whether \\(\\beta_j=0\\)\\(\\rightarrow\\) find measures variable importance\nRemark: see \\(\\beta_j\\) \\(\\hat{\\beta}_j\\) measure variable importance!Variable importance: predictors \\(x_j\\) relevant?\\(\\rightarrow\\) test whether \\(\\beta_j=0\\)\\(\\rightarrow\\) find measures variable importanceRemark: see \\(\\beta_j\\) \\(\\hat{\\beta}_j\\) measure variable importance!","code":""},{"path":"estimating-regression-coefficients.html","id":"estimating-regression-coefficients","chapter":"16 Estimating regression coefficients","heading":"16 Estimating regression coefficients","text":"chapter discuss various ways estimate regression coefficients. First, discuss estimation Ordinary Least Squares (OLS)\nminimising residual sum squares. yields famous\nGauss estimator. Second, derive estimates regression coefficients\nusing methods maximum likelihood assuming normal errors. also leads Gauss estimator. Third, show coefficients \nlinear regression can written interpreted terms two\ncovariance matrices Gauss estimator regression coefficients\nplug-estimator using MLEs covariance matrices.\nFurthermore, show (population version) Gauss estimator\ncan also derived finding best linear predictor conditioning.\nFinally, discuss special cases regression coefficients relationship\nmarginal correlation.","code":""},{"path":"estimating-regression-coefficients.html","id":"ordinary-least-squares-ols-estimator-of-regression-coefficients","chapter":"16 Estimating regression coefficients","heading":"16.1 Ordinary Least Squares (OLS) estimator of regression coefficients","text":"Now show classic way (Gauss 1809; Legendre 1805) estimate regression coefficients method \nordinary least squares (OLS).Idea: choose regression coefficients minimise squared error observations prediction.data matrix notation (note assume \\(\\beta_0=0\\) thus centered data \\(\\boldsymbol X\\) \\(\\boldsymbol y\\)):\\[\\text{RSS}(\\boldsymbol \\beta)=(\\boldsymbol y-\\boldsymbol X\\boldsymbol \\beta)^T(\\boldsymbol y-\\boldsymbol X\\boldsymbol \\beta)\\]RSS abbreviation “Residual Sum Squares” function \\(\\boldsymbol \\beta\\).\nMinimising RSS yields OLS estimate:\\[\\widehat{\\boldsymbol \\beta}_{\\text{OLS}}=\\underset{\\boldsymbol \\beta}{\\arg \\min}\\, \\text{RSS}(\\boldsymbol \\beta)\\]\\[\\text{RSS}(\\boldsymbol \\beta) = \\boldsymbol y^T \\boldsymbol y- 2 \\boldsymbol \\beta^T \\boldsymbol X^T \\boldsymbol y+ \\boldsymbol \\beta^T \\boldsymbol X^T \\boldsymbol X\\boldsymbol \\beta\\]Gradient:\n\\[\\nabla \\text{RSS}(\\boldsymbol \\beta) = -2\\boldsymbol X^T \\boldsymbol y+ 2\\boldsymbol X^T \\boldsymbol X\\boldsymbol \\beta\\]\\[\\nabla \\text{RSS}(\\widehat{\\boldsymbol \\beta}) = 0 \\longrightarrow \\boldsymbol X^T \\boldsymbol y= \\boldsymbol X^T\\boldsymbol X\\widehat{\\boldsymbol \\beta}\\]\\[\\Longrightarrow \\widehat{\\boldsymbol \\beta}_{\\text{OLS}} = \\left(\\boldsymbol X^T\\boldsymbol X\\right)^{-1} \\boldsymbol X^T \\boldsymbol y\\]Note similarities procedure maximum likelihood (ML) estimation (minimisation instead maximisation)! fact, \nsee next chance OLS indeed special case ML!\nalso implies OLS generally good method — sample size \\(n\\) large!Gauss’ estimator fundamental statistics worthwile memorise !","code":""},{"path":"estimating-regression-coefficients.html","id":"maximum-likelihood-estimation-of-regression-coefficients","chapter":"16 Estimating regression coefficients","heading":"16.2 Maximum likelihood estimation of regression coefficients","text":"","code":""},{"path":"estimating-regression-coefficients.html","id":"normal-log-likelihood-function-for-regression-coefficients-and-noise-variance","chapter":"16 Estimating regression coefficients","heading":"16.2.1 Normal log-likelihood function for regression coefficients and noise variance","text":"now show estimate regression coefficients using method\nmaximum likelihood. second method derive \\(\\hat{\\boldsymbol \\beta}\\).recall basic regression equation\n\\[\ny = \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x+ \\varepsilon\n\\]\nindependent noise \\(\\varepsilon\\) observed data \\(y_1, \\ldots, y_n\\) \\(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n\\).Assuming \\(\\text{E}(\\varepsilon)=0\\) intercept identified \n\\[\n\\beta_0 = \\mu_{y}- \\boldsymbol \\beta^T \\boldsymbol \\mu_{\\boldsymbol x}\n\\]\nCombining two equations see noise variable equals\n\\[\n\\varepsilon = (y- \\mu_{y}) - \\boldsymbol \\beta^T (\\boldsymbol x-\\boldsymbol \\mu_{\\boldsymbol x})\n\\]Assuming joint (multivariate) normality observed data, response \\(y\\) predictors \\(\\boldsymbol x\\), get MLEs respective means (co)variances:\\(\\hat{\\mu}_y=\\hat{\\text{E}}(y)= \\frac{1}{n}\\sum^n_{=1} y_i\\)\\(\\hat{\\sigma}^2_y=\\widehat{\\text{Var}}(y)= \\frac{1}{n}\\sum^n_{=1} (y_i - \\hat{\\mu}_y)^2\\)\\(\\hat{\\boldsymbol \\mu}_{\\boldsymbol x}=\\hat{\\text{E}}(\\boldsymbol x)= \\frac{1}{n}\\sum^n_{=1} \\boldsymbol x_i\\)\\(\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}=\\widehat{\\text{Var}}(\\boldsymbol x)= \\frac{1}{n}\\sum^n_{=1} (\\boldsymbol x_i-\\hat{\\boldsymbol \\mu}_{\\boldsymbol x}) (\\boldsymbol x_i-\\hat{\\boldsymbol \\mu}_{\\boldsymbol x})^T\\)\\(\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol xy}=\\widehat{\\text{Cov}}(\\boldsymbol x, y)= \\frac{1}{n}\\sum^n_{=1} (\\boldsymbol x_i-\\hat{\\boldsymbol \\mu}_{\\boldsymbol x}) (y_i - \\hat{\\mu}_y)\\)Note sufficient statistics hence summarize perfectly\nobserved data \\(\\boldsymbol x\\) \\(y\\) normal assumptionConsequently, residuals (indirect observations noise variable) given choice regression\ncoefficients \\(\\boldsymbol \\beta\\) observed data \\(\\boldsymbol x\\) \\(y\\) \n\\[\n\\varepsilon_i = (y_i- \\hat{\\mu}_{y}) - \\boldsymbol \\beta^T (\\boldsymbol x_i -\\hat{\\boldsymbol \\mu}_{\\boldsymbol x})\n\\]Assuming noise \\(\\varepsilon \\sim N(0, \\sigma^2_{\\varepsilon})\\)\nnormally distributed mean 0 variance \\(\\text{Var}(\\varepsilon) = \\sigma^2_{\\varepsilon}\\).\ncan write normal log-likelihood function \\(\\sigma^2_{\\varepsilon}\\) \\(\\boldsymbol \\beta\\):\n\\[\n\\begin{split}\n\\log L(\\boldsymbol \\beta,\\sigma^2_{\\varepsilon} )\n&= -\\frac{n}{2} \\log \\sigma^2_{\\varepsilon} - \\frac{1}{2\\sigma^2_{\\varepsilon}} \\sum^n_{=1} \\left((y_i- \\hat{\\mu}_{y}) - \\boldsymbol \\beta^T (\\boldsymbol x_i -\\hat{\\boldsymbol \\mu}_{\\boldsymbol x})\\right)^2\\\\\n\\end{split}\n\\]\nMaximising function leads MLEs \\(\\sigma^2_{\\varepsilon}\\) \\(\\boldsymbol \\beta\\)!Note residual sum squares appears log-likelihood function\n(minus sign), implies ML assuming normal distribution recover\nOLS estimator regression coefficients! OLS special case ML !","code":""},{"path":"estimating-regression-coefficients.html","id":"detailed-derivation-of-the-mles","chapter":"16 Estimating regression coefficients","heading":"16.2.2 Detailed derivation of the MLEs","text":"gradient regard \\(\\boldsymbol \\beta\\) \n\\[\n\\begin{split}\n\\nabla_{\\boldsymbol \\beta} \\log L(\\boldsymbol \\beta,\\sigma^2_{\\varepsilon} ) &= \\frac{1}{\\sigma^2_{\\varepsilon}} \\sum^n_{=1} \\left((\\boldsymbol x_i -\\hat{\\boldsymbol \\mu}_{\\boldsymbol x} ) (y_i - \\hat{\\mu}_{y}) - (\\boldsymbol x_i -\\hat{\\boldsymbol \\mu}_{\\boldsymbol x} )(\\boldsymbol x_i -\\hat{\\boldsymbol \\mu}_{\\boldsymbol x})^T \\boldsymbol \\beta\\right)  \\\\\n&= \\frac{n}{\\sigma^2_{\\varepsilon}} \\left( \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol xy} -  \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}\\boldsymbol \\beta\\right)\\\\\n\\end{split}\n\\]\nSetting equal zero yields Gauss estimator\n\\[\n\\hat{\\boldsymbol \\beta} = \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{-1} \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol xy}  \n\\]\nplugin get MLE \\(\\beta_0\\)\n\n\\[\n\\hat{\\beta}_0 = \\hat{\\mu}_{y}- \\hat{\\boldsymbol \\beta}^T \\hat{\\boldsymbol \\mu}_{\\boldsymbol x}\n\\]\nTaking derivative \\(\\log L(\\hat{\\boldsymbol \\beta},\\sigma^2_{\\varepsilon} )\\) regard \\(\\sigma^2_{\\varepsilon}\\) yields\n\\[\n\\frac{\\partial}{\\partial \\sigma^2_{\\varepsilon}} \\log L(\\hat{\\boldsymbol \\beta},\\sigma^2_{\\varepsilon} ) = -\\frac{n}{2\\sigma^2_{\\varepsilon}} +\\frac{1}{2\\sigma^4_{\\varepsilon}} \\sum^n_{=1}  (y_i-\\hat{y}_i)^2\n\\]\n\\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\boldsymbol \\beta}^T \\boldsymbol x_i\\) residuals \\(y_i-\\hat{y}_i\\) resulting fitted linear model.\nleads MLE noise variance\n\\[\n\\widehat{\\sigma^2_{\\varepsilon}}  = \\frac{1}{n}\\sum^n_{=1}(y_i-\\hat{y}_i)^2\n\\]Note MLE \\(\\widehat{\\sigma^2_{\\varepsilon}}\\) biased estimate \\(\\sigma^2_{\\varepsilon}\\). unbiased estimate \\(\\frac{1}{n-d-1}\\sum^n_{=1}(y_i-\\hat{y}_i)^2\\), \\(d\\) dimension \\(\\boldsymbol \\beta\\)\n(.e. number predictors).","code":""},{"path":"estimating-regression-coefficients.html","id":"asymptotics","chapter":"16 Estimating regression coefficients","heading":"16.2.3 Asymptotics","text":"advantage using maximum likelihood also get (asympotic) variance associated estimator typically can also assume asymptotic normality.Specifically, \\(\\hat{\\boldsymbol \\beta}\\) get via observed Fisher information MLE\nasymptotic estimator variance\n\\[\\widehat{\\text{Var}}(\\widehat{\\boldsymbol \\beta})=\\frac{1}{n} \\widehat{\\sigma^2_{\\varepsilon}} \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{-1}\\]\nSimilarly, \\(\\hat{\\beta}_0\\) \n\\[\n\\widehat{\\text{Var}}(\\widehat{\\beta}_0)=\\frac{1}{n} \\widehat{\\sigma^2_{\\varepsilon}} (1 + \\hat{\\boldsymbol \\mu}^T \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{-1} \\hat{\\boldsymbol \\mu})\n\\]finite sample size \\(n\\) known \\(\\text{Var}(\\varepsilon)\\) one can show variances \n\\[\\text{Var}(\\widehat{\\boldsymbol \\beta})=\\frac{1}{n} \\sigma^2_{\\varepsilon}\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{-1}\\]\n\n\\[\n\\text{Var}(\\widehat{\\beta}_0)=\\frac{1}{n} \\sigma^2_{\\varepsilon} (1 + \\hat{\\boldsymbol \\mu}^T_{\\boldsymbol x} \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{-1} \\hat{\\boldsymbol \\mu}_{\\boldsymbol x})\n\\]\nregression coefficients intercept normally distributed according \n\\[\n\\widehat{\\boldsymbol \\beta} \\sim N_d(\\boldsymbol \\beta, \\text{Var}(\\widehat{\\boldsymbol \\beta}))\n\\]\n\n\\[\n\\widehat{\\beta}_0 \\sim N(\\beta_0, \\text{Var}(\\widehat{\\beta}_0))\n\\]may use test whether whether \\(\\beta_j = 0\\) \\(\\beta_0 = 0\\).","code":""},{"path":"estimating-regression-coefficients.html","id":"covariance-plug-in-estimator-of-regression-coefficients","chapter":"16 Estimating regression coefficients","heading":"16.3 Covariance plug-in estimator of regression coefficients","text":"","code":""},{"path":"estimating-regression-coefficients.html","id":"regression-coeffients-as-product-of-variances","chapter":"16 Estimating regression coefficients","heading":"16.3.1 Regression coeffients as product of variances","text":"now try understand regression coefficients terms covariances (thus obtaining third way compute estimate ).recall Gauss regression coefficients given \\[\\widehat{\\boldsymbol \\beta} = \\left(\\boldsymbol X^T\\boldsymbol X\\right)^{-1}\\boldsymbol X^T \\boldsymbol y\\]\n\\(\\boldsymbol X\\) \\(n \\times d\\) data matrix (statistics convention)\\[\\boldsymbol X= \\begin{pmatrix} x_{11} & \\dots & x_{1d} \\\\ \\vdots & \\ddots & \\vdots \\\\ x_{n1} & \\dots & x_{nd} \\end{pmatrix}\\]\nNote assume data matrix \\(\\boldsymbol X\\) centered (.e. column sums\n\\(\\boldsymbol X^T \\boldsymbol 1_n = \\boldsymbol 0\\) zero).Likewise \\(\\boldsymbol y= (y_1, \\ldots, y_n)^T\\) response data vector (also centered \\(\\boldsymbol y^T \\boldsymbol 1_n = 0\\)).Noting \n\\[\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}=\\frac{1}{n}(\\boldsymbol X^T\\boldsymbol X)\\]\nMLE covariance matrix among \\(\\boldsymbol x\\)\n\n\\[\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol xy}=\\frac{1}{n}(\\boldsymbol X^T \\boldsymbol y)\\]\nMLE covariance \\(\\boldsymbol x\\) \\(y\\)\nsee OLS estimate regression coefficients can expressed \n\\[\\widehat{\\boldsymbol \\beta} = \\left(\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}\\right)^{-1}\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol xy}\\]\ncan write population version (hats!): \\[\\boldsymbol \\beta= \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}\\]Thus, OLS regression coefficients can interpreted plugin estimator using MLEs covariances!\nfact, may also use unbiased estimates since scale factor (\\(1/n\\) \\(1/(n-1)\\)) cancels matter\none use!","code":""},{"path":"estimating-regression-coefficients.html","id":"importance-of-positive-definiteness-of-estimated-covariance-matrix","chapter":"16 Estimating regression coefficients","heading":"16.3.2 Importance of positive definiteness of estimated covariance matrix","text":"Note \\(\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}\\) inverted \\(\\widehat{\\boldsymbol \\beta} = \\left(\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}\\right)^{-1}\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol xy}\\).Hence, estimate \\(\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}\\) needs positive definite!\\(\\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{\\text{MLE}}\\) positive definite \\(n>d\\)!Therefore can use ML estimate (empirical estimator) large \\(n\\) > \\(d\\),\notherwise need employ different (regularised) estimation approach (e.g. Bayes penalised ML)!Remark: writing \\(\\hat{\\boldsymbol \\beta}\\) explicitly based covariance estimates advantage \ncan construct plug-estimators regression coefficients based regularised\ncovariance estimators improve ML small sample size.\nleads -called SCOUT method (=covariance-regularized regression Witten Tibshirani, 2008).","code":""},{"path":"estimating-regression-coefficients.html","id":"standardised-regression-coefficients-and-their-relationship-to-correlation","chapter":"16 Estimating regression coefficients","heading":"16.4 Standardised regression coefficients and their relationship to correlation","text":"recall relationship regression coefficients \\(\\boldsymbol \\beta\\) \nmarginal covariance \\(\\boldsymbol \\Sigma_{\\boldsymbol xy}\\) covariances among \npredictors \\(\\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}\\):\\[\\boldsymbol \\beta= \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}\\]can rewrite regression coefficients terms marginal correlations \\(\\boldsymbol P_{\\boldsymbol xy}\\)\ncorrelations \\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x}\\) among predictors using variance-correlation decompositions \\(\\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}= \\boldsymbol V_{\\boldsymbol x}^{1/2} \\boldsymbol P_{\\boldsymbol x\\boldsymbol x} \\boldsymbol V_{\\boldsymbol x}^{1/2}\\) \\(\\boldsymbol \\Sigma_{\\boldsymbol xy}= \\boldsymbol V_{\\boldsymbol x}^{1/2} \\boldsymbol P_{\\boldsymbol xy} \\sigma_y\\):\n\\[\n\\begin{split}\n\\boldsymbol \\beta&= \\underbrace{\\boldsymbol V_{\\boldsymbol x}^{-1/2}}_{\\text{(inverse) scale } x_i} \\,\\,\n          \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy} \\,\\,\n          \\underbrace{\\sigma_y}_{\\text{ scale }y} \\\\\n  &= \\boldsymbol V_{\\boldsymbol x}^{-1/2} \\,\\, \\boldsymbol \\beta_{\\text{std}} \\,\\,  \\sigma_y \\\\\n\\end{split}\n\\]\nThus regression coefficients \\(\\boldsymbol \\beta\\) contain scale variables, \ntake account correlations among predictors (\\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x}\\))\naddition marginal correlations response \\(y\\) predictors \\(x_i\\) (\\(\\boldsymbol P_{\\boldsymbol xy}\\)).decomposition allows understand number special cases regression coefficients simplify :response predictors standardised variance one, .e. \\(\\text{Var}(y)=1\\) \\(\\text{Var}(x_i)=1\\), \\(\\boldsymbol \\beta\\) becomes equal \nstandardised regression coefficients\n\\[\\boldsymbol \\beta_{\\text{std}} = \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy}\\]\nNote standardised regression coefficients make use variances thus scale-independent.response predictors standardised variance one, .e. \\(\\text{Var}(y)=1\\) \\(\\text{Var}(x_i)=1\\), \\(\\boldsymbol \\beta\\) becomes equal \nstandardised regression coefficients\n\\[\\boldsymbol \\beta_{\\text{std}} = \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy}\\]\nNote standardised regression coefficients make use variances thus scale-independent.correlation among predictors , .e. \\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x} = \\boldsymbol \\)\nregression coefficients reduce \n\\[\\boldsymbol \\beta= \\boldsymbol V_{\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}\\]\n\\(\\boldsymbol V_{\\boldsymbol x}\\) diagonal matrix containing variances predictors.\nalso called marginal regression. Note inversion \\(\\boldsymbol V_{\\boldsymbol x}\\)\ntrival since need invert diagonal element individually.correlation among predictors , .e. \\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x} = \\boldsymbol \\)\nregression coefficients reduce \n\\[\\boldsymbol \\beta= \\boldsymbol V_{\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}\\]\n\\(\\boldsymbol V_{\\boldsymbol x}\\) diagonal matrix containing variances predictors.\nalso called marginal regression. Note inversion \\(\\boldsymbol V_{\\boldsymbol x}\\)\ntrival since need invert diagonal element individually.) b) apply simultaneously (.e. correlation among predictors response predictors predictors\nstandardised) \nregression coefficients simplify even \n\\[\n\\boldsymbol \\beta= \\boldsymbol P_{\\boldsymbol xy}\n\\]\nThus, special case regression coefficients identical correlations response predictors!) b) apply simultaneously (.e. correlation among predictors response predictors predictors\nstandardised) \nregression coefficients simplify even \n\\[\n\\boldsymbol \\beta= \\boldsymbol P_{\\boldsymbol xy}\n\\]\nThus, special case regression coefficients identical correlations response predictors!","code":""},{"path":"estimating-regression-coefficients.html","id":"further-ways-to-obtain-regression-coefficients","chapter":"16 Estimating regression coefficients","heading":"16.5 Further ways to obtain regression coefficients","text":"","code":""},{"path":"estimating-regression-coefficients.html","id":"best-linear-predictor","chapter":"16 Estimating regression coefficients","heading":"16.5.1 Best linear predictor","text":"best linear predictor fourth way arrive linear model. closely related OLS minimising squared residual error.Without assuming normality multiple regression model\ncan shown optimal linear predictor minimum mean squared prediction error:Assumptions:\\(y\\) \\(\\boldsymbol x\\) random variableswe construct new variable (linear predictor)\n\\(y^{\\star\\star} = b_0 + \\boldsymbol b^T \\boldsymbol x\\) optimally approximate \\(y\\)Aim:choose \\(b_0\\) \\(\\boldsymbol b\\) minimize mean squared prediction error\n\\(\\text{E}( (y - y^{\\star\\star})^2 )\\)","code":""},{"path":"estimating-regression-coefficients.html","id":"result","chapter":"16 Estimating regression coefficients","heading":"16.5.1.1 Result:","text":"mean squared prediction error \\(MSPE\\) dependence \\((b_0, \\boldsymbol b)\\) \n\\[\n\\begin{split}\n\\text{E}( (y - y^{\\star\\star} )^2) & = \\text{Var}(y - y^{\\star\\star}) + \\text{E}(y - y^{\\star\\star})^2 \\\\\n  & = \\text{Var}(y - b_0 -\\boldsymbol b^T \\boldsymbol x) + ( \\text{E}(y) -b_0 - \\boldsymbol b^T \\text{E}(\\boldsymbol x) )^2 \\\\\n& = \\sigma^2_y + \\text{Var}(\\boldsymbol b^T \\boldsymbol x) + 2 \\, \\text{Cov}(y, -\\boldsymbol b^T \\boldsymbol x)  + ( \\mu_y -b_0 - \\boldsymbol b^T \\boldsymbol \\mu_{\\boldsymbol x} )^2 \\\\\n  & = \\sigma^2_y + \\boldsymbol b^T \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x} \\boldsymbol b- 2 \\, \\boldsymbol b^T \\boldsymbol \\Sigma_{\\boldsymbol xy} + ( \\mu_y -b_0 - \\boldsymbol b^T \\boldsymbol \\mu_{\\boldsymbol x} )^2 \\\\\n  & = MSPE(b_0, \\boldsymbol b) \\\\\n\\end{split}\n\\]look \n\\[\n(\\beta_0, \\boldsymbol \\beta) = \\underset{b_0,\\boldsymbol b}{\\arg\\min} \\,\\, MSPE(b_0, \\boldsymbol b)\n\\]order find minimum compute gradient regard \\((b_0, \\boldsymbol b)\\)\n\\[\n\\nabla MSPE =\n\\begin{pmatrix}\n-2( \\mu_y -b_0 - \\boldsymbol b^T \\boldsymbol \\mu_{\\boldsymbol x} ) \\\\\n2 \\, \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x} \\boldsymbol b- 2 \\, \\boldsymbol \\Sigma_{\\boldsymbol xy} -2 \\boldsymbol \\mu_{\\boldsymbol x} (\\mu_y -b_0 - \\boldsymbol b^T \\boldsymbol \\mu_{\\boldsymbol x}) \\\\\n\\end{pmatrix}\n\\]\nsetting equal zero yields\n\\[\n\\begin{pmatrix}\n\\beta_0\\\\\n\\boldsymbol \\beta\\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\mu_y- \\boldsymbol \\beta^T \\boldsymbol \\mu_{\\boldsymbol x} \\\\\n\\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}\\\\\n\\end{pmatrix}\n\\]\nThus, optimal values \\(b_0\\) \\(\\boldsymbol b\\) best linear predictor\ncorrespond previously derived coefficients \\(\\beta_0\\) \\(\\boldsymbol \\beta\\)!","code":""},{"path":"estimating-regression-coefficients.html","id":"irreducible-error","chapter":"16 Estimating regression coefficients","heading":"16.5.1.2 Irreducible Error","text":"minimum achieved MSPE (=irreducible error) \n\\[\nMSPE(\\beta_0,\\boldsymbol \\beta)\n= \\sigma^2_{y} - \\boldsymbol \\beta^T \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x} \\boldsymbol \\beta= \\sigma^2_{y} -  \\boldsymbol \\Sigma_{y \\boldsymbol x} \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}\n\\]\nabbreviation\n\\(\\Omega^2 = \\boldsymbol P_{y \\boldsymbol x} \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy} = \\sigma_y^{-2} \\boldsymbol \\Sigma_{y \\boldsymbol x} \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}\\)\ncan simplify \n\\[\nMSPE(\\beta_0,\\boldsymbol \\beta)\n=  \\sigma^2_y (1-\\Omega^2) = \\text{Var}(\\varepsilon)\n\\]Writing \\(b_0=\\beta_0 + \\Delta_0\\) \\(\\boldsymbol b= \\boldsymbol \\beta+ \\boldsymbol \\Delta\\) easy see \nmean squared predictive error quadratic function around minimum:\n\\[\nMSPE(\\beta_0 + \\Delta_0, \\boldsymbol \\beta+ \\boldsymbol \\Delta) = \\text{Var}(\\varepsilon) + \\Delta_0^2 + \\boldsymbol \\Delta^T \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x} \\boldsymbol \\Delta\n\\]Note usually \\(y^{\\star} = \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x\\) perfectly approximate \\(y\\) irreducible error (= noise variance)\n\\[\\text{Var}(\\varepsilon) =\\sigma^2_y (1-\\Omega^2) > 0\\]\nimplies \\(\\Omega^2 < 1\\).quantity \\(\\Omega^2\\) interpretation population version \nsquared multiple correlation coefficient response predictors\nplays vital role decomposition variance, discussed later.","code":""},{"path":"estimating-regression-coefficients.html","id":"regression-by-conditioning","chapter":"16 Estimating regression coefficients","heading":"16.5.2 Regression by conditioning","text":"Conditioning fifth way arrive linear model. also general way can used derive many regression models\n(just simple linear model).","code":""},{"path":"estimating-regression-coefficients.html","id":"general-idea","chapter":"16 Estimating regression coefficients","heading":"16.5.2.1 General idea:","text":"two random variables \\(y\\) (response, scalar) \\(\\boldsymbol x\\) (predictor variables, vector)assume \\(y\\) \\(\\boldsymbol x\\) joint distribution \\(F_{y,\\boldsymbol x}\\)compute conditional random variable \\(y | \\boldsymbol x\\) \ncorresponding distribution \\(F_{y | \\boldsymbol x}\\)","code":""},{"path":"estimating-regression-coefficients.html","id":"multivariate-normal-assumption","chapter":"16 Estimating regression coefficients","heading":"16.5.2.2 Multivariate normal assumption","text":"Now assume \\(y\\) \\(\\boldsymbol x\\) (jointly) multivariate normal. conditional distribution \\(F_{y | \\boldsymbol x}\\) univariate normal following moments (can verify looking general conditional multivariate normal distribution):) Conditional expectation:\\[ \\text{E}( y | \\boldsymbol x) = y^{\\star} = \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x\\]coefficients \\(\\boldsymbol \\beta= \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1}\\boldsymbol \\Sigma_{\\boldsymbol xy}\\) \nintercept \\(\\beta_0 = \\mu_{y} - \\boldsymbol \\beta^T \\boldsymbol \\mu_{\\boldsymbol x}\\) .Note \\(y^{\\star}\\) depends \\(\\boldsymbol x\\) random variable \nmean\n\\[\n\\text{E}(y^{\\star}) = \\beta_0 + \\boldsymbol \\beta^T  \\boldsymbol \\mu_{\\boldsymbol x} = \\mu_{y}\n\\]\nvariance\n\\[\n\\begin{split}\n\\text{Var}(y^{\\star}) & = \\text{Var}(\\text{E}( y | \\boldsymbol x)) \\\\\n& = \\boldsymbol \\beta^T \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x} \\boldsymbol \\beta= \\boldsymbol \\Sigma_{y \\boldsymbol x} \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy} \\\\\n& = \\sigma^2_y \\boldsymbol P_{y \\boldsymbol x} \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy} \\\\\n& = \\sigma_y^2 \\Omega^2\\\\\n\\end{split}\n\\]b) Conditional variance:\\[\n\\begin{split}\n\\text{Var}( y | \\boldsymbol x) &=\\sigma^2_y - \\boldsymbol \\beta^T \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x} \\boldsymbol \\beta\\\\\n& = \\sigma^2_y - \\boldsymbol \\Sigma_{y \\boldsymbol x} \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}  \\\\\n& = \\sigma^2_y (1-\\Omega^2)\\\\\n\\end{split}\n\\]\nNote constant \\(\\text{E}(\\text{Var}( y | \\boldsymbol x)) = \\sigma^2_y (1-\\Omega^2)\\) well.","code":""},{"path":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression.html","id":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression","chapter":"17 Squared multiple correlation and variance decomposition in linear regression","heading":"17 Squared multiple correlation and variance decomposition in linear regression","text":"chapter first introduce (squared) multiple correlation multiple adjusted \\(R^2\\) coefficients estimators. Subsequently\ndiscuss variance decomposition.","code":""},{"path":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression.html","id":"squared-multiple-correlation-omega2-and-the-r2-coefficient","chapter":"17 Squared multiple correlation and variance decomposition in linear regression","heading":"17.1 Squared multiple correlation \\(\\Omega^2\\) and the \\(R^2\\) coefficient","text":"previous chapter encountered following quantity:\n\\[\n\\Omega^2 =  \\boldsymbol P_{y \\boldsymbol x} \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy} = \\sigma_y^{-2} \\boldsymbol \\Sigma_{y \\boldsymbol x} \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}\n\\]\\(\\boldsymbol \\beta=\\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy}\\)\n\n\\(\\beta_0=\\mu_y- \\boldsymbol \\beta^T \\boldsymbol \\mu_{\\boldsymbol x}\\) straightforward verify following:cross-covariance \\(y\\) \\(y^{\\star}\\) \n\\[\n\\begin{split}\n\\text{Cov}(y, y^{\\star}) &= \\boldsymbol \\Sigma_{y  \\boldsymbol x} \\boldsymbol \\beta= \\boldsymbol \\Sigma_{y \\boldsymbol x} \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol \\Sigma_{\\boldsymbol xy} \\\\\n& = \\sigma^2_y \\boldsymbol P_{y \\boldsymbol x} \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy} = \\sigma_y^2 \\Omega^2\\\\\n\\end{split}\n\\](signal) variance \\(y^{\\star}\\) \n\\[\n\\begin{split}\n\\text{Var}(y^{\\star}) &= \\boldsymbol \\beta^T \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x} \\boldsymbol \\beta= \\boldsymbol \\Sigma_{y \\boldsymbol x} \\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}^{-1}  \\boldsymbol \\Sigma_{\\boldsymbol xy} \\\\\n& = \\sigma^2_y \\boldsymbol P_{y \\boldsymbol x} \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy} = \\sigma_y^2 \\Omega^2\\\\\n\\end{split}\n\\]hence correlation \\(\\text{Cor}(y, y^{\\star}) = \\frac{\\text{Cov}(y, y^{\\star})}{\\text{SD}(y) \\text{SD}(y^{\\star})} = \\Omega\\) \\(\\Omega \\geq 0\\).helps understand \\(\\Omega\\) \\(\\Omega^2\\) coefficients:\\(\\Omega\\) linear correlation response (\\(y\\)) prediction \\(y^{\\star}\\).\\(\\Omega\\) linear correlation response (\\(y\\)) prediction \\(y^{\\star}\\).\\(\\Omega^2\\) called squared multiple correlation scalar \\(y\\) vector \\(\\boldsymbol x\\).\\(\\Omega^2\\) called squared multiple correlation scalar \\(y\\) vector \\(\\boldsymbol x\\).Note one predictor (\\(x\\) scalar) \n\\(\\boldsymbol P_{x x} = 1\\) \\(\\boldsymbol P_{y x} = \\rho_{yx}\\) multiple squared correlation coefficient reduces squared correlation\n\\(\\Omega^2 = \\rho_{yx}^2\\) two scalar random variables \\(y\\) \\(x\\).Note one predictor (\\(x\\) scalar) \n\\(\\boldsymbol P_{x x} = 1\\) \\(\\boldsymbol P_{y x} = \\rho_{yx}\\) multiple squared correlation coefficient reduces squared correlation\n\\(\\Omega^2 = \\rho_{yx}^2\\) two scalar random variables \\(y\\) \\(x\\).","code":""},{"path":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression.html","id":"estimation-of-omega2-and-the-multiple-r2-coefficient","chapter":"17 Squared multiple correlation and variance decomposition in linear regression","heading":"17.1.1 Estimation of \\(\\Omega^2\\) and the multiple \\(R^2\\) coefficient","text":"multiple squared correlation coefficient \\(\\Omega^2\\) can estimated plug-empirical estimates corresponding correlation matrices:\n\\[R^2 =  \\hat{\\boldsymbol P}_{y \\boldsymbol x} \\hat{\\boldsymbol P}_{\\boldsymbol x\\boldsymbol x}^{-1} \\hat{\\boldsymbol P}_{\\boldsymbol xy} = \\hat{\\sigma}_y^{-2} \\hat {\\boldsymbol \\Sigma}_{y \\boldsymbol x} \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{-1} \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol xy}\\]\nestimator \\(\\Omega^2\\) called multiple \\(R^2\\) coefficient.scale factor \\(1/n\\) \\(1/(n-1)\\) used estimating variance \\(\\sigma^2_y\\) \ncovariances \\(\\boldsymbol \\Sigma_{\\boldsymbol x\\boldsymbol x}\\) \\(\\boldsymbol \\Sigma_{y \\boldsymbol x}\\) factor cancel .seen \\(\\Omega^2\\) directly linked noise variance via\n\\[\n\\text{Var}(\\varepsilon) =\\sigma^2_y (1-\\Omega^2) \\,.\n\\]\ncan express squared multiple correlation \n\\[\n\\Omega^2 = 1- \\text{Var}(\\varepsilon) / \\sigma^2_y\n\\]maximum likelihood estimate noise variance \\(\\text{Var}(\\varepsilon)\\) (also called residual variance) can computed residual sum squares \\(RSS = \\sum_{=1}^n (y_i -\\hat{y}_i)^2\\)\nfollows:\n\\[\n\\widehat{\\text{Var}}(\\varepsilon)_{ML} = \\frac{RSS}{n}\n\\]\nwhereas unbiased estimate obtained \n\\[\n\\widehat{\\text{Var}}(\\varepsilon)_{UB} = \\frac{RSS}{n-d-1} = \\frac{RSS}{df}\n\\]\ndegree freedom \\(df=n-d-1\\) \\(d\\) number predictors.Similarly, can find maximum likelihood estimate \\(v_y^{ML}\\) \\(\\sigma^2_y\\)\n(factor \\(1/n\\)) well unbiased estimate \\(v_y^{UB}\\) (scale factor \\(1/(n-1)\\))multiple \\(R^2\\) coefficient can written \n\\[\nR^2 =1- \\widehat{\\text{Var}}(\\varepsilon)_{ML} / v_y^{ML}\n\\]\nNote use MLEs.contrast, -called adjusted multiple \\(R^2\\) coefficient given \n\\[\nR^2_{\\text{adj}}=1- \\widehat{\\text{Var}}(\\varepsilon)_{UB} / v_y^{UB}\n\\]\nunbiased variances used.\\(R^2\\) \\(R^2_{\\text{adj}}\\) estimates \\(\\Omega^2\\) related \n\\[\n1-R^2 = (1- R^2_{\\text{adj}}) \\, \\frac{df}{n-1}\n\\]","code":""},{"path":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression.html","id":"r-commands","chapter":"17 Squared multiple correlation and variance decomposition in linear regression","heading":"17.1.2 R commands","text":"R command lm() fits linear regression model.addition regression cofficients (derived quantities) R function lm() also liststhe multiple R-squared \\(R^2\\),adjusted R-squared \\(R^2_{\\text{adj}}\\),degrees freedom \\(df\\) andthe residual standard error \\(\\sqrt{\\widehat{\\text{Var}}(\\varepsilon)_{UB}}\\) (computed unbiased variance estimate).See also Worksheet R3 provides R code reproduce exact output native lm() R function.","code":""},{"path":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression.html","id":"variance-decomposition-in-regression","chapter":"17 Squared multiple correlation and variance decomposition in linear regression","heading":"17.2 Variance decomposition in regression","text":"squared multiple correlation coefficient useful also plays important role decomposition total variance:total variance: \\(\\text{Var}(y) = \\sigma^2_y\\)unexplained variance (irreducible error): \\(\\sigma^2_y (1-\\Omega^2) = \\text{Var}(\\varepsilon)\\)explained variance complement: \\(\\sigma^2_y \\Omega^2 = \\text{Var}(y^{\\star})\\)summary:\\[\\text{Var}(y)  =  \\text{Var}(y^{\\star}) + \\text{Var}(\\varepsilon)\\]\nbecomes\n\\[\\underbrace{\\sigma^2_y}_{\\text{total variance}}  = \\underbrace{\\sigma_y^2 \\Omega^2}_{\\text{explained variance}}\n+ \\underbrace{ \\sigma^2_y (1-\\Omega^2)}_{\\text{unexplained variance}}\\]unexplained variance measures fit introducing predictors model (smaller means better fit).\ntotal variance measures fit model without predictors. explained variance\ndifference total unexplained variance, indicates increase model fit\ndue predictors.","code":""},{"path":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression.html","id":"law-of-total-variance-and-variance-decomposition","chapter":"17 Squared multiple correlation and variance decomposition in linear regression","heading":"17.2.1 Law of total variance and variance decomposition","text":"law total variance \\[\\underbrace{\\text{Var}(y)}_{\\text{total variance}}  = \\underbrace{\\text{Var}( \\text{E}(y | \\boldsymbol x) ) }_{\\text{explained variance}}\n+ \\underbrace{ \\text{E}( \\text{Var}( y | \\boldsymbol x) )}_{\\text{unexplained variance}}\\]provides general decomposition explained unexplained parts variance valid regardless form distributions \\(F_{y, \\boldsymbol x}\\) \\(F_{y | \\boldsymbol x}\\).regression conncects\nvariance decomposition conditioning. plug-conditional expections multivariate\nnormal model (cf. previous chapter) recover\\[\\underbrace{\\sigma^2_y}_{\\text{total variance}}  = \\underbrace{\\sigma_y^2 \\Omega^2 }_{\\text{explained variance}}\n+ \\underbrace{ \\sigma^2_y (1-\\Omega^2)}_{\\text{unexplained variance}}\\]","code":""},{"path":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression.html","id":"related-quantities","chapter":"17 Squared multiple correlation and variance decomposition in linear regression","heading":"17.2.2 Related quantities","text":"Using three quantities (total variance, explained variance, unexplained variance)\ncan construct number scores:coefficient determination, squared multiple correlation:\\[\n\\frac{\\text{explained var}}{\\text{total var}} = \\frac{\\sigma_y^2 \\Omega^2}{\\sigma_y^2} = \\Omega^2\n\\]\n(range 0 1, 1 indicating perfect fit)coefficient non-determination, coefficient alienation:\\[\n\\frac{\\text{unexplained var}}{\\text{total var}} = \\frac{\\sigma_y^2 (1-\\Omega^2)}{\\sigma_y^2} = 1-\\Omega^2\n\\]\n(range 0 1, 0 indicating perfect fit)\\(F\\) score, \\(t^2\\) score:\\[\n\\frac{\\text{explained var}}{\\text{unexplained var}} = \\frac{\\sigma_y^2 \\Omega^2}{\\sigma_y^2 (1-\\Omega^2)} = \\frac{\\Omega^2}{1-\\Omega^2} = \\mathcal{F} = \\frac{\\tau^2}{n}\n\\]\n(range 0 \\(\\infty\\), \\(\\infty\\) indicating perfect fit)Note \\(\\mathcal{F}\\) \\(\\tau^2\\) scores population versions \n\\(F\\) \\(t^2\\) statistics.Also note \\(\\Omega^2 = \\frac{\\tau^2}{\\tau^2 + n} = \\frac{\\mathcal{F}}{\\mathcal{F} + 1}\\) links squared correlation squared \\(t\\)-scores \\(F\\)-scores.","code":""},{"path":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression.html","id":"sample-version-of-variance-decomposition","chapter":"17 Squared multiple correlation and variance decomposition in linear regression","heading":"17.3 Sample version of variance decomposition","text":"\\(\\Omega^2\\) \\(\\sigma^2_y\\) replaced MLEs can written sample version follows using data points \\(y_i\\), predictions \\(\\hat{y}_i\\) \\(\\bar{y} = \\frac{1}{n}\\sum_{=1}^n {y_i}\\)\\[\\underbrace{\\sum_{=1}^n (y_i-\\bar{y})^2}_{\\text{total sum squares (TSS)}}  = \\underbrace{\\sum_{=1}^n (\\hat{y}_i-\\bar{y})^2 }_{\\text{explained sum squares (ESS)}}\n+ \\underbrace{\\sum_{=1}^n (y_i-\\hat{y}_i)^2 }_{\\text{residual sum squares (RSS)}}\\]Note TSS, ESS RSS scale \\(n\\).\nUsing data vector notation sample-based variance decomposition can written form Pythagorean theorem:\n\\[\\underbrace{|| \\boldsymbol y-\\bar{y} \\boldsymbol 1\\ ||^2}_{\\text{total sum squares (TSS)}}  =\n\\underbrace{||\\hat{\\boldsymbol y}-\\bar{y} \\boldsymbol 1||^2 }_{\\text{explained sum squares (ESS)}}\n+ \\underbrace{|| \\boldsymbol y-\\hat{\\boldsymbol y} ||^2 }_{\\text{residual sum squares (RSS)}}\\]","code":""},{"path":"squared-multiple-correlation-and-variance-decomposition-in-linear-regression.html","id":"geometric-interpretation-of-regression-as-orthogonal-projection","chapter":"17 Squared multiple correlation and variance decomposition in linear regression","heading":"17.3.1 Geometric interpretation of regression as orthogonal projection:","text":"equation can simplified \\[|| \\boldsymbol y||^2  =\n||\\hat{\\boldsymbol y}||^2\n+ \\underbrace{|| \\boldsymbol y-\\hat{\\boldsymbol y} ||^2 }_{\\text{RSS}}\n\\]Geometrically speaking, implies \\(\\hat{\\boldsymbol y}\\) orthogonal projection \\(\\boldsymbol y\\), since \nresiduals \\(\\boldsymbol y-\\hat{\\boldsymbol y}\\) predictions \\(\\hat{\\boldsymbol y}\\) orthogonal (construction!).also valid centered versions vectors, .e.\n\\(\\hat{\\boldsymbol y}-\\bar{y} \\boldsymbol 1_n\\) orthogonal projection \\(\\boldsymbol y-\\bar{y} \\boldsymbol 1_n\\) (see Figure).Also note angle \\(\\theta\\) two centered vectors directly related (estimated) multiple correlation, \\(R = \\cos(\\theta) = \\frac{||\\hat{\\boldsymbol y}-\\bar{y} \\boldsymbol 1_n ||}{|| \\boldsymbol y-\\bar{y} \\boldsymbol 1_n||}\\), \\(R^2 = \\cos(\\theta)^2 = \\frac{||\\hat{\\boldsymbol y}-\\bar{y} \\boldsymbol 1_n ||^2}{|| \\boldsymbol y-\\bar{y} \\boldsymbol 1_n||^2} = \\frac{\\text{ESS}}{\\text{TSS}}\\).Source Figure: Stack Exchange","code":""},{"path":"prediction-and-variable-selection.html","id":"prediction-and-variable-selection","chapter":"18 Prediction and variable selection","heading":"18 Prediction and variable selection","text":"chapter discuss compute (lower bounds) \nprediction error select variables relevant prediction","code":""},{"path":"prediction-and-variable-selection.html","id":"prediction-and-prediction-intervals","chapter":"18 Prediction and variable selection","heading":"18.1 Prediction and prediction intervals","text":"Learning regression function (training) data first step application regression models.next step actually make prediction future outcomes \\(y^{\\text{test}}\\) given test data\n\\(\\boldsymbol x^{\\text{test}}\\):\n\\[\ny^{\\text{test}} = \\hat{y}(\\boldsymbol x^{\\text{test}}) = \\hat{f}_{\\hat{\\beta}_0, \\hat{\\boldsymbol \\beta}}(\\boldsymbol x^{\\text{test}})\n\\]Note \n\\(y^{\\text{test}}\\) point estimator. possible also construct corresponding interval estimate?answer yes, leads back conditioning approach:\\[y^\\star = \\text{E}(y| \\boldsymbol x) = \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x\\]\\[\\text{Var}(\\varepsilon) = \\text{Var}(y|\\boldsymbol x) = \\sigma^2_y (1-\\Omega^2)\\]know mean squared prediction error \\(y^{\\star}\\) \\(\\text{E}((y -y^{\\star})^2)=\\text{Var}(\\varepsilon)\\) minimal irreducible error. Hence, may use \\(\\text{Var}(\\varepsilon)\\) minimum variability prediction.corresponding prediction interval \n\\[\\left[ y^{\\star}(\\boldsymbol x^{\\text{test}}) \\pm c \\times \\text{SD}(\\varepsilon) \\right]\\]\n\\(c\\) suitable constant (e.g. 1.96 symmetric 95% normal intervals).However, please note prediction interval constructed fashion underestimate.\nreason assumes employ \\(y^{\\star} = \\beta_0 + \\boldsymbol \\beta^T \\boldsymbol x\\) reality actually use \\(\\hat{y} = \\hat{\\beta}_0 + \\hat{\\boldsymbol \\beta}^T \\boldsymbol x\\) prediction — note estimated coefficients! recall earlier chapter (best linear predictor) leads increase MSPE compared using optimal \\(\\beta_0\\) \\(\\boldsymbol \\beta\\).Thus, better prediction intervals need consider mean squared prediction error \\(\\hat{y}\\) can written \\(\\text{E}((y -\\hat{y})^2) = \\text{Var}(\\varepsilon) + \\delta\\) \\(\\delta\\) additional error term due using estimated rather true regression function. \\(\\delta\\) typically declines \\(1/n\\) can substantial small \\(n\\) (particular usually depends number predictors \\(d\\)).details refer later modules regression.","code":""},{"path":"prediction-and-variable-selection.html","id":"variable-importance-and-prediction","chapter":"18 Prediction and variable selection","heading":"18.2 Variable importance and prediction","text":"Another key question regression modelling find \npredictor variables \\(x_1, x_2, \\dots, x_d\\) actually important predicting outcome \\(y\\).\\(\\rightarrow\\) need study variable importance measures (VIM).","code":""},{"path":"prediction-and-variable-selection.html","id":"how-to-quantify-variable-importance","chapter":"18 Prediction and variable selection","heading":"18.2.1 How to quantify variable importance?","text":"variable \\(x_i\\) important improves prediction response \\(y\\).Recall variance decomposition:\\[\\text{Var}(y) = \\sigma_y^2 = \\underbrace{\\sigma^2_y\\Omega^2}_{\\text{explained variance}} + \\underbrace{\\sigma^2_y(1-\\Omega^2)}_{\\text{unexplained/residual variance =} \\text{Var}(\\varepsilon)}\\]\\(\\Omega^2\\) squared multiple correlation \\(\\[0,1]\\)\\(\\Omega^2\\) large \\(\\rightarrow 1\\) predictor variables explain \\(\\sigma_y^2\\)\\(\\Omega^2\\) small \\(\\rightarrow 0\\) linear model fails predictors explain variability\\(\\Rightarrow\\) predictor helps \\(\\begin{array}{ll} \\text{increase explained variance} \\\\ \\text{decrease unexplained variance} \\end{array}\\) important!\\(\\Omega^2 = \\boldsymbol P_{y\\boldsymbol x} \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy} \\hat{=}\\) function \\(X\\)!VIM: predictors contribute \\(\\Omega^2\\)","code":""},{"path":"prediction-and-variable-selection.html","id":"some-candidates-for-vims","chapter":"18 Prediction and variable selection","heading":"18.2.2 Some candidates for VIMs","text":"regression coefficients \\(\\boldsymbol \\beta\\)\n\\(\\boldsymbol \\beta= \\boldsymbol \\Sigma^{-1}_{\\boldsymbol x\\boldsymbol x} \\boldsymbol \\Sigma_{\\boldsymbol xy}= \\boldsymbol V_{\\boldsymbol x}^{-1/2} \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy} \\sigma_y\\)\ngood VIM since \\(\\boldsymbol \\beta\\) contains scale!\nLarge \\(\\hat{\\beta}_i\\) indicate \\(x_i\\) important.\nSmall \\(\\hat{\\beta}_i\\) indicate \\(x_i\\) important.\nregression coefficients \\(\\boldsymbol \\beta\\)\\(\\boldsymbol \\beta= \\boldsymbol \\Sigma^{-1}_{\\boldsymbol x\\boldsymbol x} \\boldsymbol \\Sigma_{\\boldsymbol xy}= \\boldsymbol V_{\\boldsymbol x}^{-1/2} \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy} \\sigma_y\\)good VIM since \\(\\boldsymbol \\beta\\) contains scale!Large \\(\\hat{\\beta}_i\\) indicate \\(x_i\\) important.Small \\(\\hat{\\beta}_i\\) indicate \\(x_i\\) important.Standardised regression coefficients \\(\\boldsymbol \\beta_{\\text{std}}\\)\n\\(\\boldsymbol \\beta_{\\text{std}} = \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy}\\)\nimplies \\(\\text{Var}(y)=1\\), \\(\\text{Var}(x_i)=1\\)\ncontain scale (better \\(\\hat{\\beta}\\))\nstill unclear relates decomposition variance\nStandardised regression coefficients \\(\\boldsymbol \\beta_{\\text{std}}\\)\\(\\boldsymbol \\beta_{\\text{std}} = \\boldsymbol P_{\\boldsymbol x\\boldsymbol x}^{-1} \\boldsymbol P_{\\boldsymbol xy}\\)implies \\(\\text{Var}(y)=1\\), \\(\\text{Var}(x_i)=1\\)contain scale (better \\(\\hat{\\beta}\\))still unclear relates decomposition varianceSquared marginal correlations \\(\\rho_{y, x_i}^2\\)\nConsider case uncorrelated predictors: \\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x}=\\boldsymbol \\) (correlation among \\(x_i\\))\n\\[\\Rightarrow \\Omega^2 = \\boldsymbol P_{y\\boldsymbol x} \\boldsymbol P_{\\boldsymbol xy} = \\sum^d_{=1} \\rho_{y, x_i}^2\\]\n\\(\\rho_{y, x_i}^2 = \\text{Cor}(y, x_i)\\) marginal correlation \\(y\\) \\(x_i\\), \\(\\Omega^2\\) (uncorrelated predictors) sum squared marginal correlations.\n\\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x}=\\boldsymbol \\), ranking predictors \\(\\rho_{y, x_i}^2\\) optimal!\npredictor largest marginal correlation reduces unexplained variance !\ngood news: even weak correlation among predictors marginal correlations still good VIM (perfectly add \\(\\Omega^2\\))\nAdvantage: simple often also effective.\nCaution! strong correlation \\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x}\\), colinearity (case oftern best remove one strongly correlated variables, merge correlated variables).\nSquared marginal correlations \\(\\rho_{y, x_i}^2\\)Consider case uncorrelated predictors: \\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x}=\\boldsymbol \\) (correlation among \\(x_i\\))\\[\\Rightarrow \\Omega^2 = \\boldsymbol P_{y\\boldsymbol x} \\boldsymbol P_{\\boldsymbol xy} = \\sum^d_{=1} \\rho_{y, x_i}^2\\]\\(\\rho_{y, x_i}^2 = \\text{Cor}(y, x_i)\\) marginal correlation \\(y\\) \\(x_i\\), \\(\\Omega^2\\) (uncorrelated predictors) sum squared marginal correlations.\\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x}=\\boldsymbol \\), ranking predictors \\(\\rho_{y, x_i}^2\\) optimal!predictor largest marginal correlation reduces unexplained variance !good news: even weak correlation among predictors marginal correlations still good VIM (perfectly add \\(\\Omega^2\\))Advantage: simple often also effective.Caution! strong correlation \\(\\boldsymbol P_{\\boldsymbol x\\boldsymbol x}\\), colinearity (case oftern best remove one strongly correlated variables, merge correlated variables).Often, ranking predictors squared marginal correlations done prefiltering step\n(independence screening).","code":""},{"path":"prediction-and-variable-selection.html","id":"regression-t-scores.","chapter":"18 Prediction and variable selection","heading":"18.3 Regression \\(t\\)-scores.","text":"","code":""},{"path":"prediction-and-variable-selection.html","id":"wald-statistic-for-regression-coefficients","chapter":"18 Prediction and variable selection","heading":"18.3.1 Wald statistic for regression coefficients","text":"far, discussed three obvious candidates variable importance measures\n(regression coefficients, standardised regression coefficients, marginal correlations).section consider quantity, \nregression \\(t-\\)score:Recall ML estimation regression coefficients yieldsa point estimate \\(\\hat{\\boldsymbol \\beta}\\)(asymptotic) variance \\(\\widehat{\\text{Var}}(\\hat{\\boldsymbol \\beta})\\)asymptotic normal distribution \\(\\hat{\\boldsymbol \\beta} \\overset{}{\\sim} N_d(\\boldsymbol \\beta, \\widehat{\\text{Var}}(\\hat{\\boldsymbol \\beta}))\\)Corresponding predictor \\(x_i\\) can construct \\(t\\)-score\n\\[\nt_i = \\frac{\\hat{\\beta}_i}{\\widehat{\\text{SD}}(\\hat{\\beta}_i)}\n\\]\nstandard deviations computed \\(\\widehat{\\text{SD}}(\\hat{\\beta}_i) = \\text{Diag}(\\widehat{\\text{Var}}(\\hat{\\boldsymbol \\beta}))_{}\\). corresponds Wald statistic test underlying true\nregression coefficient zero (\\(\\beta_i =0\\)).Correspondingly, null hypthesis \\(\\beta_i=0\\) asymptotically large \\(n\\)\nregression \\(t\\)-score standard normal distributed:\n\\[\nt_i \\overset{}{\\sim} N(0,1)\n\\]\nallows compute (symmetric) \\(p\\)-values \\(p = 2 \\Phi(-|t_i|)\\) \\(\\Phi\\) standard normal distribution function.finite \\(n\\), assuming normality observation using unbiased estimate variance\ncomputing \\(t_i\\), exact distribution \\(i_i\\) given Student-\\(t\\) distribution:\n\\[\nt_i \\sim t_{n-d-1}\n\\]Regression \\(t\\)-scores can thus used test whether regression coefficient zero.\nlarge magnitude \\(t_i\\) score indicates hypothesis \\(\\beta_i=0\\) can rejected.\nThus, small \\(p\\)-value (say smaller 0.05) signals regression coefficient non-zero hence corresponding predictor variable included model.allows rank predictor variables \\(|t_i|\\) corresponding \\(p\\)-values regard relevance linear model. Typically, order simplify model, predictors largest \\(p\\)-values (thus smallest absolute \\(t\\)-scores) may removed model. However, note \\(p\\)-value say larger 0.05 sufficient declare regression coefficient zero (classical statistical testing can reject null hypothesis, accept !).Note construction regression \\(t\\)-scores depend scale, original data rescaled affect corresponding regression \\(t\\)-scores.\nFurthermore, \\(\\widehat{\\text{SD}}(\\hat{\\beta}_i)\\) small, regression \\(t\\)-score\n\\(t_i\\) can still large even \\(\\hat{\\beta}_i\\) small!","code":""},{"path":"prediction-and-variable-selection.html","id":"computing","chapter":"18 Prediction and variable selection","heading":"18.3.2 Computing","text":"perform regression analysis R (another statistical software package) computer return following:\\[\\begin{align*}\n\\begin{array}{cc}\n\\hat{\\beta}_i\\\\\n\\text{Estimated}\\\\\n\\text{repression}\\\\\n\\text{coefficient}\\\\\n\\\\\n\\end{array}\n\\begin{array}{cc}\n\\widehat{\\text{SD}}(\\hat{\\beta}_i)\\\\\n\\text{Error }\\\\\n\\hat{\\beta}_i\\\\\n\\\\\n\\\\\n\\end{array}\n\\begin{array}{cc}\nt_i = \\frac{\\hat{\\beta}_i}{\\widehat{\\text{SD}}(\\hat\\beta_i)}\\\\\n\\text{t-score}\\\\\n\\text{computed }\\\\\n\\text{first two columns}\\\\\n\\\\\n\\end{array}\n\\begin{array}{cc}\n\\text{p-values}\\\\\n\\text{} t_i\\\\\n\\text{based t-distribution}\\\\\n\\\\\n\\\\\n\\end{array}\n\\begin{array}{ll}\n\\text{Indicator }\\\\\n\\text{Significance}\\\\\n\\text{*     } 0.9\\\\\n\\text{**    } 0.95\\\\\n\\text{***   } 0.99\\\\\n\\end{array}\n\\end{align*}\\]lm() function R standard deviation square root unbiased estimate\nvariance (note unbiased!).","code":""},{"path":"prediction-and-variable-selection.html","id":"connection-with-partial-correlation","chapter":"18 Prediction and variable selection","heading":"18.3.3 Connection with partial correlation","text":"deeper reason ranking predictors regression \\(t\\)-scores associated \\(p\\)-values useful link \npartial correlation.particular, (squared) regression \\(t\\)-score can 1:1 transformed \n(estimated) (squared) partial correlation\n\\[\n\\hat{\\rho}_{y, x_i | x_{j \\neq }}^2 = \\frac{t_i^2}{t_i^2 + df}\n\\]\n\\(df=n-d-1\\), can shown \\(p\\)-values testing \\(\\beta_i=0\\) exactly \n\\(p\\)-values testing partial correlation \\(\\rho_{y, x_i | x_{j \\neq }}\\) vanishes!Therefore, ranking predictors \\(x_i\\) regression \\(t\\)-scores leads exactly ranking\n\\(p\\)-values partial correlation!","code":""},{"path":"prediction-and-variable-selection.html","id":"squared-wald-statistic-and-the-f-statistic","chapter":"18 Prediction and variable selection","heading":"18.3.4 Squared Wald statistic and the \\(F\\) statistic","text":"looked individual regression coefficients. However, can also\nconstruct Wald test using complete vector \\(\\hat{\\boldsymbol \\beta}\\). squared Wald statistic\ntest \\(\\boldsymbol \\beta= 0\\) given \n\\[\n\\begin{split}\nt^2 & = \\hat{\\boldsymbol \\beta}^T \\widehat{\\text{Var}}(\\hat{\\boldsymbol \\beta}^{-1}) \\hat{\\boldsymbol \\beta}\\\\\n     & = \\left( \\hat{\\boldsymbol \\Sigma}_{y \\boldsymbol x} \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{-1} \\right)  \n       \\left(  \\frac{n}{ \\widehat{\\sigma^2_{\\varepsilon}} } \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}\\right)\n       \\left(  \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{-1} \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol xy} \\right)  \\\\\n    & = \\frac{n}{ \\widehat{\\sigma^2_{\\varepsilon}} }\n         \\hat{\\boldsymbol \\Sigma}_{y \\boldsymbol x} \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol x\\boldsymbol x}^{-1}   \n         \\hat{\\boldsymbol \\Sigma}_{\\boldsymbol xy}  \\\\\n    & = \\frac{n}{ \\widehat{\\sigma^2_{\\varepsilon}} } \\hat{\\sigma}_y^{2} R^2\\\\\n\\end{split}\n\\]\n\\(\\widehat{\\sigma^2_{\\varepsilon}} / \\hat{\\sigma}_y^{2} = 1- R^2\\)\nfinally get related \\(F\\) statistic\n\\[\n\\frac{t^2}{n} = \\frac{R^2}{1-R^2} = F\n\\]\nfunction \\(R^2\\). \\(R^2=0\\) \\(F=0\\). \\(R^2\\) large (\\(< 1\\)) \\(F\\) large well (\\(< \\infty\\)) null hypothesis \\(\\boldsymbol \\beta= 0\\) can rejected, implies least one regression coefficient non-zero.\nNote squared Wald statistic \\(t^2\\) asymptotically \\(\\chi^2_d\\) distributed useful\nfind critical values compute \\(p\\)-values.","code":""},{"path":"prediction-and-variable-selection.html","id":"further-approaches-for-variable-selection","chapter":"18 Prediction and variable selection","heading":"18.4 Further approaches for variable selection","text":"addition ranking marginal partial correlation, many approaches variable selection regression!Search-based methods:\nsearch subsets linear models \\(d\\) variables, ranging full model (including\npredictors) empty model (includes predictor) everything inbetween.\nProblem: exhaustive search possible even relatively small \\(d\\) space models large!\nTherefore heuristic approaches forward selection (adding predictors), backward selection (removing predictors), monte-carlo random search employed.\nProblem: maximum likelihood used choosing among models - since ML always pick best model. Therefore, penalised ML criteria AIC Bayesian criteria often employed instead.\nSearch-based methods:search subsets linear models \\(d\\) variables, ranging full model (including\npredictors) empty model (includes predictor) everything inbetween.Problem: exhaustive search possible even relatively small \\(d\\) space models large!Therefore heuristic approaches forward selection (adding predictors), backward selection (removing predictors), monte-carlo random search employed.Problem: maximum likelihood used choosing among models - since ML always pick best model. Therefore, penalised ML criteria AIC Bayesian criteria often employed instead.Integrative estimation variable selection:\nmethods fit regression model perform variable selection simultaneously.\nwell-known approach type “lasso” regression (Tibshirani 1996)\napplies (generalised) linear model ML plus L1 penalty.\nAlternative: Bayesian variable selection estimation procedures\nIntegrative estimation variable selection:methods fit regression model perform variable selection simultaneously.well-known approach type “lasso” regression (Tibshirani 1996)applies (generalised) linear model ML plus L1 penalty.Alternative: Bayesian variable selection estimation proceduresEntropy-based variable selection:\nseen , two popular approaches linear models based correlation, either marginal correlation partial correlation (via regression \\(t\\)-scores).\nCorrelation measures can generalised non-linear settings. One popular measure mutual information computed using KL divergence. case two variables \\(x\\) \\(y\\) joint normal distribution correlation \\(\\rho\\) mutual information function correlation:\n\\[\\text{MI}(x,y) = \\frac{1}{2} \\log (1-\\rho^2)\\]\nregression mutual information response \\(y\\) predictor \\(x_i\\) \\(\\text{MI}(y, x_i)\\), widely used feature selection, particular machine learning.Entropy-based variable selection:seen , two popular approaches linear models based correlation, either marginal correlation partial correlation (via regression \\(t\\)-scores).Correlation measures can generalised non-linear settings. One popular measure mutual information computed using KL divergence. case two variables \\(x\\) \\(y\\) joint normal distribution correlation \\(\\rho\\) mutual information function correlation:\n\\[\\text{MI}(x,y) = \\frac{1}{2} \\log (1-\\rho^2)\\]regression mutual information response \\(y\\) predictor \\(x_i\\) \\(\\text{MI}(y, x_i)\\), widely used feature selection, particular machine learning.FDR based variable selection regression:\nFeature selection controling false discovery rate (FDR) among selected features becoming popular,\nparticular number procedures using -called “knockoffs”, see https://web.stanford.edu/group/candes/knockoffs/ .FDR based variable selection regression:Feature selection controling false discovery rate (FDR) among selected features becoming popular,\nparticular number procedures using -called “knockoffs”, see https://web.stanford.edu/group/candes/knockoffs/ .Variable importance using Shapley values:\nBorrowing concept game theory Shapley values recently become popular machine learning evaluate variable importance predictors nonlinear models. relationship statistical methods measuring variable importance focus current research.Variable importance using Shapley values:Borrowing concept game theory Shapley values recently become popular machine learning evaluate variable importance predictors nonlinear models. relationship statistical methods measuring variable importance focus current research.","code":""},{"path":"refresher.html","id":"refresher","chapter":"A Refresher","heading":"A Refresher","text":"Statistics mathematical science requires practical use tools probability,\nvector matrices, analysis etc.briefly list essentials needed “Statistical Methods”.\nPlease familiarise () topics.","code":""},{"path":"refresher.html","id":"basic-mathematical-notation","chapter":"A Refresher","heading":"A.1 Basic mathematical notation","text":"Summation:\n\\[\n\\sum_{=1}^n x_i = x_1 + x_2 + \\ldots + x_n\n\\]Multiplication:\n\\[\n\\prod_{=1}^n x_i = x_1 \\times x_2 \\times \\ldots \\times x_n\n\\]","code":""},{"path":"refresher.html","id":"vectors-and-matrices","chapter":"A Refresher","heading":"A.2 Vectors and matrices","text":"Vector matrix notation.Vector algebra.Eigenvectors eigenvalues real symmetric matrix.Eigenvalue (spectral) decomposition real symmetric matrix.Positive negative definiteness real symmetric matrix (containing positive negative eigenvalues).Singularity real symmetric matrix (containing one eigenvalues identical zero).Singular value decomposition real matrix.Inverse matrix.Trace determinant square matrix.Connection eigenvalues (trace = sum eigenvalues, determinant = product eigenvalues).","code":""},{"path":"refresher.html","id":"functions","chapter":"A Refresher","heading":"A.3 Functions","text":"","code":""},{"path":"refresher.html","id":"gradient","chapter":"A Refresher","heading":"A.3.1 Gradient","text":"gradient scalar-valued function\n\\(h(\\boldsymbol x)\\) vector argument \\(\\boldsymbol x= (x_1, \\ldots, x_d)^T\\)\nvector containing first order partial derivatives\n\\(h(\\boldsymbol x)\\) regard \\(x_1, \\ldots, x_d\\):\n\\[\n\\begin{split}\n\\nabla h(\\boldsymbol x) &= \\begin{pmatrix}\n\\frac{\\partial h(\\boldsymbol x)}{\\partial x_1} \\\\\n\\vdots\\\\\n\\frac{\\partial h(\\boldsymbol x)}{\\partial x_d}\n\\end{pmatrix}\\\\\n&=  \\frac{\\partial h(\\boldsymbol x)}{\\partial \\boldsymbol x} \\\\\n& = \\text{grad } h(\\boldsymbol x) \\\\\n\\end{split}\n\\]\nsymbol \\(\\nabla\\) called nabla operator (also known del operator).Note write gradient column vector. called \ndenominator layout convention, see https://en.wikipedia.org/wiki/Matrix_calculus details.\ncontrast, many textbooks (also earlier versions lecture notes) assume gradients row vectors, following -called numerator layout convention.Example .1  Examples gradient:\\(h(\\boldsymbol x)=\\boldsymbol ^T \\boldsymbol x+ b\\). \\(\\nabla h(\\boldsymbol x) = \\frac{\\partial h(\\boldsymbol x)}{\\partial \\boldsymbol x} = \\boldsymbol \\).\\(h(\\boldsymbol x)=\\boldsymbol x^T \\boldsymbol x\\). \\(\\nabla h(\\boldsymbol x) = \\frac{\\partial h(\\boldsymbol x)}{\\partial \\boldsymbol x} = 2 \\boldsymbol x\\).\\(h(\\boldsymbol x)=\\boldsymbol x^T \\boldsymbol \\boldsymbol x\\). \\(\\nabla h(\\boldsymbol x) = \\frac{\\partial h(\\boldsymbol x)}{\\partial \\boldsymbol x} = (\\boldsymbol + \\boldsymbol ^T) \\boldsymbol x\\).","code":""},{"path":"refresher.html","id":"hessian-matrix","chapter":"A Refresher","heading":"A.3.2 Hessian matrix","text":"matrix second order partial derivates scalar-valued\nfunction vector-valued argument called Hessian matrix:\n\\[\n\\begin{split}\n\\nabla \\nabla^T h(\\boldsymbol x) &=\n\\begin{pmatrix}\n  \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial x_1^2}\n     & \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial x_1 \\partial x_2}\n     & \\cdots\n     & \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial x_1 \\partial x_d} \\\\\n  \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial x_2 \\partial x_1}\n     & \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial x_2^2}\n     & \\cdots\n     & \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial x_2 \\partial x_d} \\\\\n  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n  \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial x_d \\partial x_1}\n     & \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial x_d \\partial x_2}  \n     & \\cdots\n     & \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial x_d^2}\n\\end{pmatrix} \\\\\n&= \\left(\\frac{\\partial h(\\boldsymbol x)}{\\partial x_i \\partial x_j}\\right)  \\\\\n& = \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial \\boldsymbol x\\partial \\boldsymbol x^T} \\\\\n\\end{split}\n\\]\nconstruction Hessian matrix square symmetric.Example .2  \\(h(\\boldsymbol x)=\\boldsymbol x^T \\boldsymbol \\boldsymbol x\\). \\(\\nabla \\nabla^T h(\\boldsymbol x) = \\frac{\\partial^2 h(\\boldsymbol x)}{\\partial \\boldsymbol x\\partial \\boldsymbol x^T} = (\\boldsymbol + \\boldsymbol ^T)\\).","code":""},{"path":"refresher.html","id":"convex-and-concave-functions","chapter":"A Refresher","heading":"A.3.3 Convex and concave functions","text":"function \\(h(x)\\) convex second derivative \\(h''(x) \\geq 0\\) \\(x\\).\ngenerally, function \\(h(\\boldsymbol x)\\), \\(\\boldsymbol x\\) vector, convex Hessian matrix \\(\\nabla \\nabla^T h(\\boldsymbol x)\\)\npositive definite, .e. eigenvalues Hessian matrix positive.\\(h(\\boldsymbol x)\\) convex, \\(-h(\\boldsymbol x)\\) concave. function concave Hessian matrix negative definite, .e. eigenvalues Hessian matrix negative.Example .3  logarithm \\(\\log(x)\\) example concave function whereas \\(x^2\\) convex function.memorise, valley convex.","code":""},{"path":"refresher.html","id":"linear-and-quadratic-approximation","chapter":"A Refresher","heading":"A.3.4 Linear and quadratic approximation","text":"linear quadratic approximation function given Taylor series first second order, respectively.Applied scalar-valued function scalar:\n\\[\nh(x) \\approx h(x_0) + h'(x_0) (x-x_0) + \\frac{1}{2} h''(x_0) (x-x_0)^2\n\\]\nNote \\(h'(x_0) = h'(x) \\,|\\, x_0\\) first derivative \\(h(x)\\) evaluated \\(x_0\\) \n\\(h''(x_0) = h''(x) \\,|\\, x_0\\) second derivative \\(h(x)\\) evaluated \\(x_0\\).\\(x = x_0+ \\varepsilon\\) approximation can also written \n\\[\nh(x_0+ \\varepsilon) \\approx h(x_0) + h'(x_0) \\, \\varepsilon + \\frac{1}{2} h''(x_0)\\, \\varepsilon^2\n\\]Applied scalar-valued function vector:\n\\[\nh(\\boldsymbol x) \\approx h(\\boldsymbol x_0) + \\nabla h(\\boldsymbol x_0)^T (\\boldsymbol x-\\boldsymbol x_0) + \\frac{1}{2}\n(\\boldsymbol x-\\boldsymbol x_0)^T \\, \\nabla \\nabla^T h(\\boldsymbol x_0) \\, (\\boldsymbol x-\\boldsymbol x_0)\n\\]\nNote \\(\\nabla h(\\boldsymbol x_0)\\) gradient \\(h(\\boldsymbol x)\\) evaluated \\(\\boldsymbol x_0\\)\n\\(\\nabla \\nabla^T h(\\boldsymbol x_0)\\) Hessian matrix \\(h(\\boldsymbol x)\\) evaluated \\(\\boldsymbol x_0\\).\\(\\boldsymbol x= \\boldsymbol x_0+ \\boldsymbol \\varepsilon\\) approximation can also written \n\\[\nh(\\boldsymbol x_0+ \\boldsymbol \\varepsilon) \\approx h(\\boldsymbol x_0) + \\nabla h(\\boldsymbol x_0)^T\\boldsymbol \\varepsilon+ \\frac{1}{2} \\boldsymbol \\varepsilon^T \\, \\nabla \\nabla^T h(\\boldsymbol x_0) \\,\\boldsymbol \\varepsilon\n\\]Example .4  Commonly occurring Taylor series approximations second order example\n\\[\n\\log(x_0+\\varepsilon) \\approx \\log(x_0) + \\frac{\\varepsilon}{x_0} - \\frac{\\varepsilon^2}{2 x_0^2}\n\\]\n\n\\[\n\\frac{x_0}{x_0+\\varepsilon} \\approx 1 - \\frac{\\varepsilon}{x_0} + \\frac{\\varepsilon^2}{ x_0^2}\n\\]","code":""},{"path":"refresher.html","id":"conditions-for-local-optimum-of-a-function","chapter":"A Refresher","heading":"A.3.5 Conditions for local optimum of a function","text":"check \\(x_0\\) \\(\\boldsymbol x_0\\) local maximum minimum can use following conditions:function single variable:First derivative zero optimum \\(h'(x_0) = 0\\).second derivative \\(h''(x_0) < 0\\) optimum negative function locally concave optimum maximum.second derivative \\(h''(x_0) > 0\\) positive optimum function locally convex optimum minimum.function several variables:Gradient vanishes maximum, \\(\\nabla h(\\boldsymbol x_0)=0\\).Hessian \\(\\nabla \\nabla^T h(\\boldsymbol x_0)\\) negative definite (= eigenvalues Hessian matrix negative) function locally concave optimum maximum.Hessian positive definite (= eigenvalues Hessian matrix positive) function locally convex optimum minimum.Around local optimum \\(\\boldsymbol x_0\\) can approximate function quadratically using\n\\[\nh(\\boldsymbol x_0+ \\boldsymbol \\varepsilon) \\approx h(\\boldsymbol x_0) +  \\frac{1}{2} \\boldsymbol \\varepsilon^T \\nabla \\nabla^T h(\\boldsymbol x_0) \\boldsymbol \\varepsilon\n\\]\nNote linear term missing due gradient zero \\(\\boldsymbol x_0\\).","code":""},{"path":"refresher.html","id":"combinatorics","chapter":"A Refresher","heading":"A.4 Combinatorics","text":"","code":""},{"path":"refresher.html","id":"number-of-permutations","chapter":"A Refresher","heading":"A.4.1 Number of permutations","text":"number possible orderings, permutations, \\(n\\) distinct items \nnumber ways put \\(n\\) items \\(n\\) bins exactly one item bin. given \nfactorial\n\\[\nn! = \\prod_{=1}^n = 1 \\times 2 \\times \\ldots \\times n\n\\]\n\\(n\\) positive integer.\n\\(n=0\\) factorial defined \n\\[\n0! = 1\n\\]\nexactly one permutation zero objects.factorial can also obtained using \ngamma function\n\\[\n\\Gamma(x) = \\int_0^\\infty t^{x-1} e^{-t} dt\n\\]\ncan viewed continuous version factorial\n\n\\(\\Gamma(x) = (x-1)!\\) positive integer \\(x\\).","code":""},{"path":"refresher.html","id":"multinomial-and-binomial-coefficient","chapter":"A Refresher","heading":"A.4.2 Multinomial and binomial coefficient","text":"number possible permutation \\(n\\) items \\(K\\) distinct types, \\(n_1\\) type 1, \\(n_2\\) type 2 , equals number ways\nput \\(n\\) items \\(K\\) bins \\(n_1\\) items first bin, \\(n_2\\) second .\ngiven multinomial coefficient\n\\[\n\\binom{n}{n_1, \\ldots, n_K} = \\frac {n!}{n_1! \\times n_2! \\times\\ldots \\times n_K! }\n\\]\n\\(\\sum_{k=1}^K n_k = n\\) \\(K \\leq n\\).\nNote equals number permutation items divided number permutations items bin (type).\\(n_k=1\\) hence \\(K=n\\) multinomial coefficient reduces factorial.two bins / types (\\(K=2\\)) multinomial coefficients becomes \nbinomial coefficient\n\\[\n\\binom{n}{n_1} = \\binom{n}{n_1, n-n_1}    =  \\frac {n!}{n_1! (n - n_1)!}\n\\]\ncounts number ways choose \\(n_1\\) elements set \\(n\\) elements.","code":""},{"path":"refresher.html","id":"de-moivre-sterling-approximation-of-the-factorial","chapter":"A Refresher","heading":"A.4.3 De Moivre-Sterling approximation of the factorial","text":"factorial frequently approximated following formula derived Abraham de Moivre (1667–1754) James Stirling (1692-1770)\n\\[\nn! \\approx \\sqrt{2 \\pi} n^{n+\\frac{1}{2}} e^{-n}\n\\]\nequivalently logarithmic scale\n\\[\n\\log n!  \\approx \\left(n+\\frac{1}{2}\\right) \\log n  -n + \\frac{1}{2}\\log \\left( 2 \\pi\\right)\n\\]\napproximation good small \\(n\\) (fails \\(n=0\\)) becomes\naccurate increasing \\(n\\). large \\(n\\) approximation can simplified \n\\[\n\\log n! \\approx  n \\log n  -n\n\\]","code":""},{"path":"refresher.html","id":"probability","chapter":"A Refresher","heading":"A.5 Probability","text":"","code":""},{"path":"refresher.html","id":"random-variables","chapter":"A Refresher","heading":"A.5.1 Random variables","text":"random variable describes random experiment. set possible outcomes\nsample space state space denoted \n\\(\\Omega = \\{\\omega_1, \\omega_2, \\ldots\\}\\). outcomes \\(\\omega_i\\) elementary events.\nsample space \\(\\Omega\\) can finite infinite. Depending type outcomes\nrandom variable discrete continuous.event \\(\\subseteq \\Omega\\) subset \\(\\Omega\\) thus set elementary events \\(= \\{a_1, a_2, \\ldots\\}\\).\nincludes special cases full set \\(= \\Omega\\), empty set \\(= \\emptyset\\), elementary\nevents \\(=\\omega_i\\). complementary event \\(^C\\) complement set \\(\\) set \\(\\Omega\\)\n\\(^C = \\Omega \\setminus = \\{\\omega_i \\\\Omega: \\omega_i \\notin \\}\\).probability event denoted \\(\\text{Pr}()\\).\nassume \\(\\text{Pr}() \\geq 0\\), probabilities positive,\\(\\text{Pr}(\\Omega) = 1\\),\ncertain event probability 1, \\(\\text{Pr}() = \\sum_{a_i \\} \\text{Pr}(a_i)\\), probability \nevent equals sum constituting elementary events \\(a_i\\).implies\\(\\text{Pr}() \\leq 1\\), .e. probabilities lie interval \\([0,1]\\)\\(\\text{Pr}(^C) = 1 - \\text{Pr}()\\), \\(\\text{Pr}(\\emptyset) = 0\\)Assume now two events \\(\\) \\(B\\).\nprobability event “\\(\\) \\(B\\)” given probability set intersection\n\\(\\text{Pr}(\\cap B)\\).\nLikewise probability event “\\(\\) \\(B\\)” given probability set union\n\\(\\text{Pr}(\\cup B)\\).clear probability theory closely linked set theory,\nparticular measure theory. allows unified treatment discrete\ncontinuous random variables (elegant framework needed module).","code":""},{"path":"refresher.html","id":"probability-mass-and-density-function-and-distribution-and-quantile-function","chapter":"A Refresher","heading":"A.5.2 Probability mass and density function and distribution and quantile function","text":"describe random variable \\(x\\) need assign probabilities corresponding elementary outcomes\n\\(x \\\\Omega\\). convenience use name denote random variable elementary outcomes.discrete random variable employ probability mass function (PMF).\ndenote lower case \\(f\\) occasionally also use\n\\(p\\) \\(q\\). discrete case can define \nevent \\(= \\{x: x=\\} = \\{\\}\\) obtain probability directly PMF:\n\\[\\text{Pr}() = \\text{Pr}(x=) =f() \\,.\\]\nPMF property \\(\\sum_{x \\\\Omega} f(x) = 1\\) \n\\(f(x) \\[0,1]\\).continuous random variables need use probability density function (PDF)\ninstead. define event\n\\(= \\{x: < x \\leq + da\\}\\) infinitesimal interval\nassign probability\n\\[\n\\text{Pr}() = \\text{Pr}( < x \\leq + da) = f() da \\,.\n\\]\nPDF property \\(\\int_{x \\\\Omega} f(x) dx = 1\\)\ncontrast PMF density \\(f(x)\\geq 0\\) may take values larger\n1.Assuming ordering\ncan define event \\(= \\{x: x \\leq \\}\\) compute \nprobability\n\\[\nF() = \\text{Pr}() = \\text{Pr}( x \\leq ) =\n\\begin{cases}\n\\sum_{x \\} f(x) & \\text{discrete case} \\\\\n\\int_{x \\} f(x) dx & \\text{continuous case} \\\\\n\\end{cases}\n\\]\nknown distribution function, cumulative distribution function (CDF)\ndenoted upper case \\(F\\) corresponding PDF/PMF \\(f\\)\n(\\(P\\) \\(Q\\) corresponding PDF/PMF \\(p\\) \\(q\\)).\nconstruction distribution function monotonically increasing value ranges 0 1.\nhelp can compute probability general interval sets \n\\[\n\\text{Pr}( < x \\leq b ) = F(b)-F() \\,.\n\\]inverse distribution function \\(y=F(x)\\) quantile function \\(x=F^{-1}(y)\\).\n50% quantile \\(F^{-1}\\left(\\frac{1}{2}\\right)\\) median.random variable \\(x\\) distribution function \\(F\\) write \\(x \\sim F\\).","code":""},{"path":"refresher.html","id":"expection-and-variance-of-a-random-variable","chapter":"A Refresher","heading":"A.5.3 Expection and variance of a random variable","text":"expected value \\(\\text{E}(x)\\) random variable defined \nweighted average possible outcomes, weight given PMF / PDF \\(f(x)\\):\n\\[\n\\text{E}(x) =\n\\begin{cases}\n\\sum_{x \\\\Omega} f(x) x & \\text{discrete case} \\\\\n\\int_{x \\\\Omega} f(x) x dx & \\text{continuous case} \\\\\n\\end{cases}\n\\]\nemphasise expecation taken regard distribution\n\\(F\\) write \\(\\text{E}_F(x)\\) distribution \\(F\\) subscript. expectation necessarily always defined continuous\nrandom variable integral may diverge.expected value function random variable \\(h(x)\\) \nobtained similarly:\n\\[\n\\text{E}(h(x)) =\n\\begin{cases}\n\\sum_{x \\\\Omega} f(x) h(x) & \\text{discrete case} \\\\\n\\int_{x \\\\Omega} f(x) h(x) dx & \\text{continuous case} \\\\\n\\end{cases}\n\\]\ncalled “law unconscious statistician”, short LOTUS.\n, highlight random variable \\(x\\) distribution \\(F\\) \nwrite \\(\\text{E}_F(h(x))\\).event \\(\\) can define corresponding indicator function\n\\[\n1_A(x) =\n\\begin{cases}\n1 & x \\\\\\\n0 & x \\notin \\\\\n\\end{cases}\n\\]\nIntriguingly,\n\\[\n\\text{E}(1_A(x) ) = \\text{Pr}()\n\\]\n.e. expectation indicator variable \\(\\) probability\n\\(\\).moments random variables also defined expectation:Zeroth moment: \\(\\text{E}(x^0) = 1\\) definition PDF PMF,First moment: \\(\\text{E}(x^1) = \\text{E}(x) = \\mu\\) , mean,Second moment: \\(\\text{E}(x^2)\\)variance second momented centered mean \\(\\mu\\):\n\\[\\text{Var}(x) = \\text{E}( (x - \\mu)^2 ) = \\sigma^2\\]variance can also computed \\(\\text{Var}(x) = \\text{E}(x^2)-\\text{E}(x)^2\\).distribution necessarily need finite first higher moments.\nexample Cauchy distribution mean variance (higher moment).","code":""},{"path":"refresher.html","id":"transformation-of-random-variables","chapter":"A Refresher","heading":"A.5.4 Transformation of random variables","text":"Linear transformation random variables: \\(\\) \\(b\\) constants \\(x\\) random variable, random variable \\(y= + b x\\) mean \\(\\text{E}(y) = + b \\text{E}(x)\\) variance \\(\\text{Var}(y) = b^2 \\text{Var}(x)\\).general invertible coordinate transformation \\(y = h(x) = y(x)\\) backtransformation \\(x = h^{-1}(y) = x(y)\\).transformation infinitesimal volume element \\(dy = |\\frac{dy}{dx}| dx\\).transformation density \\(f_y(y) =\\left|\\frac{dx}{dy}\\right| f_x(x(y))\\).Note \\(\\left|\\frac{dx}{dy}\\right| = \\left|\\frac{dy}{dx}\\right|^{-1}\\).","code":""},{"path":"refresher.html","id":"law-of-large-numbers","chapter":"A Refresher","heading":"A.5.5 Law of large numbers:","text":"Suppose observe data \\(D=\\{x_1, \\ldots, x_n\\}\\) \\(x_i \\sim F\\).strong law large numbers empirical distribution\n\\(\\hat{F}_n\\) based data \\(D=\\{x_1, \\ldots, x_n\\}\\) converges true underlying distribution \\(F\\) \\(n \\rightarrow \\infty\\) almost surely:\n\\[\n\\hat{F}_n\\overset{. s.}{\\} F\n\\]\nGlivenko–Cantelli theorem asserts convergence uniform. Since strong law implies weak law also convergence probability:\n\\[\n\\hat{F}_n\\overset{P}{\\} F\n\\]strong law large numbers empirical distribution\n\\(\\hat{F}_n\\) based data \\(D=\\{x_1, \\ldots, x_n\\}\\) converges true underlying distribution \\(F\\) \\(n \\rightarrow \\infty\\) almost surely:\n\\[\n\\hat{F}_n\\overset{. s.}{\\} F\n\\]\nGlivenko–Cantelli theorem asserts convergence uniform. Since strong law implies weak law also convergence probability:\n\\[\n\\hat{F}_n\\overset{P}{\\} F\n\\]Correspondingly, \\(n \\rightarrow \\infty\\) average \\(\\text{E}_{\\hat{F}_n}(h(x)) = \\frac{1}{n} \\sum_{=1}^n h(x_i)\\) converges expectation \\(\\text{E}_{F}(h(x))\\).Correspondingly, \\(n \\rightarrow \\infty\\) average \\(\\text{E}_{\\hat{F}_n}(h(x)) = \\frac{1}{n} \\sum_{=1}^n h(x_i)\\) converges expectation \\(\\text{E}_{F}(h(x))\\).","code":""},{"path":"refresher.html","id":"jensens-inequality","chapter":"A Refresher","heading":"A.5.6 Jensen’s inequality","text":"\\[\\text{E}(h(\\boldsymbol x)) \\geq h(\\text{E}(\\boldsymbol x))\\]\nconvex function \\(h(\\boldsymbol x)\\).Recall: convex function (\\(x^2\\)) shape “valley”.","code":""},{"path":"refresher.html","id":"distributions","chapter":"A Refresher","heading":"A.6 Distributions","text":"","code":""},{"path":"refresher.html","id":"bernoulli-distribution-and-binomial-distribution","chapter":"A Refresher","heading":"A.6.1 Bernoulli distribution and binomial distribution","text":"Bernoulli distribution \\(\\text{Ber}(\\theta)\\) simplest distribution possible.\nnamed Jacob Bernoulli (1655-1705)\nalso invented law large numbers.describes discrete binary random variable\ntwo states \\(x=0\\) (“failure”) \\(x=1\\) (“success”),\nparameter \\(\\theta \\[0,1]\\) probability “success”.\nOften Bernoulli distribution also referred “coin tossing” model \ntwo outcomes “heads” “tails”.Correspondingly, probability mass function \\(\\text{Ber}(\\theta)\\) \n\\[\np(x=0) = \\text{Pr}(\\text{\"failure\"}) = 1-\\theta  \n\\]\n\n\\[\np(x=1) = \\text{Pr}(\\text{\"success\"}) = \\theta\n\\]\ncompact way write PMF Bernoulli distribution \n\\[\np(x | \\theta ) = \\theta^{x} (1-\\theta)^{1-x}\n\\]random variable \\(x\\) follows Bernoulli distribution \nwrite\n\\[\nx \\sim \\text{Ber}(\\theta) \\,.\n\\]\nexpected value \\(\\text{E}(x) = \\theta\\) variance \\(\\text{Var}(x) = \\theta (1 - \\theta)\\).Closely related Bernoulli distribution binomial distribution\n\\(\\text{Bin}(n, \\theta)\\) results repeating \nBernoulli experiment \\(n\\) times counting number successes among\n\\(n\\) trials (without keeping track ordering experiments).\nThus, \\(x_1, \\ldots, x_n\\) \\(n\\) independent \\(\\text{Ber}(\\theta)\\) random variables\n\\(y = \\sum_{=1}^n\\) distributed \\(\\text{Bin}(n, \\theta)\\).probability mass function :\n\\[\np(y | n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}\n\\]\n\\(y \\\\{ 0, 1, 2, \\ldots, n\\}\\).\nbinomial coefficient \\(\\binom{n}{x}\\) needed account multiplicity\nways (orderings samples) can observe \\(y\\) sucesses.expected value \\(\\text{E}(y) = n \\theta\\) variance \\(\\text{Var}(y) = n \\theta (1 - \\theta)\\).random variable \\(y\\) follows binomial distribution \nwrite\n\\[\ny \\sim \\text{Bin}(n, \\theta)\\,\n\\]\n\\(n=1\\) reduces Bernoulli distribution \\(\\text{Ber}(\\theta)\\).R PMF binomial distribution called dbinom(). binomial coefficient computed choose().","code":""},{"path":"refresher.html","id":"normal-distribution","chapter":"A Refresher","heading":"A.6.2 Normal distribution","text":"normal distribution important continuous probability distribution.\nalso called Gaussian distribution named Carl Friedrich Gauss (1777–1855).univariate normal distribution \\(N(\\mu, \\sigma^2)\\) two parameters \\(\\mu\\) (location) \\(\\sigma^2\\) (scale):\\[\nx \\sim N(\\mu,\\sigma^2)\n\\]\nmean\n\\[\n\\text{E}(x)=\\mu\n\\]\nvariance\n\\[\n\\text{Var}(x) = \\sigma^2\n\\]Probability density function (PDF):\n\\[\np(x| \\mu, \\sigma^2)=(2\\pi\\sigma^2)^{-\\frac{1}{2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n\\]R density function called dnorm().standard normal distribution \\(N(0, 1)\\) mean 0 variance 1.Plot PDF standard normal:cumulative distribution function (CDF) standard normal \\(N(0,1)\\)\n\n\\[\n\\Phi (x ) = \\int_{-\\infty}^{x} f(x'| \\mu=0, \\sigma^2=1) dx'\n\\]\nanalytic expression \\(\\Phi(x)\\). R function called pnorm().Plot CDF standard normal:inverse \\(\\Phi^{-1}(p)\\) called quantile function standard normal.\nR function called qnorm().sum two normal random variables also normal (appropriate mean variance).central limit theorem (first postulated Abraham de Moivre (1667–1754)) asserts\nmany cases distribution mean identically distributed independent random variables converges normal distribution, even individual random variables normal.","code":""},{"path":"refresher.html","id":"gamma-distribution","chapter":"A Refresher","heading":"A.6.3 Gamma distribution","text":"","code":""},{"path":"refresher.html","id":"standard-parameterisation","chapter":"A Refresher","heading":"A.6.3.1 Standard parameterisation","text":"Another important continous distribution gamma distribution\n\\(\\text{Gam}(\\alpha, \\theta)\\).\ntwo parameters \\(\\alpha>0\\) (shape) \\(\\theta>0\\) (scale):\n\\[\nx \\sim\\text{Gam}(\\alpha, \\theta)\n\\]\nmean\n\\[\\text{E}(x)=\\alpha \\theta\\]\nvariance\n\\[\\text{Var}(x) = \\alpha \\theta^2\\]gamma distribution also often used rate\nparameter \\(\\beta=1/\\theta\\) (one needs pay attention parameterisation used).Probability density function (PDF):\n\\[\np(x| \\alpha, \\theta)=\\frac{1}{\\Gamma(\\alpha) \\theta^{\\alpha} } x^{\\alpha-1} e^{-x/\\theta}\n\\]\ndensity gamma distribution available R function dgamma(). cumulative density function pgamma() quantile function qgamma().","code":""},{"path":"refresher.html","id":"wishart-parameterisation-and-scaled-chi-squared-distribution","chapter":"A Refresher","heading":"A.6.3.2 Wishart parameterisation and scaled chi-squared distribution","text":"gamma distribution often used different set parameters\n\\(k=2 \\alpha\\) \\(s^2 =\\theta/2\\) (hence conversely \\(\\alpha = k/2\\) \\(\\theta=2 s^2\\)).\nform known one-dimensional Wishart distribution\n\\[\nW_1\\left(s^2, k \\right)\n\\]\nnamed John Wishart (1898–1954).\nWishart parameterisation mean \n\\[\n\\text{E}(x) = k s^2\n\\]\nvariance\n\\[\n\\text{Var}(x) = 2 k s^4\n\\]Another name one-dimensional Wishart distribution exactly \nparameterisation scaled chi-squared distribution denoted \n\\[\ns^2 \\text{$\\chi^2_{k}$}\n\\]Finally, note often employ Wishart distribution mean parameterisation\n\\(W_1\\left(s^2= \\mu / k, k \\right)\\)\n\\(\\mu = k s^2\\) \\(k\\) (thus \\(\\theta = 2 \\mu /k\\)). \nmean\n\\[\n\\text{E}(x) = \\mu\n\\]\nvariance\n\\[\n\\text{Var}(x) = \\frac{2 \\mu^2}{k}\n\\]","code":""},{"path":"refresher.html","id":"construction-as-sum-of-squared-normals","chapter":"A Refresher","heading":"A.6.3.3 Construction as sum of squared normals","text":"gamma distributed variable can constructed follows.\nAssume \\(k\\) independent normal random variables mean 0\nvariance \\(s^2\\):\n\\[z_1,z_2,\\dots,z_k\\sim N(0,s^2)\\]\nsum squares\n\\[\nx = \\sum_{=1}^{k} z_i^2\n\\]\nfollows\n\\[\nx \\sim \\sigma^2 \\text{$\\chi^2_{k}$} =  W_1\\left( s^2, k \\right)\n\\]\nequivalently\n\\[\nx \\sim \\text{Gam}\\left(\\alpha=\\frac{k}{2}, \\theta = 2 s^2\\right)\n\\]","code":""},{"path":"refresher.html","id":"special-cases-of-the-gamma-distribution","chapter":"A Refresher","heading":"A.6.4 Special cases of the gamma distribution","text":"","code":""},{"path":"refresher.html","id":"chi-squared-distribution","chapter":"A Refresher","heading":"A.6.4.1 Chi-squared distribution","text":"chi-squared distribution\n\\(\\text{$\\chi^2_{k}$}\\) special one-parameter restriction \ngamma resp. Wishart distribution obtained setting\n\\(s^2=1\\) , equivalently, \\(\\theta = 2\\) \\(\\mu = k\\).mean \\(\\text{E}(x)=k\\) variance \\(\\text{Var}(x)=2k\\). chi-squared distribution \\(\\text{$\\chi^2_{k}$}\\) equals \\(\\text{Gam}(\\alpha=k/2, \\theta=2) = W_1\\left(1, k \\right)\\).plot density chi-squared distribution\ndegrees freedom \\(k=1\\) \\(k=3\\):R density chi-squared distribution given dchisq(). cumulative density function pchisq() \nquantile function qchisq().","code":""},{"path":"refresher.html","id":"exponential-distribution","chapter":"A Refresher","heading":"A.6.4.2 Exponential distribution","text":"exponential distribution \\(\\text{Exp}(\\theta)\\) scale parameter \\(\\theta\\)\nanother special one-parameter restriction gamma distribution shape parameter set \n\\(\\alpha=1\\) (equivalently \\(k=2\\)).thus equals\n\\(\\text{Gam}(\\alpha=1, \\theta) = W_1(s^2=\\theta/2, k=2)\\). mean \\(\\theta\\) variance \\(\\theta^2\\).Just like gamma distribution exponential distribution also often specified using rate parameter \\(\\beta= 1/\\theta\\) instead scale parameter \\(\\theta\\).R command dexp() returns \ndensity exponential distribution,\npexp() corresponding cumulative density function qexp() quantile function.","code":""},{"path":"refresher.html","id":"location-scale-t-distribution-students-t-distribution-and-cauchy-distribution","chapter":"A Refresher","heading":"A.6.5 Location-scale \\(t\\)-distribution, Student’s \\(t\\)-distribution and Cauchy distribution","text":"","code":""},{"path":"refresher.html","id":"location-scale-t-distribution","chapter":"A Refresher","heading":"A.6.5.1 Location-scale \\(t\\)-distribution","text":"location-scale \\(t\\)-distribution \\(\\text{lst}(\\mu, \\tau^2, \\nu)\\) generalisation normal distribution.\nadditional parameter \\(\\nu > 0\\) (degrees freedom) controls probability mass tails. small values \\(\\nu\\) distribution heavy-tailed — indeed heavy \\(\\nu \\leq 1\\) even mean defined\n\\(\\nu \\leq 2\\) variance undefined.probability density \\(\\text{lst}(\\mu, \\tau^2, \\nu)\\) \n\\[\np(x | \\mu, \\tau^2, \\nu) = \\frac{\\Gamma(\\frac{\\nu+1}{2})} {\\sqrt{\\pi \\nu \\tau^2}  \\,\\Gamma(\\frac{\\nu}{2})} \\left(1+\\frac{(x-\\mu)^2}{\\nu \\tau^2} \\right)^{-(\\nu+1)/2}\n\\]\nmean (\\(\\nu>1\\))\n\\[\n\\text{E}(x) = \\mu\n\\]\nvariance (\\(\\nu>2\\))\n\\[\n\\text{Var}(x) = \\tau^2 \\frac{\\nu}{\\nu-2}\n\\]\\(\\nu \\rightarrow \\infty\\) location-scale \\(t\\)-distribution \\(\\text{lst}(\\mu, \\tau^2, \\nu)\\) becomes\nnormal distribution \\(N(\\mu, \\tau^2)\\).\\(\\nu=1\\) location-scale \\(t\\)-distribution becomes Cauchy distribution \\(\\text{Cau}(\\mu, \\tau)\\)\ndensity \\(p(x| \\mu, \\tau) = \\frac{\\tau}{\\pi (\\tau^2+(x-\\mu)^2)}\\).R extraDistr package command dlst() returns \ndensity location-scale \\(t\\)-distribution,\nplst() corresponding cumulative density function qlst() quantile function.","code":""},{"path":"refresher.html","id":"students-t-distribution","chapter":"A Refresher","heading":"A.6.5.2 Student’s \\(t\\)-distribution","text":"\\(\\mu=0\\) \\(\\tau^2=1\\) location-scale \\(t\\)-distribution becomes \nStudent’s \\(t\\)-distribution \\(t_\\nu\\)\nmean 0 (\\(\\nu>1\\)) variance \\(\\frac{\\nu}{\\nu-2}\\) (\\(\\nu>2\\)).\\(y \\sim t_\\nu\\) \\(x = \\mu + \\tau y\\) distributed \\(x \\sim \\text{lst}(\\mu, \\tau^2, \\nu)\\).\\(\\nu \\rightarrow \\infty\\) \\(t\\)-distribution becomes equal \\(N(0,1)\\).\\(\\nu=1\\) \\(t\\)-distribution becomes standard Cauchy distribution\n\\(\\text{Cau}(0, 1)\\) density \\(p(x) = \\frac{1}{\\pi (1+x^2)}\\).R command dt() returns \ndensity \\(t\\)-distribution,\npt() corresponding cumulative density function qt() quantile function.","code":""},{"path":"refresher.html","id":"statistics","chapter":"A Refresher","heading":"A.7 Statistics","text":"","code":""},{"path":"refresher.html","id":"statistical-learning","chapter":"A Refresher","heading":"A.7.1 Statistical learning","text":"aim statistics — data science — machine learning use data\n(experiments, observations, measurements) learn understand world.Specifically, aim identify best model(s) data order toto explain current data, andto enable good prediction future dataNote easy find models explain data predict well!Typically, one like avoid overfitting data prefers models \nappropriate data hand (.e. simple also complex).Specifically, data denoted \\(D =\\{x_1, \\ldots, x_n\\}\\) models \\(p(x| \\theta)\\) indexed parameter \\(\\theta\\).Often (always) \\(\\theta\\) can interpreted /associated property model.single parameter write \\(\\theta\\) (scalar parameter). parameter vector write \\(\\boldsymbol \\theta\\) (bold type).","code":""},{"path":"refresher.html","id":"point-and-interval-estimation","chapter":"A Refresher","heading":"A.7.2 Point and interval estimation","text":"parameter \\(\\theta\\) interest modelwe uncertain parameter (.e. don’t know exact value)like learn parameter observing data \\(x_1, \\ldots, x_n\\) modelOften parameter(s) interest related moments (mean variance) \nquantiles distribution representing model.Estimation:estimator \\(\\theta\\) function \\(\\hat{\\theta}(x_1, \\ldots, x_n)\\) maps data (input) “guess” (output) \\(\\theta\\).point estimator provides single number parameterAn interval estimator provides set possible values parameter.Simple estimators mean variance:Suppose data \\(D = \\{x_1, \\ldots, x_n\\}\\) sampled independently distribution \\(F\\).average (also known empirical mean) \\(\\hat{\\mu} = \\frac{1}{n} \\sum_{=1}^n x_i\\) estimate mean \\(F\\).empirical variance \\(\\widehat{\\sigma^2}_{\\text{ML}} = \\frac{1}{n} \\sum_{=1}^n (x_i -\\hat{\\mu})^2\\) estimate variance \\(F\\). Note factor \\(1/n\\). maximum likelihood estimate assuming normal model.unbiased sample variance \\(\\widehat{\\sigma^2}_{\\text{UB}} = \\frac{1}{n-1} \\sum_{=1}^n (x_i -\\hat{\\mu})^2\\) another estimate variance \\(F\\). Note factor \\(1/(n-1)\\) therefore \\(n\\geq 2\\) required estimator.","code":""},{"path":"refresher.html","id":"sampling-properties-of-a-point-estimator-hatboldsymbol-theta","chapter":"A Refresher","heading":"A.7.3 Sampling properties of a point estimator \\(\\hat{\\boldsymbol \\theta}\\)","text":"point estimator \\(\\hat\\theta\\) depends data, hence sampling variation (.e. estimate different new set observations)Thus \\(\\hat\\theta\\) can seen random variable, distribution called sampling distribution (across different experiments).Properties distribution can used evaluate far estimator\ndeviates (average across different experiments) true value:\\[\\begin{align*}\n\\begin{array}{rr}\n\\text{Bias:}\\\\\n\\text{Variance:}\\\\\n\\text{Mean squared error:}\\\\\n\\\\\n\\end{array}\n\\begin{array}{rr}\n\\text{Bias}(\\hat{\\theta})\\\\\n\\text{Var}(\\hat{\\theta})\\\\\n\\text{MSE}(\\hat{\\theta})\\\\\n\\\\\n\\end{array}\n\\begin{array}{ll}\n=\\text{E}(\\hat{\\theta})-\\theta\\\\\n=\\text{E}\\left((\\hat{\\theta}-\\text{E}(\\hat{\\theta}))^2\\right)\\\\\n=\\text{E}((\\hat{\\theta}-\\theta)^2)\\\\\n=\\text{Var}(\\hat{\\theta})+\\text{Bias}(\\hat{\\theta})^2\\\\\n\\end{array}\n\\end{align*}\\]last identity MSE follows \\(\\text{E}(x^2)=\\text{Var}(x)+\\text{E}(x)^2\\).first sight seems desirable focus unbiased (finite \\(n\\)) estimators.\nHowever, requiring strict unbiasedness always good idea!many situations better allow small bias order achieve smaller variance overall total smaller MSE. called bias-variance tradeoff — bias\ntraded smaller variance (, conversely, less bias traded higher variance)","code":""},{"path":"refresher.html","id":"consistency","chapter":"A Refresher","heading":"A.7.4 Consistency","text":"Typically, \\(\\text{Bias}\\), \\(\\text{Var}\\) \\(\\text{MSE}\\) decrease increasing sample size\ndata \\(n \\\\infty\\) errors become smaller smaller.typical rate decrease variance good estimator \\(\\frac{1}{n}\\).\nThus, sample size doubled variance divided 2\n(standard deviation divided \\(\\sqrt{2}\\)).Consistency: \\(\\hat{\\theta}\\) called consistent \n\\[\n\\text{MSE}(\\hat{\\theta}) \\longrightarrow 0 \\text{ $n\\rightarrow \\infty$ }\n\\]\nthree estimators discussed (empirical mean, empirical variance, unbiased variance) consistent MSE goes zero large sample size \\(n\\).Consistency minimum essential requirement reasonable estimator! consistent\nestimators typically prefer estimator efficient (.e. fasted decrease MSE) therefore smallest variance /MSE given finite \\(n\\).Consistency implies recover true model limit infinite data model class contains true data generating model.model class contain true model strict consistency\nachived still wish get close possible\ntrue model choosing model parameters.","code":""},{"path":"refresher.html","id":"sampling-distribution-of-mean-and-variance-estimators-for-normal-data","chapter":"A Refresher","heading":"A.7.5 Sampling distribution of mean and variance estimators for normal data","text":"Suppose data \\(x_1, \\ldots, x_n\\) sampled normal distribution \\(N(\\mu, \\sigma^2)\\).empirical estimator mean parameter \\(\\mu\\) given \\(\\hat{\\mu} = \\frac{1}{n} \\sum_{=1}^n x_i\\). normal assumption distribution \\(\\hat{\\mu}\\) \n\\[\n\\hat{\\mu} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\n\\]\nThus \\(\\text{E}(\\hat{\\mu}) = \\mu\\) \\(\\text{Var}(\\hat{\\mu}) = \\frac{\\sigma^2}{n}\\).\nestimate \\(\\hat{\\mu}\\) unbiased since \\(\\text{E}(\\hat{\\mu})-\\mu = 0\\) mean\nsquared error \\(\\hat{\\mu}\\) \\(\\text{MSE}(\\hat{\\mu}) = \\frac{\\sigma^2}{n}\\).empirical estimator mean parameter \\(\\mu\\) given \\(\\hat{\\mu} = \\frac{1}{n} \\sum_{=1}^n x_i\\). normal assumption distribution \\(\\hat{\\mu}\\) \n\\[\n\\hat{\\mu} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\n\\]\nThus \\(\\text{E}(\\hat{\\mu}) = \\mu\\) \\(\\text{Var}(\\hat{\\mu}) = \\frac{\\sigma^2}{n}\\).\nestimate \\(\\hat{\\mu}\\) unbiased since \\(\\text{E}(\\hat{\\mu})-\\mu = 0\\) mean\nsquared error \\(\\hat{\\mu}\\) \\(\\text{MSE}(\\hat{\\mu}) = \\frac{\\sigma^2}{n}\\).empirical variance \\(\\widehat{\\sigma^2}_{\\text{ML}} = \\frac{1}{n} \\sum_{=1}^n (x_i -\\hat{\\mu})^2\\) normal data follows one-dimensional Wishart distribution\n\\[\n\\widehat{\\sigma^2}_{\\text{ML}} \\sim\nW_1\\left(s^2 = \\frac{\\sigma^2}{n}, k=n-1\\right)\n\\]\nThus, \\(\\text{E}( \\widehat{\\sigma^2}_{\\text{ML}} ) = \\frac{n-1}{n}\\sigma^2\\) \n\\(\\text{Var}( \\widehat{\\sigma^2}_{\\text{ML}} ) = \\frac{2(n-1)}{n^2}\\sigma^4\\).\nestimate \\(\\widehat{\\sigma^2}_{\\text{ML}}\\) biased since\n\\(\\text{E}( \\widehat{\\sigma^2}_{\\text{ML}} )-\\sigma^2 = -\\frac{1}{n}\\sigma^2\\).\nmean squared error \\(\\text{MSE}( \\widehat{\\sigma^2}_{\\text{ML}} ) = \\frac{2(n-1)}{n^2}\\sigma^4 +\\frac{1}{n^2}\\sigma^4 =\\frac{2 n-1}{n^2}\\sigma^4\\).empirical variance \\(\\widehat{\\sigma^2}_{\\text{ML}} = \\frac{1}{n} \\sum_{=1}^n (x_i -\\hat{\\mu})^2\\) normal data follows one-dimensional Wishart distribution\n\\[\n\\widehat{\\sigma^2}_{\\text{ML}} \\sim\nW_1\\left(s^2 = \\frac{\\sigma^2}{n}, k=n-1\\right)\n\\]\nThus, \\(\\text{E}( \\widehat{\\sigma^2}_{\\text{ML}} ) = \\frac{n-1}{n}\\sigma^2\\) \n\\(\\text{Var}( \\widehat{\\sigma^2}_{\\text{ML}} ) = \\frac{2(n-1)}{n^2}\\sigma^4\\).\nestimate \\(\\widehat{\\sigma^2}_{\\text{ML}}\\) biased since\n\\(\\text{E}( \\widehat{\\sigma^2}_{\\text{ML}} )-\\sigma^2 = -\\frac{1}{n}\\sigma^2\\).\nmean squared error \\(\\text{MSE}( \\widehat{\\sigma^2}_{\\text{ML}} ) = \\frac{2(n-1)}{n^2}\\sigma^4 +\\frac{1}{n^2}\\sigma^4 =\\frac{2 n-1}{n^2}\\sigma^4\\).unbiased variance estimate \\(\\widehat{\\sigma^2}_{\\text{UB}} = \\frac{1}{n-1} \\sum_{=1}^n (x_i -\\hat{\\mu})^2\\) normal data follows one-dimensional Wishart distribution\n\\[\n\\widehat{\\sigma^2}_{\\text{UB}} \\sim\nW_1\\left(s^2 = \\frac{\\sigma^2}{n-1}, k = n-1 \\right)\n\\]\nThus, \\(\\text{E}( \\widehat{\\sigma^2}_{\\text{UB}} ) = \\sigma^2\\) \n\\(\\text{Var}( \\widehat{\\sigma^2}_{\\text{UB}} ) = \\frac{2}{n-1}\\sigma^4\\).\nestimate \\(\\widehat{\\sigma^2}_{\\text{ML}}\\) unbiased since\n\\(\\text{E}( \\widehat{\\sigma^2}_{\\text{UB}} )-\\sigma^2 =0\\).\nmean squared error \\(\\text{MSE}( \\widehat{\\sigma^2}_{\\text{UB}} ) =\\frac{2}{n-1}\\sigma^4\\).\nInterestingly, \\(n>1\\) find \\(\\text{Var}( \\widehat{\\sigma^2}_{\\text{UB}} ) > \\text{Var}( \\widehat{\\sigma^2}_{\\text{ML}} )\\) \\(\\text{MSE}( \\widehat{\\sigma^2}_{\\text{UB}} ) > \\text{MSE}( \\widehat{\\sigma^2}_{\\text{ML}} )\\) biased empirical estimator lower variance lower mean squared error unbiased estimator.unbiased variance estimate \\(\\widehat{\\sigma^2}_{\\text{UB}} = \\frac{1}{n-1} \\sum_{=1}^n (x_i -\\hat{\\mu})^2\\) normal data follows one-dimensional Wishart distribution\n\\[\n\\widehat{\\sigma^2}_{\\text{UB}} \\sim\nW_1\\left(s^2 = \\frac{\\sigma^2}{n-1}, k = n-1 \\right)\n\\]\nThus, \\(\\text{E}( \\widehat{\\sigma^2}_{\\text{UB}} ) = \\sigma^2\\) \n\\(\\text{Var}( \\widehat{\\sigma^2}_{\\text{UB}} ) = \\frac{2}{n-1}\\sigma^4\\).\nestimate \\(\\widehat{\\sigma^2}_{\\text{ML}}\\) unbiased since\n\\(\\text{E}( \\widehat{\\sigma^2}_{\\text{UB}} )-\\sigma^2 =0\\).\nmean squared error \\(\\text{MSE}( \\widehat{\\sigma^2}_{\\text{UB}} ) =\\frac{2}{n-1}\\sigma^4\\).Interestingly, \\(n>1\\) find \\(\\text{Var}( \\widehat{\\sigma^2}_{\\text{UB}} ) > \\text{Var}( \\widehat{\\sigma^2}_{\\text{ML}} )\\) \\(\\text{MSE}( \\widehat{\\sigma^2}_{\\text{UB}} ) > \\text{MSE}( \\widehat{\\sigma^2}_{\\text{ML}} )\\) biased empirical estimator lower variance lower mean squared error unbiased estimator.","code":""},{"path":"refresher.html","id":"one-sample-t-statistic","chapter":"A Refresher","heading":"A.7.6 One sample \\(t\\)-statistic","text":"Supppose observe \\(n\\) independent data points \\(x_1, \\ldots, x_n \\sim N(\\mu, \\sigma^2)\\).\naverage \\(\\bar{x} = \\sum_{=1}^n x_i\\) distributed \n\\(\\bar{x} \\sim N(\\mu, \\sigma^2/n)\\) correspondingly\n\\[\nz = \\frac{\\bar{x}-\\mu}{\\sqrt{\\sigma^2/n}} \\sim N(0, 1)\n\\]Note \\(z\\) uses known variance \\(\\sigma^2\\). instead variance estimated\n\\(s^2_{\\text{UB}} = \\frac{1}{n-1} \\sum_{=1}^n (x_i -\\bar{x})^2\\)\none sample \\(t\\)-statistic\n\\[\nt = \\frac{\\bar{x}-\\mu}{\\sqrt{s^2_{\\text{UB}}/n}} \\sim t_{n-1}\n\\]\nobtained. distributed according Student’s \\(t\\)-distribution\n\\(n-1\\) degrees freedom, mean 0 \\(n>2\\) variance\n\\((n-1)/(n-3)\\) \\(n>3\\).instead unbiased estimate empirical (ML) estimate variance \\(s^2_{\\text{ML}} = \\frac{1}{n} \\sum_{=1}^n (x_i -\\bar{x})^2 = \\frac{n-1}{n} s^2_{\\text{UB}}\\) used leads slightly different statistic\n\\[\nt_{\\text{ML}} = \\frac{\\bar{x}-\\mu}{ \\sqrt{ s^2_{\\text{ML}}/n}}  = \\sqrt{\\frac{n}{n-1}} t\n\\]\n\n\\[\nt_{\\text{ML}} \\sim \\text{lst}\\left(0, \\tau^2=\\frac{n}{n-1}, n-1\\right)\n\\]\nThus, \\(t_{\\text{ML}}\\) follows location-scale \\(t\\)-distribution, mean 0 \\(n>2\\) variance\n\\(n/(n-3)\\) \\(n>3\\).","code":""},{"path":"refresher.html","id":"two-sample-t-statistic-with-common-variance","chapter":"A Refresher","heading":"A.7.7 Two sample \\(t\\)-statistic with common variance","text":"Now suppose observe normal data \\(D = \\{x_1, \\ldots, x_n\\}\\) two groups\nsample size \\(n_1\\) \\(n_2\\) (\\(n=n_1+n_2\\)) two different means \\(\\mu_1\\) \\(\\mu_2\\) common variance \\(\\sigma^2\\):\n\\[x_1,\\dots,x_{n_1} \\sim N(\\mu_1, \\sigma^2)\\]\n\n\\[x_{n_1+1},\\dots,x_{n} \\sim N(\\mu_2, \\sigma^2)\\]\n\\(\\hat{\\mu}_1 = \\frac{1}{n_1}\\sum^{n_1}_{=1}x_i\\) \n\\(\\hat{\\mu}_2 = \\frac{1}{n_2}\\sum^{n}_{=n_1+1}x_i\\) sample averages group.common variance \\(\\sigma^2\\) may estimated either \nunbiased estimate \\(s^2_{\\text{UB}} = \\frac{1}{n-2} \\left(\\sum^{n_1}_{=1}(x_i-\\hat{\\mu}_1)^2+\\sum^n_{=n_1+1}(x_i-\\hat{\\mu}_2)^2\\right)\\)\n(note factor \\(n-2\\)) empirical (ML) estimate \\(s^2_{\\text{ML}} = \\frac{1}{n} \\left(\\sum^{n_1}_{=1}(x_i-\\hat{\\mu}_1)^2+\\sum^n_{=n_1+1}(x_i-\\hat{\\mu}_2)^2\\right) =\\frac{n-2}{n} s^2_{\\text{UB}}\\). two estimators\ncommon variance often referred pooled variance estimate information pooled two groups obtain estimate.gives rise two sample \\(t\\)-statistic\n\\[\nt = \\frac{\\hat{\\mu}_1-\\hat{\\mu}_2}{ \\sqrt{ s^2_{\\text{UB}} \\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)}   } \\sim t_{n-2}\n\\]\ndistributed according Student’s \\(t\\)-distribution \\(n-2\\) degrees freedom, mean 0 \\(n>3\\) variance \\((n-2)/(n-4)\\) \\(n>4\\).\nLarge values two sample \\(t\\)-statistic indicates indeed two groups\nrather just one.two sample \\(t\\)-statistic using empirical (ML) estimate common variance \n\\[\nt_{\\text{ML}} = \\frac{\\hat{\\mu}_1-\\hat{\\mu}_2}{ \\sqrt{ s^2_{\\text{ML}} \\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)}   } = \\sqrt{\\frac{n}{n-2}} t\n\\]\n\n\\[\nt_{\\text{ML}} \\sim \\text{lst}\\left(0, \\tau^2=\\frac{n}{n-2}, n-2\\right)\n\\]\nThus, \\(t_{\\text{ML}}\\) follows location-scale \\(t\\)-distribution, mean 0 \\(n>3\\) variance\n\\(n/(n-4)\\) \\(n>4\\).","code":""},{"path":"refresher.html","id":"confidence-intervals","chapter":"A Refresher","heading":"A.7.8 Confidence intervals","text":"confidence interval (CI) interval estimate frequentist interpretation.Definition coverage \\(\\kappa\\) CI: often (repeated identical experiment) estimated CI overlap true parameter value \\(\\theta\\)\nEg.: Coverage \\(\\kappa=0.95\\) (95%) means 95 100 case estimated CI contain (unknown) true value (.e. “cover” \\(\\theta\\)).\nEg.: Coverage \\(\\kappa=0.95\\) (95%) means 95 100 case estimated CI contain (unknown) true value (.e. “cover” \\(\\theta\\)).Illustration repeated construction CI \\(\\theta\\):Note CI actually estimate: \\(\\widehat{\\text{CI}}(x_1, \\ldots, x_n)\\), .e. depends data random (sampling) variation.good CI high coverage compact.Note: coverage probability probability true value contained given estimated interval (Bayesian credible interval).","code":""},{"path":"refresher.html","id":"symmetric-normal-confidence-interval","chapter":"A Refresher","heading":"A.7.9 Symmetric normal confidence interval","text":"normally distributed univariate random variable\nstraightforward construct symmetric two-sided CI given desired coverage \\(\\kappa\\).normal random variable \\(X \\sim N(\\mu, \\sigma^2)\\) mean \\(\\mu\\) variance \\(\\sigma^2\\) density function \\(f(x)\\) can compute probability\\[\\text{Pr}(x \\leq \\mu + c \\sigma) =  \\int_{-\\infty}^{\\mu+c\\sigma} f(x) dx  = \\Phi (c) = \\frac{1+\\kappa}{2}\\]\nNote \\(\\Phi(c)\\) cumulative distribution function (CDF) standard normal \\(N(0,1)\\):obtain critical point \\(c\\) quantile function, .e. inversion \\(\\Phi\\):\\[c=\\Phi^{-1}\\left(\\frac{1+\\kappa}{2}\\right)\\]following table lists \\(c\\) three commonly used values \\(\\kappa\\) - useful memorise values!symmetric standard normal CI nominal coverage \\(\\kappa\\) fora scalar parameter \\(\\theta\\)normally distributed estimate \\(\\hat{\\theta}\\) andwith estimated standard deviation \\(\\hat{\\text{SD}}(\\hat{\\theta}) = \\hat{\\sigma}\\)given \n\\[\n\\widehat{\\text{CI}}=[\\hat{\\theta} \\pm c \\hat{\\sigma}]\n\\]\n\\(c\\) chosen desired coverage level \\(\\kappa\\).","code":""},{"path":"refresher.html","id":"confidence-interval-based-on-the-chi-squared-distribution","chapter":"A Refresher","heading":"A.7.10 Confidence interval based on the chi-squared distribution","text":"normal CI can compute critical values \nchi-squared distribution use one-sided interval:\n\\[\n\\text{Pr}(x \\leq c) = \\kappa\n\\]\nget \\(c\\) quantile function, .e. inverting CDF chi-squared distribution.following list critical values three common choice \\(\\kappa\\)\n\\(m=1\\) (one degree freedom):one-sided CI nominal coverage \\(\\kappa\\) given \\([0, c ]\\).","code":""},{"path":"distributions-used-in-bayesian-analysis.html","id":"distributions-used-in-bayesian-analysis","chapter":"B Distributions used in Bayesian analysis","heading":"B Distributions used in Bayesian analysis","text":"appendix introduces number distributions\nessential Bayesian analysis.See particular Chapter “Bayesian learning practise”.","code":""},{"path":"distributions-used-in-bayesian-analysis.html","id":"beta-distribution","chapter":"B Distributions used in Bayesian analysis","heading":"B.1 Beta distribution","text":"","code":""},{"path":"distributions-used-in-bayesian-analysis.html","id":"standard-parameterisation-1","chapter":"B Distributions used in Bayesian analysis","heading":"B.1.1 Standard parameterisation","text":"density beta distribution \\(\\text{Beta}(\\alpha, \\beta)\\) \n\\[\np(x | \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}\n\\]\n\\(x \\[0,1]\\) \\(\\alpha>0\\) \\(\\beta>0\\).\ndensity depends beta function \\(B(z_1, z_1) = \\frac{ \\Gamma(z_1) \\Gamma(z_2)}{\\Gamma(z_1 + z_2)}\\)\nturn defined via Euler’s gamma function \\(\\Gamma(x)\\).\nNote \\(\\Gamma(x) = (x-1)!\\) positive integer \\(x\\).mean beta distribution \n\\[\n\\text{E}(x) = \\frac{\\alpha}{\\alpha+\\beta}\n\\]\nvariance \n\\[\n\\text{Var}(x)=\\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\n\\]beta distribution flexible can assume number different shapes, depending value \\(\\alpha\\) \\(\\beta\\):","code":""},{"path":"distributions-used-in-bayesian-analysis.html","id":"mean-parameterisation","chapter":"B Distributions used in Bayesian analysis","heading":"B.1.2 Mean parameterisation","text":"useful reparameterisation \\(\\text{Beta}(\\mu, k)\\) beta distribution terms mean parameter\n\\(\\mu \\[0,1]\\) concentration parameter \\(k > 0\\). given \n\\[\nk=\\alpha+\\beta\n\\]\n\n\\[\\mu = \\frac{\\alpha}{\\alpha+\\beta}\n\\]\noriginal parameters can recovered \n\\[\\alpha= \\mu k\\] \\[\\beta=(1-\\mu) k\\]mean variance beta distribution expressed terms \\(\\mu\\) \\(k\\) \n\\[\n\\text{E}(x) = \\mu\n\\]\n\n\\[\n\\text{Var}(x)=\\frac{\\mu (1-\\mu)}{k+1}\n\\]\nincreasing concentration parameter \\(k\\) variance decreases thus probability mass becomes concentrated around mean.","code":""},{"path":"distributions-used-in-bayesian-analysis.html","id":"inverse-gamma-inverse-wishart-distribution","chapter":"B Distributions used in Bayesian analysis","heading":"B.2 Inverse gamma (inverse Wishart) distribution","text":"","code":""},{"path":"distributions-used-in-bayesian-analysis.html","id":"standard-parameterisation-2","chapter":"B Distributions used in Bayesian analysis","heading":"B.2.1 Standard parameterisation","text":"inverse gamma (IG) distribution \\(\\text{Inv-Gam}(\\alpha, \\beta)\\)\ndensity\n\\[\n\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} (1/x)^{\\alpha+1} e^{-\\beta/x}\n\\]\ntwo parameters \\(\\alpha >0\\) (shape parameter) \\(\\beta >0\\) (scale parameter) support \\(x >0\\).mean inverse gamma distribution \n\\[\\text{E}(x) = \\frac{\\beta}{\\alpha-1}\\]\nvariance\n\\[\\text{Var}(x) = \\frac{\\beta^2}{(\\alpha-1)^2 (\\alpha-2)}\\]Thus, mean exist restriction\n\\(\\alpha>1\\) variance exist \\(\\alpha>2\\).IG distribution closely linked gamma distribution.\n\\(x \\sim \\text{Inv-Gam}(\\alpha, \\beta)\\) IG-distributed inverse \\(x\\) gamma distributed:\n\\[\\frac{1}{x} \\sim \\text{Gam}(\\alpha, \\theta=\\beta^{-1})\\]\n\\(\\alpha\\) shared shape parameter \\(\\theta\\) scale parameter gamma distribution.","code":""},{"path":"distributions-used-in-bayesian-analysis.html","id":"wishart-parameterisation","chapter":"B Distributions used in Bayesian analysis","heading":"B.2.2 Wishart parameterisation","text":"inverse gamma distribution frequently used different\nset parameters\n\\(\\psi = 2\\beta\\) (scale parameter) \\(\\nu = 2\\alpha\\) (shape parameter), \nconversely \\(\\alpha=\\nu/2\\) \\(\\beta=\\psi/2\\).\nform called one-dimensional inverse Wishart distribution\n\\(W^{-1}_1(\\psi, \\nu)\\) mean variance given \n\\[\n\\text{E}(x) = \\frac{\\psi}{\\nu-2} = \\mu\n\\]\n\\(\\nu>2\\) \n\\[\n\\text{Var}(x) =\\frac{2 \\psi^2}{(\\nu-4) (\\nu-2)^2}  = \\frac{2 \\mu^2}{\\nu-4}\n\\]\n\\(\\nu >4\\).Instead \\(\\psi\\) \\(\\nu\\) may also equivalently use \\(\\mu\\) \\(\\kappa=\\nu-2\\) parameters inverse\nWishart distribution, \\(W^{-1}_1(\\psi=\\kappa \\mu, \\nu=\\kappa+2)\\)\nmean\n\\[\\text{E}(x) = \\mu\\]\n\\(\\kappa>0\\) variance \n\\[\\text{Var}(x) = \\frac{2 \\mu^2}{\\kappa-2}\\] \n\\(\\kappa>2\\).\nmean parameterisation useful employing IG distribution\nprior posterior.Finally, \\(W^{-1}_1(\\psi=\\nu \\tau^2, \\nu)\\), \n\\(\\tau^2 = \\mu \\frac{ \\kappa}{\\kappa+2} = \\frac{\\psi}{\\nu}\\) \nbiased mean parameter, get\nscaled inverse chi-squared distribution \\(\\tau^2 \\text{Inv-$\\chi^2_{\\nu}$}\\)\n\n\\[\n\\text{E}(x) = \\tau^2 \\frac{ \\nu}{\\nu-2}\n\\]\n\\(\\nu>2\\) \n\\[\n\\text{Var}(x) =\\frac{2 \\tau^4}{\\nu-4} \\frac{\\nu^2}{(\\nu-2)^2}\n\\]\n\\(\\nu >4\\).inverse Wishart Wishart distributions linked.\n\\(x \\sim W^{-1}_1(\\psi, \\nu)\\) inverse-Wishart distributed inverse \\(x\\) Wishart distributed inverted scale parameter:\n\\[\\frac{1}{x} \\sim W_1(s^2=\\psi^{-1}, k=\\nu)\\]\n\\(k\\) shape parameter \\(s^2\\) scale parameter Wishart distribution.","code":""},{"path":"distributions-used-in-bayesian-analysis.html","id":"location-scale-t-distribution-as-compound-distribution","chapter":"B Distributions used in Bayesian analysis","heading":"B.3 Location-scale \\(t\\)-distribution as compound distribution","text":"Suppose \n\\[\nx | s^2 \\sim N(\\mu,s^2)\n\\] corresponding density \\(p(x | s^2)\\)\nmean \\(\\text{E}(x | s^2) = \\mu\\) variance \\(\\text{Var}(x|s^2) = s^2\\).Now let variance \\(s^2\\) distributed inverse gamma / inverse Wishart\n\\[\ns^2 \\sim  W^{-1}(\\psi=\\kappa \\sigma^2, \\nu=\\kappa+2) = W^{-1}(\\psi=\\tau^2\\nu, \\nu)\n\\]\ncorresponding density \\(p(s^2)\\) mean \\(\\text{E}(s^2) = \\sigma^2 = \\tau^2 \\nu/(\\nu-2)\\).\nNote use mean parameterisation (\\(\\sigma^2, \\kappa\\))\ninverse chi-squared parameterisation (\\(\\tau^2, \\nu\\)).joint density \\(x\\) \\(s^2\\) \\(p(x, s^2) = p(x | s^2) p(s^2)\\).\ninterested marginal density \\(x\\):\n\\[\np(x) = \\int p(x, s^2) ds^2  = \\int p(s^2)  p(x | s^2) ds^2\n\\]\ncompound distribution normal fixed mean \\(\\mu\\)\nvariance \\(s^2\\) varying according inverse gamma distribution.\nCalculating integral results \nlocation-scale \\(t\\)-distribution parameters\n\\[\nx \\sim  \\text{lst}\\left(\\mu, \\sigma^2 \\frac{\\kappa}{\\kappa+2}, \\kappa+2\\right) = \\text{lst}\\left(\\mu, \\tau^2, \\nu\\right)\n\\]\nmean\n\\[\n\\text{E}(x) = \\mu\n\\]\n\nvariance\n\\[\n\\text{Var}(x) = \\sigma^2 =\\tau^2 \\frac{\\nu}{\\nu-2}\n\\]law total expectation variance can also directly verify \n\\[\n\\text{E}(x) = \\text{E}( \\text{E}(x| s^2) ) =\\mu\n\\]\n\n\\[\n\\text{Var}(x) = \\text{E}(\\text{Var}(x|s^2))+ \\text{Var}(\\text{E}(x|s^2)) = \\text{E}(s^2) = \\sigma^2 =\\tau^2 \\frac{\\nu}{\\nu-2}\n\\]","code":""},{"path":"further-study.html","id":"further-study","chapter":"C Further study","heading":"C Further study","text":"module can touch surface likelihood Bayes inference.\nstarting point reading following text books recommended.","code":""},{"path":"further-study.html","id":"recommended-reading","chapter":"C Further study","heading":"C.1 Recommended reading","text":"Faraway (2015) Linear Models R (second edition). Chapman Hall/CRC.Faraway (2015) Linear Models R (second edition). Chapman Hall/CRC.Held Bové (2020) Applied Statistical Inference: Likelihood Bayes (2nd edition). Springer.Held Bové (2020) Applied Statistical Inference: Likelihood Bayes (2nd edition). Springer.Agresti Kateri (2022) Foundations Statistics Data Scientists. Chapman Hall/CRC.Agresti Kateri (2022) Foundations Statistics Data Scientists. Chapman Hall/CRC.","code":""},{"path":"further-study.html","id":"additional-references","chapter":"C Further study","heading":"C.2 Additional references","text":"Heard (2021) Introduction Bayesian Inference, Methods Computation. Springer.Heard (2021) Introduction Bayesian Inference, Methods Computation. Springer.Gelman et al. (2014) Bayesian data analysis (3rd edition). CRC Press.Gelman et al. (2014) Bayesian data analysis (3rd edition). CRC Press.Wood (2015) Core Statistics. Cambridge University Press. PDF available https://www.maths.ed.ac.uk/~swood34/core-statistics-nup.pdfWood (2015) Core Statistics. Cambridge University Press. PDF available https://www.maths.ed.ac.uk/~swood34/core-statistics-nup.pdf","code":""},{"path":"bibliography.html","id":"bibliography","chapter":"Bibliography","heading":"Bibliography","text":"","code":""}]
