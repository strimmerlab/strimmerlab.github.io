<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Statistical Methods: Likelihood, Bayes and Regression | HTML</title>
  <meta name="description" content="Statistical Methods:<br />
Likelihood, Bayes and Regression</div>" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Statistical Methods: Likelihood, Bayes and Regression | HTML" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistical Methods: Likelihood, Bayes and Regression | HTML" />
  
  
  



<meta name="date" content="2021-05-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="01-likelihood1.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://strimmerlab.org/publications/lecture-notes/MATH20802/index.html">MATH20802 Lecture Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-these-notes"><i class="fa fa-check"></i>About these notes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the author</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-module"><i class="fa fa-check"></i>About the module</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#topics-covered"><i class="fa fa-check"></i>Topics covered</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#additional-support-material"><i class="fa fa-check"></i>Additional support material</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="part"><span><b>I Likelihood estimation and inference</b></span></li>
<li class="chapter" data-level="1" data-path="01-likelihood1.html"><a href="01-likelihood1.html"><i class="fa fa-check"></i><b>1</b> Overview of statistical learning</a><ul>
<li class="chapter" data-level="1.1" data-path="01-likelihood1.html"><a href="01-likelihood1.html#how-to-learn-from-data"><i class="fa fa-check"></i><b>1.1</b> How to learn from data?</a></li>
<li class="chapter" data-level="1.2" data-path="01-likelihood1.html"><a href="01-likelihood1.html#probability-theory-versus-statistical-learning"><i class="fa fa-check"></i><b>1.2</b> Probability theory versus statistical learning</a></li>
<li class="chapter" data-level="1.3" data-path="01-likelihood1.html"><a href="01-likelihood1.html#cartoon-of-statistical-learning"><i class="fa fa-check"></i><b>1.3</b> Cartoon of statistical learning</a></li>
<li class="chapter" data-level="1.4" data-path="01-likelihood1.html"><a href="01-likelihood1.html#likelihood"><i class="fa fa-check"></i><b>1.4</b> Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="02-likelihood2.html"><a href="02-likelihood2.html"><i class="fa fa-check"></i><b>2</b> From entropy to maximum likelihood</a><ul>
<li class="chapter" data-level="2.1" data-path="02-likelihood2.html"><a href="02-likelihood2.html#entropy"><i class="fa fa-check"></i><b>2.1</b> Entropy</a><ul>
<li class="chapter" data-level="2.1.1" data-path="02-likelihood2.html"><a href="02-likelihood2.html#overview"><i class="fa fa-check"></i><b>2.1.1</b> Overview</a></li>
<li class="chapter" data-level="2.1.2" data-path="02-likelihood2.html"><a href="02-likelihood2.html#surprise-surprisal-or-shannon-information"><i class="fa fa-check"></i><b>2.1.2</b> Surprise, surprisal or Shannon information</a></li>
<li class="chapter" data-level="2.1.3" data-path="02-likelihood2.html"><a href="02-likelihood2.html#shannon-entropy"><i class="fa fa-check"></i><b>2.1.3</b> Shannon entropy</a></li>
<li class="chapter" data-level="2.1.4" data-path="02-likelihood2.html"><a href="02-likelihood2.html#differential-entropy"><i class="fa fa-check"></i><b>2.1.4</b> Differential entropy</a></li>
<li class="chapter" data-level="2.1.5" data-path="02-likelihood2.html"><a href="02-likelihood2.html#maximum-entropy-principle-to-characterise-distributions"><i class="fa fa-check"></i><b>2.1.5</b> Maximum entropy principle to characterise distributions</a></li>
<li class="chapter" data-level="2.1.6" data-path="02-likelihood2.html"><a href="02-likelihood2.html#cross-entropy"><i class="fa fa-check"></i><b>2.1.6</b> Cross-entropy</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="02-likelihood2.html"><a href="02-likelihood2.html#kullback-leibler-divergence"><i class="fa fa-check"></i><b>2.2</b> Kullback-Leibler divergence</a><ul>
<li class="chapter" data-level="2.2.1" data-path="02-likelihood2.html"><a href="02-likelihood2.html#definition"><i class="fa fa-check"></i><b>2.2.1</b> Definition</a></li>
<li class="chapter" data-level="2.2.2" data-path="02-likelihood2.html"><a href="02-likelihood2.html#properties-of-kl-divergence"><i class="fa fa-check"></i><b>2.2.2</b> Properties of KL divergence</a></li>
<li class="chapter" data-level="2.2.3" data-path="02-likelihood2.html"><a href="02-likelihood2.html#examples"><i class="fa fa-check"></i><b>2.2.3</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="02-likelihood2.html"><a href="02-likelihood2.html#local-quadratic-approximation-and-expected-fisher-information"><i class="fa fa-check"></i><b>2.3</b> Local quadratic approximation and expected Fisher information</a><ul>
<li class="chapter" data-level="2.3.1" data-path="02-likelihood2.html"><a href="02-likelihood2.html#definition-of-expected-fisher-information"><i class="fa fa-check"></i><b>2.3.1</b> Definition of expected Fisher information</a></li>
<li class="chapter" data-level="2.3.2" data-path="02-likelihood2.html"><a href="02-likelihood2.html#examples-1"><i class="fa fa-check"></i><b>2.3.2</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="02-likelihood2.html"><a href="02-likelihood2.html#entropy-learning-and-maximum-likelihood"><i class="fa fa-check"></i><b>2.4</b> Entropy learning and maximum likelihood</a><ul>
<li class="chapter" data-level="2.4.1" data-path="02-likelihood2.html"><a href="02-likelihood2.html#the-relative-entropy-between-true-model-and-approximating-model"><i class="fa fa-check"></i><b>2.4.1</b> The relative entropy between true model and approximating model</a></li>
<li class="chapter" data-level="2.4.2" data-path="02-likelihood2.html"><a href="02-likelihood2.html#minimum-kl-divergence-and-maximum-likelihood"><i class="fa fa-check"></i><b>2.4.2</b> Minimum KL divergence and maximum likelihood</a></li>
<li class="chapter" data-level="2.4.3" data-path="02-likelihood2.html"><a href="02-likelihood2.html#further-connections"><i class="fa fa-check"></i><b>2.4.3</b> Further connections</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="03-likelihood3.html"><a href="03-likelihood3.html"><i class="fa fa-check"></i><b>3</b> Maximum likelihood estimation</a><ul>
<li class="chapter" data-level="3.1" data-path="03-likelihood3.html"><a href="03-likelihood3.html#principle-of-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>3.1</b> Principle of maximum likelihood estimation</a><ul>
<li class="chapter" data-level="3.1.1" data-path="03-likelihood3.html"><a href="03-likelihood3.html#outline"><i class="fa fa-check"></i><b>3.1.1</b> Outline</a></li>
<li class="chapter" data-level="3.1.2" data-path="03-likelihood3.html"><a href="03-likelihood3.html#obtaining-mles-for-a-regular-model"><i class="fa fa-check"></i><b>3.1.2</b> Obtaining MLEs for a regular model</a></li>
<li class="chapter" data-level="3.1.3" data-path="03-likelihood3.html"><a href="03-likelihood3.html#invariance-property-of-the-maximum-likelihood"><i class="fa fa-check"></i><b>3.1.3</b> Invariance property of the maximum likelihood</a></li>
<li class="chapter" data-level="3.1.4" data-path="03-likelihood3.html"><a href="03-likelihood3.html#consistency-of-maximum-likelihood-estimates"><i class="fa fa-check"></i><b>3.1.4</b> Consistency of maximum likelihood estimates</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="03-likelihood3.html"><a href="03-likelihood3.html#maximum-likelihood-estimation-in-practise"><i class="fa fa-check"></i><b>3.2</b> Maximum likelihood estimation in practise</a><ul>
<li class="chapter" data-level="3.2.1" data-path="03-likelihood3.html"><a href="03-likelihood3.html#worked-examples"><i class="fa fa-check"></i><b>3.2.1</b> Worked examples</a></li>
<li class="chapter" data-level="3.2.2" data-path="03-likelihood3.html"><a href="03-likelihood3.html#relationship-with-least-squares-estimation"><i class="fa fa-check"></i><b>3.2.2</b> Relationship with least squares estimation</a></li>
<li class="chapter" data-level="3.2.3" data-path="03-likelihood3.html"><a href="03-likelihood3.html#bias-and-maximum-likelihood"><i class="fa fa-check"></i><b>3.2.3</b> Bias and maximum likelihood</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="03-likelihood3.html"><a href="03-likelihood3.html#observed-fisher-information"><i class="fa fa-check"></i><b>3.3</b> Observed Fisher information</a><ul>
<li class="chapter" data-level="3.3.1" data-path="03-likelihood3.html"><a href="03-likelihood3.html#motivation-and-definition"><i class="fa fa-check"></i><b>3.3.1</b> Motivation and definition</a></li>
<li class="chapter" data-level="3.3.2" data-path="03-likelihood3.html"><a href="03-likelihood3.html#examples-of-observed-fisher-information"><i class="fa fa-check"></i><b>3.3.2</b> Examples of observed Fisher information</a></li>
<li class="chapter" data-level="3.3.3" data-path="03-likelihood3.html"><a href="03-likelihood3.html#relationship-between-observed-and-expected-fisher-information"><i class="fa fa-check"></i><b>3.3.3</b> Relationship between observed and expected Fisher information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="04-likelihood4.html"><a href="04-likelihood4.html"><i class="fa fa-check"></i><b>4</b> Quadratic approximation and normal asymptotics</a><ul>
<li class="chapter" data-level="4.1" data-path="04-likelihood4.html"><a href="04-likelihood4.html#multivariate-statistics-for-random-vectors"><i class="fa fa-check"></i><b>4.1</b> Multivariate statistics for random vectors</a><ul>
<li class="chapter" data-level="4.1.1" data-path="04-likelihood4.html"><a href="04-likelihood4.html#covariance-and-correlation"><i class="fa fa-check"></i><b>4.1.1</b> Covariance and correlation</a></li>
<li class="chapter" data-level="4.1.2" data-path="04-likelihood4.html"><a href="04-likelihood4.html#multivariate-normal-distribution"><i class="fa fa-check"></i><b>4.1.2</b> Multivariate normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="04-likelihood4.html"><a href="04-likelihood4.html#approximate-distribution-of-maximum-likelihood-estimates"><i class="fa fa-check"></i><b>4.2</b> Approximate distribution of maximum likelihood estimates</a><ul>
<li class="chapter" data-level="4.2.1" data-path="04-likelihood4.html"><a href="04-likelihood4.html#quadratic-log-likelihood-resulting-from-normal-model"><i class="fa fa-check"></i><b>4.2.1</b> Quadratic log-likelihood resulting from normal model</a></li>
<li class="chapter" data-level="4.2.2" data-path="04-likelihood4.html"><a href="04-likelihood4.html#quadratic-approximation-of-a-log-likelihood-function"><i class="fa fa-check"></i><b>4.2.2</b> Quadratic approximation of a log-likelihood function</a></li>
<li class="chapter" data-level="4.2.3" data-path="04-likelihood4.html"><a href="04-likelihood4.html#asymptotic-normality-of-maximum-likelihood-estimates"><i class="fa fa-check"></i><b>4.2.3</b> Asymptotic normality of maximum likelihood estimates</a></li>
<li class="chapter" data-level="4.2.4" data-path="04-likelihood4.html"><a href="04-likelihood4.html#asymptotic-optimal-efficiency"><i class="fa fa-check"></i><b>4.2.4</b> Asymptotic optimal efficiency</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="04-likelihood4.html"><a href="04-likelihood4.html#quantifying-the-uncertainty-of-maximum-likelihood-estimates"><i class="fa fa-check"></i><b>4.3</b> Quantifying the uncertainty of maximum likelihood estimates</a><ul>
<li class="chapter" data-level="4.3.1" data-path="04-likelihood4.html"><a href="04-likelihood4.html#estimating-the-variance-of-mles"><i class="fa fa-check"></i><b>4.3.1</b> Estimating the variance of MLEs</a></li>
<li class="chapter" data-level="4.3.2" data-path="04-likelihood4.html"><a href="04-likelihood4.html#wald-statistic"><i class="fa fa-check"></i><b>4.3.2</b> Wald statistic</a></li>
<li class="chapter" data-level="4.3.3" data-path="04-likelihood4.html"><a href="04-likelihood4.html#normal-confidence-intervals-using-the-wald-statistic"><i class="fa fa-check"></i><b>4.3.3</b> Normal confidence intervals using the Wald statistic</a></li>
<li class="chapter" data-level="4.3.4" data-path="04-likelihood4.html"><a href="04-likelihood4.html#normal-tests-using-the-wald-statistic"><i class="fa fa-check"></i><b>4.3.4</b> Normal tests using the Wald statistic</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="04-likelihood4.html"><a href="04-likelihood4.html#example-of-a-non-regular-model"><i class="fa fa-check"></i><b>4.4</b> Example of a non-regular model</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="05-likelihood5.html"><a href="05-likelihood5.html"><i class="fa fa-check"></i><b>5</b> Likelihood-based confidence interval and likelihood ratio</a><ul>
<li class="chapter" data-level="5.1" data-path="05-likelihood5.html"><a href="05-likelihood5.html#likelihood-based-confidence-intervals-and-wilks-statistic"><i class="fa fa-check"></i><b>5.1</b> Likelihood-based confidence intervals and Wilks statistic</a><ul>
<li class="chapter" data-level="5.1.1" data-path="05-likelihood5.html"><a href="05-likelihood5.html#general-idea-and-definition-of-wilks-statistic"><i class="fa fa-check"></i><b>5.1.1</b> General idea and definition of Wilks statistic</a></li>
<li class="chapter" data-level="5.1.2" data-path="05-likelihood5.html"><a href="05-likelihood5.html#quadratic-approximation-of-wilks-statistic-and-squared-wald-statistic"><i class="fa fa-check"></i><b>5.1.2</b> Quadratic approximation of Wilks statistic and squared Wald statistic</a></li>
<li class="chapter" data-level="5.1.3" data-path="05-likelihood5.html"><a href="05-likelihood5.html#distribution-of-the-wilks-statistic"><i class="fa fa-check"></i><b>5.1.3</b> Distribution of the Wilks statistic</a></li>
<li class="chapter" data-level="5.1.4" data-path="05-likelihood5.html"><a href="05-likelihood5.html#cutoff-values-for-the-likelihood-ci"><i class="fa fa-check"></i><b>5.1.4</b> Cutoff values for the likelihood CI</a></li>
<li class="chapter" data-level="5.1.5" data-path="05-likelihood5.html"><a href="05-likelihood5.html#likelihood-ratio-test-lrt-using-wilks-statistic"><i class="fa fa-check"></i><b>5.1.5</b> Likelihood ratio test (LRT) using Wilks statistic</a></li>
<li class="chapter" data-level="5.1.6" data-path="05-likelihood5.html"><a href="05-likelihood5.html#origin-of-likelihood-ratio-statistic"><i class="fa fa-check"></i><b>5.1.6</b> Origin of likelihood ratio statistic</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="05-likelihood5.html"><a href="05-likelihood5.html#generalised-likelihood-ratio-test-glrt"><i class="fa fa-check"></i><b>5.2</b> Generalised likelihood ratio test (GLRT)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="06-likelihood6.html"><a href="06-likelihood6.html"><i class="fa fa-check"></i><b>6</b> Optimality properties and conclusion</a><ul>
<li class="chapter" data-level="6.1" data-path="06-likelihood6.html"><a href="06-likelihood6.html#properties-of-maximum-likelihood-encountered-so-far"><i class="fa fa-check"></i><b>6.1</b> Properties of maximum likelihood encountered so far</a></li>
<li class="chapter" data-level="6.2" data-path="06-likelihood6.html"><a href="06-likelihood6.html#summarising-data-and-the-concept-of-minimal-sufficiency"><i class="fa fa-check"></i><b>6.2</b> Summarising data and the concept of minimal sufficiency</a></li>
<li class="chapter" data-level="6.3" data-path="06-likelihood6.html"><a href="06-likelihood6.html#concluding-remarks-on-maximum-likelihood"><i class="fa fa-check"></i><b>6.3</b> Concluding remarks on maximum likelihood</a><ul>
<li class="chapter" data-level="6.3.1" data-path="06-likelihood6.html"><a href="06-likelihood6.html#remark-on-kl-divergence"><i class="fa fa-check"></i><b>6.3.1</b> Remark on KL divergence</a></li>
<li class="chapter" data-level="6.3.2" data-path="06-likelihood6.html"><a href="06-likelihood6.html#what-happens-if-n-is-small"><i class="fa fa-check"></i><b>6.3.2</b> What happens if <span class="math inline">\(n\)</span> is small?</a></li>
<li class="chapter" data-level="6.3.3" data-path="06-likelihood6.html"><a href="06-likelihood6.html#model-selection"><i class="fa fa-check"></i><b>6.3.3</b> Model selection</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Bayesian Statistics</b></span></li>
<li class="chapter" data-level="7" data-path="07-bayes1.html"><a href="07-bayes1.html"><i class="fa fa-check"></i><b>7</b> Essentials of Bayesian statistics</a><ul>
<li class="chapter" data-level="7.1" data-path="07-bayes1.html"><a href="07-bayes1.html#conditional-probability"><i class="fa fa-check"></i><b>7.1</b> Conditional probability</a></li>
<li class="chapter" data-level="7.2" data-path="07-bayes1.html"><a href="07-bayes1.html#bayes-theorem"><i class="fa fa-check"></i><b>7.2</b> Bayes’ theorem</a></li>
<li class="chapter" data-level="7.3" data-path="07-bayes1.html"><a href="07-bayes1.html#principle-of-bayesian-learning"><i class="fa fa-check"></i><b>7.3</b> Principle of Bayesian learning</a></li>
<li class="chapter" data-level="7.4" data-path="07-bayes1.html"><a href="07-bayes1.html#what-is-exactly-is-the-bayesian-estimate"><i class="fa fa-check"></i><b>7.4</b> What is exactly is the “Bayesian estimate”?</a></li>
<li class="chapter" data-level="7.5" data-path="07-bayes1.html"><a href="07-bayes1.html#computer-implementation-of-bayesian-learning"><i class="fa fa-check"></i><b>7.5</b> Computer implementation of Bayesian learning</a></li>
<li class="chapter" data-level="7.6" data-path="07-bayes1.html"><a href="07-bayes1.html#bayesian-interpretation-of-probability"><i class="fa fa-check"></i><b>7.6</b> Bayesian interpretation of probability</a><ul>
<li class="chapter" data-level="7.6.1" data-path="07-bayes1.html"><a href="07-bayes1.html#what-makes-you-bayesian"><i class="fa fa-check"></i><b>7.6.1</b> What makes you “Bayesian”?</a></li>
<li class="chapter" data-level="7.6.2" data-path="07-bayes1.html"><a href="07-bayes1.html#mathematics-of-probability"><i class="fa fa-check"></i><b>7.6.2</b> Mathematics of probability</a></li>
<li class="chapter" data-level="7.6.3" data-path="07-bayes1.html"><a href="07-bayes1.html#interpretations-of-probability"><i class="fa fa-check"></i><b>7.6.3</b> Interpretations of probability</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="07-bayes1.html"><a href="07-bayes1.html#historical-developments"><i class="fa fa-check"></i><b>7.7</b> Historical developments</a></li>
<li class="chapter" data-level="7.8" data-path="07-bayes1.html"><a href="07-bayes1.html#connection-with-entropy-learning"><i class="fa fa-check"></i><b>7.8</b> Connection with entropy learning</a><ul>
<li class="chapter" data-level="7.8.1" data-path="07-bayes1.html"><a href="07-bayes1.html#zero-forcing-property"><i class="fa fa-check"></i><b>7.8.1</b> Zero forcing property</a></li>
<li class="chapter" data-level="7.8.2" data-path="07-bayes1.html"><a href="07-bayes1.html#connection-with-entropy-learning-1"><i class="fa fa-check"></i><b>7.8.2</b> Connection with entropy learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="08-bayes2.html"><a href="08-bayes2.html"><i class="fa fa-check"></i><b>8</b> Beta-Binomial model for estimating a proportion</a><ul>
<li class="chapter" data-level="8.1" data-path="08-bayes2.html"><a href="08-bayes2.html#binomial-likelihood"><i class="fa fa-check"></i><b>8.1</b> Binomial likelihood</a></li>
<li class="chapter" data-level="8.2" data-path="08-bayes2.html"><a href="08-bayes2.html#excursion-properties-of-the-beta-distribution"><i class="fa fa-check"></i><b>8.2</b> Excursion: Properties of the Beta distribution</a></li>
<li class="chapter" data-level="8.3" data-path="08-bayes2.html"><a href="08-bayes2.html#beta-prior-distribution"><i class="fa fa-check"></i><b>8.3</b> Beta prior distribution</a></li>
<li class="chapter" data-level="8.4" data-path="08-bayes2.html"><a href="08-bayes2.html#computing-the-posterior-distribution"><i class="fa fa-check"></i><b>8.4</b> Computing the posterior distribution</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="09-bayes3.html"><a href="09-bayes3.html"><i class="fa fa-check"></i><b>9</b> Properties of Bayesian learning</a><ul>
<li class="chapter" data-level="9.1" data-path="09-bayes3.html"><a href="09-bayes3.html#prior-acting-as-pseudo-data"><i class="fa fa-check"></i><b>9.1</b> Prior acting as pseudo-data</a></li>
<li class="chapter" data-level="9.2" data-path="09-bayes3.html"><a href="09-bayes3.html#linear-shrinkage-of-mean"><i class="fa fa-check"></i><b>9.2</b> Linear shrinkage of mean</a></li>
<li class="chapter" data-level="9.3" data-path="09-bayes3.html"><a href="09-bayes3.html#conjugacy-of-prior-and-posterior-distribution"><i class="fa fa-check"></i><b>9.3</b> Conjugacy of prior and posterior distribution</a></li>
<li class="chapter" data-level="9.4" data-path="09-bayes3.html"><a href="09-bayes3.html#large-sample-asymptotics"><i class="fa fa-check"></i><b>9.4</b> Large sample asymptotics</a><ul>
<li class="chapter" data-level="9.4.1" data-path="09-bayes3.html"><a href="09-bayes3.html#large-sample-limits-of-mean-and-variance"><i class="fa fa-check"></i><b>9.4.1</b> Large sample limits of mean and variance</a></li>
<li class="chapter" data-level="9.4.2" data-path="09-bayes3.html"><a href="09-bayes3.html#asymptotic-normality-of-the-posterior-distribution"><i class="fa fa-check"></i><b>9.4.2</b> Asymptotic Normality of the Posterior distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="09-bayes3.html"><a href="09-bayes3.html#posterior-variance-for-finite-n"><i class="fa fa-check"></i><b>9.5</b> Posterior variance for finite <span class="math inline">\(n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-bayes4.html"><a href="10-bayes4.html"><i class="fa fa-check"></i><b>10</b> Normal-Normal and Inverse-Gamma-Normal models for estimating the mean and the variance</a><ul>
<li class="chapter" data-level="10.1" data-path="10-bayes4.html"><a href="10-bayes4.html#normal-normal-model-to-estimate-mean"><i class="fa fa-check"></i><b>10.1</b> Normal-Normal model to estimate mean</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-bayes4.html"><a href="10-bayes4.html#normal-likelihood"><i class="fa fa-check"></i><b>10.1.1</b> Normal likelihood</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-bayes4.html"><a href="10-bayes4.html#normal-prior-distribution"><i class="fa fa-check"></i><b>10.1.2</b> Normal prior distribution</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-bayes4.html"><a href="10-bayes4.html#normal-posterior-distribution"><i class="fa fa-check"></i><b>10.1.3</b> Normal posterior distribution</a></li>
<li class="chapter" data-level="10.1.4" data-path="10-bayes4.html"><a href="10-bayes4.html#large-sample-asymptotics-and-stein-paradox"><i class="fa fa-check"></i><b>10.1.4</b> Large sample asymptotics and Stein paradox</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-bayes4.html"><a href="10-bayes4.html#inverse-gamma-normal-model-to-estimate-variance"><i class="fa fa-check"></i><b>10.2</b> Inverse-Gamma-Normal model to estimate variance</a><ul>
<li class="chapter" data-level="10.2.1" data-path="10-bayes4.html"><a href="10-bayes4.html#inverse-gamma-distribution"><i class="fa fa-check"></i><b>10.2.1</b> Inverse Gamma distribution</a></li>
<li class="chapter" data-level="10.2.2" data-path="10-bayes4.html"><a href="10-bayes4.html#normal-likelihoood"><i class="fa fa-check"></i><b>10.2.2</b> Normal likelihoood</a></li>
<li class="chapter" data-level="10.2.3" data-path="10-bayes4.html"><a href="10-bayes4.html#inverse-gamma-prior-distribution"><i class="fa fa-check"></i><b>10.2.3</b> Inverse Gamma prior distribution</a></li>
<li class="chapter" data-level="10.2.4" data-path="10-bayes4.html"><a href="10-bayes4.html#inverse-gamma-posterior-distribution"><i class="fa fa-check"></i><b>10.2.4</b> Inverse Gamma posterior distribution</a></li>
<li class="chapter" data-level="10.2.5" data-path="10-bayes4.html"><a href="10-bayes4.html#large-sample-asymptotics-1"><i class="fa fa-check"></i><b>10.2.5</b> Large sample asymptotics</a></li>
<li class="chapter" data-level="10.2.6" data-path="10-bayes4.html"><a href="10-bayes4.html#estimating-precision"><i class="fa fa-check"></i><b>10.2.6</b> Estimating precision</a></li>
<li class="chapter" data-level="10.2.7" data-path="10-bayes4.html"><a href="10-bayes4.html#joint-estimation-of-mean-and-variance"><i class="fa fa-check"></i><b>10.2.7</b> Joint estimation of mean and variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-bayes5.html"><a href="11-bayes5.html"><i class="fa fa-check"></i><b>11</b> Shrinkage estimation using empirical risk minimisation</a><ul>
<li class="chapter" data-level="11.1" data-path="11-bayes5.html"><a href="11-bayes5.html#linear-shrinkage"><i class="fa fa-check"></i><b>11.1</b> Linear shrinkage</a></li>
<li class="chapter" data-level="11.2" data-path="11-bayes5.html"><a href="11-bayes5.html#james-stein-estimator"><i class="fa fa-check"></i><b>11.2</b> James-Stein estimator</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-bayes6.html"><a href="12-bayes6.html"><i class="fa fa-check"></i><b>12</b> Bayesian model comparison using Bayes factors and the BIC</a><ul>
<li class="chapter" data-level="12.1" data-path="12-bayes6.html"><a href="12-bayes6.html#the-bayes-factor"><i class="fa fa-check"></i><b>12.1</b> The Bayes factor</a><ul>
<li class="chapter" data-level="12.1.1" data-path="12-bayes6.html"><a href="12-bayes6.html#connection-with-relative-entropy"><i class="fa fa-check"></i><b>12.1.1</b> Connection with relative entropy</a></li>
<li class="chapter" data-level="12.1.2" data-path="12-bayes6.html"><a href="12-bayes6.html#interpretation-of-and-scale-for-bayes-factor"><i class="fa fa-check"></i><b>12.1.2</b> Interpretation of and scale for Bayes factor</a></li>
<li class="chapter" data-level="12.1.3" data-path="12-bayes6.html"><a href="12-bayes6.html#computing-pd-m-for-simple-and-composite-models"><i class="fa fa-check"></i><b>12.1.3</b> Computing <span class="math inline">\(p(D | M)\)</span> for simple and composite models</a></li>
<li class="chapter" data-level="12.1.4" data-path="12-bayes6.html"><a href="12-bayes6.html#bayes-factor-versus-likelihood-ratio"><i class="fa fa-check"></i><b>12.1.4</b> Bayes factor versus likelihood ratio</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="12-bayes6.html"><a href="12-bayes6.html#approximate-computation-of-the-marginal-likelihood-and-of-the-log-bayes-factor"><i class="fa fa-check"></i><b>12.2</b> Approximate computation of the marginal likelihood and of the log-Bayes factor</a><ul>
<li class="chapter" data-level="12.2.1" data-path="12-bayes6.html"><a href="12-bayes6.html#schwarz-1978-approximation-of-log-marginal-likelihood"><i class="fa fa-check"></i><b>12.2.1</b> Schwarz (1978) approximation of log-marginal likelihood</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-bayes6.html"><a href="12-bayes6.html#bayesian-information-criterion-bic"><i class="fa fa-check"></i><b>12.2.2</b> Bayesian information criterion (BIC)</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-bayes6.html"><a href="12-bayes6.html#approximating-the-weight-of-evidence-log-bayes-factor-with-bic"><i class="fa fa-check"></i><b>12.2.3</b> Approximating the weight of evidence (log-Bayes factor) with BIC</a></li>
<li class="chapter" data-level="12.2.4" data-path="12-bayes6.html"><a href="12-bayes6.html#model-complexity-and-occams-razor"><i class="fa fa-check"></i><b>12.2.4</b> Model complexity and Occams razor</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-bayes7.html"><a href="13-bayes7.html"><i class="fa fa-check"></i><b>13</b> False discovery rates</a><ul>
<li class="chapter" data-level="13.1" data-path="13-bayes7.html"><a href="13-bayes7.html#general-setup"><i class="fa fa-check"></i><b>13.1</b> General setup</a><ul>
<li class="chapter" data-level="13.1.1" data-path="13-bayes7.html"><a href="13-bayes7.html#overview-1"><i class="fa fa-check"></i><b>13.1.1</b> Overview</a></li>
<li class="chapter" data-level="13.1.2" data-path="13-bayes7.html"><a href="13-bayes7.html#choosing-between-h_0-and-h_a"><i class="fa fa-check"></i><b>13.1.2</b> Choosing between <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_A\)</span></a></li>
<li class="chapter" data-level="13.1.3" data-path="13-bayes7.html"><a href="13-bayes7.html#true-and-false-positives-and-negatives"><i class="fa fa-check"></i><b>13.1.3</b> True and false positives and negatives</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="13-bayes7.html"><a href="13-bayes7.html#specificity-and-sensitivity"><i class="fa fa-check"></i><b>13.2</b> Specificity and Sensitivity</a></li>
<li class="chapter" data-level="13.3" data-path="13-bayes7.html"><a href="13-bayes7.html#fdr-and-fndr"><i class="fa fa-check"></i><b>13.3</b> FDR and FNDR</a></li>
<li class="chapter" data-level="13.4" data-path="13-bayes7.html"><a href="13-bayes7.html#bayesian-perspective"><i class="fa fa-check"></i><b>13.4</b> Bayesian perspective</a><ul>
<li class="chapter" data-level="13.4.1" data-path="13-bayes7.html"><a href="13-bayes7.html#two-component-mixture-model"><i class="fa fa-check"></i><b>13.4.1</b> Two component mixture model</a></li>
<li class="chapter" data-level="13.4.2" data-path="13-bayes7.html"><a href="13-bayes7.html#local-fdr"><i class="fa fa-check"></i><b>13.4.2</b> Local FDR</a></li>
<li class="chapter" data-level="13.4.3" data-path="13-bayes7.html"><a href="13-bayes7.html#q-values"><i class="fa fa-check"></i><b>13.4.3</b> q-values</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="13-bayes7.html"><a href="13-bayes7.html#software"><i class="fa fa-check"></i><b>13.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-bayes8.html"><a href="14-bayes8.html"><i class="fa fa-check"></i><b>14</b> Optimality properties and summary</a><ul>
<li class="chapter" data-level="14.1" data-path="14-bayes8.html"><a href="14-bayes8.html#bayesian-statistics-in-a-nutshell"><i class="fa fa-check"></i><b>14.1</b> Bayesian statistics in a nutshell</a><ul>
<li class="chapter" data-level="14.1.1" data-path="14-bayes8.html"><a href="14-bayes8.html#remarks"><i class="fa fa-check"></i><b>14.1.1</b> Remarks</a></li>
<li class="chapter" data-level="14.1.2" data-path="14-bayes8.html"><a href="14-bayes8.html#advantages"><i class="fa fa-check"></i><b>14.1.2</b> Advantages</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="14-bayes8.html"><a href="14-bayes8.html#frequentist-properties-of-bayesian-estimators"><i class="fa fa-check"></i><b>14.2</b> Frequentist properties of Bayesian estimators</a></li>
<li class="chapter" data-level="14.3" data-path="14-bayes8.html"><a href="14-bayes8.html#specifying-the-prior-problem-or-advantage"><i class="fa fa-check"></i><b>14.3</b> Specifying the prior — problem or advantage?</a></li>
<li class="chapter" data-level="14.4" data-path="14-bayes8.html"><a href="14-bayes8.html#choosing-a-prior"><i class="fa fa-check"></i><b>14.4</b> Choosing a prior</a><ul>
<li class="chapter" data-level="14.4.1" data-path="14-bayes8.html"><a href="14-bayes8.html#some-guidelines"><i class="fa fa-check"></i><b>14.4.1</b> Some guidelines</a></li>
<li class="chapter" data-level="14.4.2" data-path="14-bayes8.html"><a href="14-bayes8.html#jeffreys-prior"><i class="fa fa-check"></i><b>14.4.2</b> Jeffreys prior</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="14-bayes8.html"><a href="14-bayes8.html#optimality-of-bayesian-inference"><i class="fa fa-check"></i><b>14.5</b> Optimality of Bayesian inference</a></li>
<li class="chapter" data-level="14.6" data-path="14-bayes8.html"><a href="14-bayes8.html#conclusion"><i class="fa fa-check"></i><b>14.6</b> Conclusion</a><ul>
<li class="chapter" data-level="14.6.1" data-path="14-bayes8.html"><a href="14-bayes8.html#current-directions-of-research"><i class="fa fa-check"></i><b>14.6.1</b> Current directions of research</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Regression</b></span></li>
<li class="chapter" data-level="15" data-path="15-regression1.html"><a href="15-regression1.html"><i class="fa fa-check"></i><b>15</b> Overview over regression modelling</a><ul>
<li class="chapter" data-level="15.1" data-path="15-regression1.html"><a href="15-regression1.html#general-setup-1"><i class="fa fa-check"></i><b>15.1</b> General setup</a></li>
<li class="chapter" data-level="15.2" data-path="15-regression1.html"><a href="15-regression1.html#objectives"><i class="fa fa-check"></i><b>15.2</b> Objectives</a></li>
<li class="chapter" data-level="15.3" data-path="15-regression1.html"><a href="15-regression1.html#regression-as-a-form-of-supervised-learning"><i class="fa fa-check"></i><b>15.3</b> Regression as a form of supervised learning</a></li>
<li class="chapter" data-level="15.4" data-path="15-regression1.html"><a href="15-regression1.html#various-regression-models-used-in-statistics"><i class="fa fa-check"></i><b>15.4</b> Various regression models used in statistics</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="16-regression2.html"><a href="16-regression2.html"><i class="fa fa-check"></i><b>16</b> Linear Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="16-regression2.html"><a href="16-regression2.html#the-linear-regression-model"><i class="fa fa-check"></i><b>16.1</b> The linear regression model</a></li>
<li class="chapter" data-level="16.2" data-path="16-regression2.html"><a href="16-regression2.html#interpretation-of-regression-coefficients-and-intercept"><i class="fa fa-check"></i><b>16.2</b> Interpretation of regression coefficients and intercept</a></li>
<li class="chapter" data-level="16.3" data-path="16-regression2.html"><a href="16-regression2.html#different-types-of-linear-regression"><i class="fa fa-check"></i><b>16.3</b> Different types of linear regression:</a></li>
<li class="chapter" data-level="16.4" data-path="16-regression2.html"><a href="16-regression2.html#distributional-assumptions-and-properties"><i class="fa fa-check"></i><b>16.4</b> Distributional assumptions and properties</a></li>
<li class="chapter" data-level="16.5" data-path="16-regression2.html"><a href="16-regression2.html#regression-in-data-matrix-notation"><i class="fa fa-check"></i><b>16.5</b> Regression in data matrix notation</a></li>
<li class="chapter" data-level="16.6" data-path="16-regression2.html"><a href="16-regression2.html#centering-and-vanishing-of-the-intercept-beta_0"><i class="fa fa-check"></i><b>16.6</b> Centering and vanishing of the intercept <span class="math inline">\(\beta_0\)</span></a></li>
<li class="chapter" data-level="16.7" data-path="16-regression2.html"><a href="16-regression2.html#regression-objectives-for-linear-model"><i class="fa fa-check"></i><b>16.7</b> Regression objectives for linear model</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="17-regression3.html"><a href="17-regression3.html"><i class="fa fa-check"></i><b>17</b> Estimating regression coefficients</a><ul>
<li class="chapter" data-level="17.1" data-path="17-regression3.html"><a href="17-regression3.html#ordinary-least-squares-ols-estimator-of-regression-coefficients"><i class="fa fa-check"></i><b>17.1</b> Ordinary Least Squares (OLS) estimator of regression coefficients</a></li>
<li class="chapter" data-level="17.2" data-path="17-regression3.html"><a href="17-regression3.html#maximum-likelihood-estimation-of-regression-coefficients"><i class="fa fa-check"></i><b>17.2</b> Maximum likelihood estimation of regression coefficients</a><ul>
<li class="chapter" data-level="17.2.1" data-path="17-regression3.html"><a href="17-regression3.html#detailed-derivation-of-the-mles"><i class="fa fa-check"></i><b>17.2.1</b> Detailed derivation of the MLEs</a></li>
<li class="chapter" data-level="17.2.2" data-path="17-regression3.html"><a href="17-regression3.html#asymptotics"><i class="fa fa-check"></i><b>17.2.2</b> Asymptotics</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="17-regression3.html"><a href="17-regression3.html#covariance-plug-in-estimator-of-regression-coefficients"><i class="fa fa-check"></i><b>17.3</b> Covariance plug-in estimator of regression coefficients</a><ul>
<li class="chapter" data-level="17.3.1" data-path="17-regression3.html"><a href="17-regression3.html#importance-of-positive-definiteness-of-estimated-covariance-matrix"><i class="fa fa-check"></i><b>17.3.1</b> Importance of positive definiteness of estimated covariance matrix</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="17-regression3.html"><a href="17-regression3.html#best-linear-predictor"><i class="fa fa-check"></i><b>17.4</b> Best linear predictor</a><ul>
<li class="chapter" data-level="17.4.1" data-path="17-regression3.html"><a href="17-regression3.html#result"><i class="fa fa-check"></i><b>17.4.1</b> Result:</a></li>
<li class="chapter" data-level="17.4.2" data-path="17-regression3.html"><a href="17-regression3.html#irreducible-error"><i class="fa fa-check"></i><b>17.4.2</b> Irreducible Error</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="17-regression3.html"><a href="17-regression3.html#regression-by-conditioning"><i class="fa fa-check"></i><b>17.5</b> Regression by conditioning</a><ul>
<li class="chapter" data-level="17.5.1" data-path="17-regression3.html"><a href="17-regression3.html#general-idea"><i class="fa fa-check"></i><b>17.5.1</b> General idea:</a></li>
<li class="chapter" data-level="17.5.2" data-path="17-regression3.html"><a href="17-regression3.html#multivariate-normal-assumption"><i class="fa fa-check"></i><b>17.5.2</b> Multivariate normal assumption</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="17-regression3.html"><a href="17-regression3.html#standardised-regression-coefficients-and-relationship-to-correlation"><i class="fa fa-check"></i><b>17.6</b> Standardised regression coefficients and relationship to correlation</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="18-regression4.html"><a href="18-regression4.html"><i class="fa fa-check"></i><b>18</b> Squared multiple correlation and variance decomposition in linear regression</a><ul>
<li class="chapter" data-level="18.1" data-path="18-regression4.html"><a href="18-regression4.html#squared-multiple-correlation-omega2-and-the-r2-coefficient"><i class="fa fa-check"></i><b>18.1</b> Squared multiple correlation <span class="math inline">\(\Omega^2\)</span> and the <span class="math inline">\(R^2\)</span> coefficient</a><ul>
<li class="chapter" data-level="18.1.1" data-path="18-regression4.html"><a href="18-regression4.html#estimation-of-omega2-and-the-multiple-r2-coefficient"><i class="fa fa-check"></i><b>18.1.1</b> Estimation of <span class="math inline">\(\Omega^2\)</span> and the multiple <span class="math inline">\(R^2\)</span> coefficient</a></li>
<li class="chapter" data-level="18.1.2" data-path="18-regression4.html"><a href="18-regression4.html#r-commands"><i class="fa fa-check"></i><b>18.1.2</b> R commands</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="18-regression4.html"><a href="18-regression4.html#variance-decomposition-in-regression"><i class="fa fa-check"></i><b>18.2</b> Variance decomposition in regression</a><ul>
<li class="chapter" data-level="18.2.1" data-path="18-regression4.html"><a href="18-regression4.html#law-of-total-variance-and-variance-decomposition"><i class="fa fa-check"></i><b>18.2.1</b> Law of total variance and variance decomposition</a></li>
<li class="chapter" data-level="18.2.2" data-path="18-regression4.html"><a href="18-regression4.html#related-quantities"><i class="fa fa-check"></i><b>18.2.2</b> Related quantities</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="18-regression4.html"><a href="18-regression4.html#sample-version-of-variance-decomposition"><i class="fa fa-check"></i><b>18.3</b> Sample version of variance decomposition</a><ul>
<li class="chapter" data-level="18.3.1" data-path="18-regression4.html"><a href="18-regression4.html#geometric-interpretation-of-regression-as-orthogonal-projection"><i class="fa fa-check"></i><b>18.3.1</b> Geometric interpretation of regression as orthogonal projection:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="19-regression5.html"><a href="19-regression5.html"><i class="fa fa-check"></i><b>19</b> Prediction and variable selection</a><ul>
<li class="chapter" data-level="19.1" data-path="19-regression5.html"><a href="19-regression5.html#prediction-and-prediction-intervals"><i class="fa fa-check"></i><b>19.1</b> Prediction and prediction intervals</a></li>
<li class="chapter" data-level="19.2" data-path="19-regression5.html"><a href="19-regression5.html#variable-importance-and-prediction"><i class="fa fa-check"></i><b>19.2</b> Variable importance and prediction</a><ul>
<li class="chapter" data-level="19.2.1" data-path="19-regression5.html"><a href="19-regression5.html#how-to-quantify-variable-importance"><i class="fa fa-check"></i><b>19.2.1</b> How to quantify variable importance?</a></li>
<li class="chapter" data-level="19.2.2" data-path="19-regression5.html"><a href="19-regression5.html#some-candidates-for-vims"><i class="fa fa-check"></i><b>19.2.2</b> Some candidates for VIMs</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="19-regression5.html"><a href="19-regression5.html#regression-t-scores."><i class="fa fa-check"></i><b>19.3</b> Regression <span class="math inline">\(t\)</span>-scores.</a><ul>
<li class="chapter" data-level="19.3.1" data-path="19-regression5.html"><a href="19-regression5.html#computation"><i class="fa fa-check"></i><b>19.3.1</b> Computation</a></li>
<li class="chapter" data-level="19.3.2" data-path="19-regression5.html"><a href="19-regression5.html#connection-with-partial-correlation"><i class="fa fa-check"></i><b>19.3.2</b> Connection with partial correlation</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="19-regression5.html"><a href="19-regression5.html#further-approaches-for-variable-selection"><i class="fa fa-check"></i><b>19.4</b> Further approaches for variable selection</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="20-refresher.html"><a href="20-refresher.html"><i class="fa fa-check"></i><b>A</b> Refresher</a><ul>
<li class="chapter" data-level="A.1" data-path="20-refresher.html"><a href="20-refresher.html#basic-mathematical-notation"><i class="fa fa-check"></i><b>A.1</b> Basic mathematical notation</a></li>
<li class="chapter" data-level="A.2" data-path="20-refresher.html"><a href="20-refresher.html#vectors-and-matrices"><i class="fa fa-check"></i><b>A.2</b> Vectors and matrices</a></li>
<li class="chapter" data-level="A.3" data-path="20-refresher.html"><a href="20-refresher.html#functions"><i class="fa fa-check"></i><b>A.3</b> Functions</a><ul>
<li class="chapter" data-level="A.3.1" data-path="20-refresher.html"><a href="20-refresher.html#gradient"><i class="fa fa-check"></i><b>A.3.1</b> Gradient</a></li>
<li class="chapter" data-level="A.3.2" data-path="20-refresher.html"><a href="20-refresher.html#hessian-matrix"><i class="fa fa-check"></i><b>A.3.2</b> Hessian matrix</a></li>
<li class="chapter" data-level="A.3.3" data-path="20-refresher.html"><a href="20-refresher.html#convex-and-concave-functions"><i class="fa fa-check"></i><b>A.3.3</b> Convex and concave functions</a></li>
<li class="chapter" data-level="A.3.4" data-path="20-refresher.html"><a href="20-refresher.html#linear-and-quadratic-approximation"><i class="fa fa-check"></i><b>A.3.4</b> Linear and quadratic approximation</a></li>
<li class="chapter" data-level="A.3.5" data-path="20-refresher.html"><a href="20-refresher.html#conditions-for-local-optimum-of-a-function"><i class="fa fa-check"></i><b>A.3.5</b> Conditions for local optimum of a function</a></li>
<li class="chapter" data-level="A.3.6" data-path="20-refresher.html"><a href="20-refresher.html#functions-of-matrices"><i class="fa fa-check"></i><b>A.3.6</b> Functions of matrices</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="20-refresher.html"><a href="20-refresher.html#combinatorics"><i class="fa fa-check"></i><b>A.4</b> Combinatorics</a><ul>
<li class="chapter" data-level="A.4.1" data-path="20-refresher.html"><a href="20-refresher.html#number-of-permutations"><i class="fa fa-check"></i><b>A.4.1</b> Number of permutations</a></li>
<li class="chapter" data-level="A.4.2" data-path="20-refresher.html"><a href="20-refresher.html#multinomial-and-binomial-coefficient"><i class="fa fa-check"></i><b>A.4.2</b> Multinomial and binomial coefficient</a></li>
<li class="chapter" data-level="A.4.3" data-path="20-refresher.html"><a href="20-refresher.html#de-moivre-sterling-approximation-of-the-factorial"><i class="fa fa-check"></i><b>A.4.3</b> De Moivre-Sterling approximation of the factorial</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="20-refresher.html"><a href="20-refresher.html#probability"><i class="fa fa-check"></i><b>A.5</b> Probability</a><ul>
<li class="chapter" data-level="A.5.1" data-path="20-refresher.html"><a href="20-refresher.html#random-variables"><i class="fa fa-check"></i><b>A.5.1</b> Random variables</a></li>
<li class="chapter" data-level="A.5.2" data-path="20-refresher.html"><a href="20-refresher.html#probability-mass-and-density-function-and-distribution-and-quantile-function"><i class="fa fa-check"></i><b>A.5.2</b> Probability mass and density function and distribution and quantile function</a></li>
<li class="chapter" data-level="A.5.3" data-path="20-refresher.html"><a href="20-refresher.html#expection-and-variance-of-a-random-variable"><i class="fa fa-check"></i><b>A.5.3</b> Expection and variance of a random variable</a></li>
<li class="chapter" data-level="A.5.4" data-path="20-refresher.html"><a href="20-refresher.html#transformation-of-random-variables"><i class="fa fa-check"></i><b>A.5.4</b> Transformation of random variables</a></li>
<li class="chapter" data-level="A.5.5" data-path="20-refresher.html"><a href="20-refresher.html#law-of-large-numbers"><i class="fa fa-check"></i><b>A.5.5</b> Law of large numbers:</a></li>
<li class="chapter" data-level="A.5.6" data-path="20-refresher.html"><a href="20-refresher.html#jensens-inequality"><i class="fa fa-check"></i><b>A.5.6</b> Jensen’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="A.6" data-path="20-refresher.html"><a href="20-refresher.html#distributions"><i class="fa fa-check"></i><b>A.6</b> Distributions</a><ul>
<li class="chapter" data-level="A.6.1" data-path="20-refresher.html"><a href="20-refresher.html#bernoulli-and-binomial-distribution"><i class="fa fa-check"></i><b>A.6.1</b> Bernoulli and Binomial distribution</a></li>
<li class="chapter" data-level="A.6.2" data-path="20-refresher.html"><a href="20-refresher.html#normal-distribution"><i class="fa fa-check"></i><b>A.6.2</b> Normal distribution</a></li>
<li class="chapter" data-level="A.6.3" data-path="20-refresher.html"><a href="20-refresher.html#scaled-chi-squared-wishart-gamma-distribution-and-exponential-distribution"><i class="fa fa-check"></i><b>A.6.3</b> Scaled chi-squared / Wishart / gamma distribution and exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="A.7" data-path="20-refresher.html"><a href="20-refresher.html#statistics"><i class="fa fa-check"></i><b>A.7</b> Statistics</a><ul>
<li class="chapter" data-level="A.7.1" data-path="20-refresher.html"><a href="20-refresher.html#statistical-learning"><i class="fa fa-check"></i><b>A.7.1</b> Statistical learning</a></li>
<li class="chapter" data-level="A.7.2" data-path="20-refresher.html"><a href="20-refresher.html#point-and-interval-estimation"><i class="fa fa-check"></i><b>A.7.2</b> Point and interval estimation</a></li>
<li class="chapter" data-level="A.7.3" data-path="20-refresher.html"><a href="20-refresher.html#sampling-properties-of-a-point-estimator-hatboldsymbol-theta"><i class="fa fa-check"></i><b>A.7.3</b> Sampling properties of a point estimator <span class="math inline">\(\hat{\boldsymbol \theta}\)</span></a></li>
<li class="chapter" data-level="A.7.4" data-path="20-refresher.html"><a href="20-refresher.html#asymptotics-1"><i class="fa fa-check"></i><b>A.7.4</b> Asymptotics</a></li>
<li class="chapter" data-level="A.7.5" data-path="20-refresher.html"><a href="20-refresher.html#confidence-intervals"><i class="fa fa-check"></i><b>A.7.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="A.7.6" data-path="20-refresher.html"><a href="20-refresher.html#symmetric-normal-confidence-interval"><i class="fa fa-check"></i><b>A.7.6</b> Symmetric normal confidence interval</a></li>
<li class="chapter" data-level="A.7.7" data-path="20-refresher.html"><a href="20-refresher.html#confidence-interval-for-chi-squared-distribution"><i class="fa fa-check"></i><b>A.7.7</b> Confidence interval for chi-squared distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="21-further-study.html"><a href="21-further-study.html"><i class="fa fa-check"></i><b>B</b> Further study</a><ul>
<li class="chapter" data-level="B.1" data-path="21-further-study.html"><a href="21-further-study.html#recommended-reading"><i class="fa fa-check"></i><b>B.1</b> Recommended reading</a></li>
<li class="chapter" data-level="B.2" data-path="21-further-study.html"><a href="21-further-study.html#additional-references"><i class="fa fa-check"></i><b>B.2</b> Additional references</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="22-references.html"><a href="22-references.html"><i class="fa fa-check"></i>Bibliography</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><div class="line-block">Statistical Methods:<br />
Likelihood, Bayes and Regression</div></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title"><div class="line-block">Statistical Methods:<br />
Likelihood, Bayes and Regression</div></h1>
<h2 class="subtitle"><em><div class="line-block">MATH20802<br />
Lecture Notes<br />
2019–2021</div></em></h2>
<p class="author"><em><div class="line-block">Korbinian Strimmer<br />
<br />
University of Manchester<br />
<a href="mailto:korbinian.strimmer@manchester.ac.uk">korbinian.strimmer@manchester.ac.uk</a></div></em></p>
<p class="date" style="margin-top: 1.5em;"><em>8 May 2021</em></p>
</div>

<div id="preface" class="section level1 unnumbered">
<h1>Preface</h1>
<div id="about-these-notes" class="section level2 unnumbered">
<h2>About these notes</h2>
<p>This is the course text for MATH20802, an introductory course in <strong>Statistical Methods</strong> for second year mathematics students.</p>
<p>These notes will be updated from time to time. To view the current
version in your browser visit the
<a href="http://strimmerlab.org/publications/lecture-notes/MATH20802/index.html">online MATH20802 lecture notes</a>.
You may also <a href="http://strimmerlab.org/publications/lecture-notes/MATH20802/math20802-script.pdf">download the MATH20802 lecture notes as PDF</a>.</p>
</div>
<div id="about-the-author" class="section level2 unnumbered">
<h2>About the author</h2>
<p>My name is Korbinian Strimmer and I am a Professor in Statistics in the <a href="https://www.maths.manchester.ac.uk/research/expertise/statistics/">Statistics group
of the Department of Mathematics at the University of Manchester</a>. You can find more information about me on <a href="http://strimmerlab.org/korbinian.html">my home page</a>.</p>
<p>I have first taught this module in the Spring term 2019 at the University of Manchester.</p>
<p>I hope you enjoy the course. If you have any questions, comments, or corrections then please email me at <a href="mailto:korbinian.strimmer@manchester.ac.uk">korbinian.strimmer@manchester.ac.uk</a></p>
</div>
<div id="about-the-module" class="section level2 unnumbered">
<h2>About the module</h2>
<div id="topics-covered" class="section level3 unnumbered">
<h3>Topics covered</h3>
<p>The MATH20802 module is designed to run over the course of 11 weeks.
It has three parts:</p>
<ol style="list-style-type: decimal">
<li>Likelihood estimation and likelihood ratio tests (W1–W5)</li>
<li>Bayesian learning and inference (W6–W8)</li>
<li>Linear regression (W9–W11)</li>
</ol>
<p>This module focuses on conceptual understanding and methods, not on theory,
As such, the presentation in this course is non-technical.
The aim is to offer insights how diverse statistical approaches
are linked and to demonstrate that statistics offers a concise and coherent theory of information rather than being an adhoc collection of “recipes” for data analysis (a common but wrong perception of statistics).</p>
</div>
<div id="prerequisites" class="section level3 unnumbered">
<h3>Prerequisites</h3>
<p>For this module it is important that you refresh your knowledge in:</p>
<ul>
<li>Introduction to statistics</li>
<li>Probability</li>
<li>R data analysis and programming</li>
</ul>
<p>In addition you will need to know matrix algebra and how to compute
the gradient and the curvature of a function of several variables.</p>
<p>Check the Appendix for a brief refresher of the essential material.</p>
</div>
<div id="additional-support-material" class="section level3 unnumbered">
<h3>Additional support material</h3>
<p>Accompanying these notes are</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=omxIGF131q4&amp;list=PLrSyZqaWj-tMn-EywOSlh7CfGs2VzEAqQ">lecture videos</a> (visualiser style).</li>
</ul>
<p>Furthermore, there is also an <a href="https://www.readinglists.manchester.ac.uk/leganto/public/44MAN_INST/lists/320791548820001631?auth=CAS">MATH20802 online reading list</a> hosted by the University of Manchester library.</p>
<p>If you are a University of Manchester student and enrolled in this module
you will find on <a href="https://online.manchester.ac.uk">Blackboard</a>:</p>
<ul>
<li>a weekly learning plan for an 11 week study period,</li>
<li>weekly worksheets with examples and solutions and R code, and</li>
<li>exam papers of previous years.</li>
</ul>
</div>
</div>
<div id="acknowledgements" class="section level2 unnumbered">
<h2>Acknowledgements</h2>
<p>Many thanks to <a href="https://www.turing.ac.uk/people/beatriz-costa-gomes">Beatriz Costa Gomes</a> for her help in creating the 2019 version of the lecture notes and to <a href="https://www.linkedin.com/public-profile/in/kristijonasraudys">Kristijonas Raudys</a> for his extensive feedback on the 2020 version.</p>

<p></p>
</div>
</div>



            </section>

          </div>
        </div>
      </div>

<a href="01-likelihood1.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["math20802-script.pdf", "PDF"]],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
