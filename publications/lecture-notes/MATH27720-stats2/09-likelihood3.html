<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; Observed Fisher information – Statistics 2: Statistical Learning with Likelihood and Bayes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./10-likelihood4.html" rel="next">
<link href="./08-likelihood2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-9290db0fca16de22067673ab8036b289.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-intro1.html">Entropy and likelihood</a></li><li class="breadcrumb-item"><a href="./09-likelihood3.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Observed Fisher information</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistics 2: Statistical Learning with Likelihood and Bayes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-prerequisites.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prerequisites</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Entropy and likelihood</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statistical learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-intro2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Distributions for statistical models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-entropy1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Entropy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-entropy2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Divergence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-entropy3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Expected Fisher information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-entropy4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><span class="math inline">\(\color{Red} \blacktriangleright\)</span> Principle of maximum entropy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-likelihood1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Principle of maximum likelihood</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-likelihood2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Maximum likelihood estimation in practice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-likelihood3.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Observed Fisher information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-likelihood4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Quadratic approximation and normal asymptotics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-likelihood5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Likelihood-based confidence interval and likelihood ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-likelihood6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Optimality properties and conclusion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayesian statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-bayes1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Conditioning and Bayes rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-bayes2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Models with latent variables and missing data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-bayes3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Essentials of Bayesian statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-bayes4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Bayesian learning in practice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-bayes5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Bayesian model comparison</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-bayes6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Choosing priors in Bayesian analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-bayes7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Optimality properties and summary</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bibliography.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-stats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Statistics refresher</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-further-study.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Further study</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#definition-of-the-observed-fisher-information" id="toc-definition-of-the-observed-fisher-information" class="nav-link active" data-scroll-target="#definition-of-the-observed-fisher-information"><span class="header-section-number">9.1</span> Definition of the observed Fisher information</a>
  <ul class="collapse">
  <li><a href="#transformation-properties" id="toc-transformation-properties" class="nav-link" data-scroll-target="#transformation-properties">Transformation properties</a></li>
  <li><a href="#relationship-between-observed-and-expected-fisher-information" id="toc-relationship-between-observed-and-expected-fisher-information" class="nav-link" data-scroll-target="#relationship-between-observed-and-expected-fisher-information">Relationship between observed and expected Fisher information</a></li>
  </ul></li>
  <li><a href="#observed-fisher-information-examples" id="toc-observed-fisher-information-examples" class="nav-link" data-scroll-target="#observed-fisher-information-examples"><span class="header-section-number">9.2</span> Observed Fisher information examples</a>
  <ul class="collapse">
  <li><a href="#models-with-a-single-parameter" id="toc-models-with-a-single-parameter" class="nav-link" data-scroll-target="#models-with-a-single-parameter">Models with a single parameter</a></li>
  <li><a href="#models-with-multiple-parameters" id="toc-models-with-multiple-parameters" class="nav-link" data-scroll-target="#models-with-multiple-parameters">Models with multiple parameters</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-intro1.html">Entropy and likelihood</a></li><li class="breadcrumb-item"><a href="./09-likelihood3.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Observed Fisher information</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-obsfisher" class="quarto-section-identifier"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Observed Fisher information</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="definition-of-the-observed-fisher-information" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="definition-of-the-observed-fisher-information"><span class="header-section-number">9.1</span> Definition of the observed Fisher information</h2>
<div class="cell">
<div class="cell-output-display">
<div id="fig-flatlogl" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="t">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-flatlogl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="09-likelihood3_files/figure-html/fig-flatlogl-1.png" class="img-fluid figure-img" data-fig-pos="t" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-flatlogl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.1: Flat and sharp log-likelihood function.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Visual inspection of the log-likelihood function (e.g. <a href="#fig-flatlogl" class="quarto-xref">Figure&nbsp;<span>9.1</span></a>) suggests that it contains more information about the parameter <span class="math inline">\(\boldsymbol \theta\)</span> than just the location of the maximum point at <span class="math inline">\(\hat{\boldsymbol \theta}_{ML}\)</span>.</p>
<p>In particular, in a regular model the <strong>curvature</strong> of the log-likelihood function at the MLE seems to be related to the accuracy of <span class="math inline">\(\hat{\boldsymbol \theta}_{ML}\)</span>: if the likelihood surface is flat near the maximum (low curvature) then if is more difficult to find the optimal parameter (also numerically). Conversely, if the likelihood surface is sharply peaked (strong curvature) then the maximum point is well defined.</p>
<p>The curvature can be quantified by the second-order derivatives (Hessian matrix) of the log-likelihood function.</p>
<p>Accordingly, the <strong>observed Fisher information</strong> (matrix) is defined as the negative Hessian of the log-likelihood function <span class="math inline">\(\ell_n(\boldsymbol \theta)\)</span> at the MLE <span class="math inline">\(\hat{\boldsymbol \theta}_{ML}\)</span>: <span class="math display">\[
{\boldsymbol J_n}(\hat{\boldsymbol \theta}_{ML}) = - \boldsymbol H(\hat{\boldsymbol \theta}_{ML}  ) = -\nabla \nabla^T \ell_n(\hat{\boldsymbol \theta}_{ML})
\]</span></p>
<p>Sometimes this is simply called the “observed information”. To avoid confusion with the <strong>expected Fisher information</strong> <span class="math display">\[
\boldsymbol I^{\text{Fisher}}(\boldsymbol \theta) = -\text{E}_{P(\boldsymbol \theta)} \left( \nabla \nabla^T \log p(x|\boldsymbol \theta)\right)
\]</span> introduced earlier it is necessary to always use the qualifier “observed” when referring to <span class="math inline">\({\boldsymbol J_n}(\hat{\boldsymbol \theta}_{ML})\)</span>.</p>
<p>We will see in more detail later that the observed Fisher information plays an important role at quantifying the uncertainty of a maximum likelihood estimate.</p>
<section id="transformation-properties" class="level3">
<h3 class="anchored" data-anchor-id="transformation-properties">Transformation properties</h3>
<p>As a consequence of the invariance of the score function and curvature function the <strong>observed Fisher information is invariant against transformations of the sample space</strong>. This is the same invariance also shown by the expected Fisher information and by the KL divergence.</p>
<p><span class="math inline">\(\color{Red} \blacktriangleright\)</span> Like the expected Fisher information the observed Fisher information (as a Hessian matrix) transforms covariantly under change of model parameters — see <a href="05-entropy3.html#sec-covariantfisher" class="quarto-xref"><span>Section 5.1.5</span></a>.</p>
</section>
<section id="relationship-between-observed-and-expected-fisher-information" class="level3">
<h3 class="anchored" data-anchor-id="relationship-between-observed-and-expected-fisher-information">Relationship between observed and expected Fisher information</h3>
<p>The observed Fisher information <span class="math inline">\(\boldsymbol J_n(\hat{\boldsymbol \theta}_{ML})\)</span> and the expected Fisher information <span class="math inline">\(\boldsymbol I^{\text{Fisher}}(\boldsymbol \theta)\)</span> are related but also two clearly different entities.</p>
<p>Curvature based:</p>
<ul>
<li>Both types of Fisher information are based on computing second order derivatives (Hessian matrix), thus both are based on the curvature of a function.</li>
</ul>
<p>Transformation properties:</p>
<ul>
<li><p>Both quantities are invariant against changes of the parametrisation of the sample space.</p></li>
<li><p><span class="math inline">\(\color{Red} \blacktriangleright\)</span> Both transform covariantly when changing the parameter of the distribution.</p></li>
</ul>
<p>Data-based vs.&nbsp;model only:</p>
<ul>
<li><p>The observed Fisher information is computed from the log-likelihood function. Therefore it takes both the model and the observed data <span class="math inline">\(D\)</span> into account and explicitly depends on the sample size <span class="math inline">\(n\)</span>. It contains estimates of the parameters but not the parameters themselves. While the curvature of the log-likelihood function may be computed for any point of the log-likelihood function the observed Fisher information specifically refers to the curvature at the MLE <span class="math inline">\(\hat{\boldsymbol \theta}_{ML}\)</span>. It is linked to the (asymptotic) variance of the MLE (see the examples and as will be discussed in more detail later).</p></li>
<li><p>In contrast, the expected Fisher information is derived directly from the log-density of the model family. It does not depend on the observed data, and thus does not depend on sample size. It is a property of the model family <span class="math inline">\(P(\boldsymbol \theta)\)</span> alone. It makes sense and can be computed at any <span class="math inline">\(\boldsymbol \theta\)</span>. It describes the local geometry of the space of the model family, and is the local approximation of KL information.</p></li>
</ul>
<p>Large sample equivalence:</p>
<ul>
<li>Assume that for large sample size <span class="math inline">\(n\)</span> the MLE converges to <span class="math inline">\(\hat{\boldsymbol \theta}_{ML} \rightarrow \boldsymbol \theta_0\)</span>. It follows from the construction of the observed Fisher information and the law of large numbers that asymptotically for large sample size <span class="math inline">\(\boldsymbol J_n(\hat{\boldsymbol \theta}_{ML}) \rightarrow n \boldsymbol I^{\text{Fisher}}( \boldsymbol \theta_0 )\)</span> (i.e.&nbsp;the expected Fisher information for a set of iid random variables, see <a href="05-entropy3.html#sec-additivityfisher" class="quarto-xref"><span>Section 5.1.3</span></a>.</li>
</ul>
<p><span class="math inline">\(\color{Red} \blacktriangleright\)</span> Finite sample equivalence for exponential families:</p>
<ul>
<li>In a very important class of models, namely for <strong>exponential families</strong>, we find that <span class="math inline">\(\boldsymbol J_n(\hat{\boldsymbol \theta}_{ML}) = n \boldsymbol I^{\text{Fisher}}( \hat{\boldsymbol \theta}_{ML} )\)</span> is valid also for finite sample size <span class="math inline">\(n\)</span>. This can be directly seen from the special instances of exponential families such as the Bernoulli distribution (<a href="05-entropy3.html#exm-expectedfisherbernoulli" class="quarto-xref">Example&nbsp;<span>5.1</span></a> and <a href="#exm-obsfisherproportion" class="quarto-xref">Example&nbsp;<span>9.1</span></a>), the normal distribution with one parameter (<a href="05-entropy3.html#exm-expectedfishernormknownvar" class="quarto-xref">Example&nbsp;<span>5.3</span></a> and <a href="#exm-obsfishernormalmean" class="quarto-xref">Example&nbsp;<span>9.2</span></a>), the normal distribution with two parameters (<a href="05-entropy3.html#exm-expectedfishernormal" class="quarto-xref">Example&nbsp;<span>5.4</span></a> and <a href="#exm-obsfishernormalmeanvar" class="quarto-xref">Example&nbsp;<span>9.4</span></a>) and the categorical distribution (<a href="05-entropy3.html#exm-catexpectfisher" class="quarto-xref">Example&nbsp;<span>5.5</span></a> and <a href="#exm-catobsfisher" class="quarto-xref">Example&nbsp;<span>9.5</span></a>).</li>
</ul>
<ul>
<li>However, exponential families are an exception. In a general model <span class="math inline">\(\boldsymbol J_n(\hat{\boldsymbol \theta}_{ML}) \neq n \boldsymbol I^{\text{Fisher}}( \hat{\boldsymbol \theta}_{ML} )\)</span> for finite sample size <span class="math inline">\(n\)</span>. As an example consider the location-scale <span class="math inline">\(t\)</span>-distribution <span class="math inline">\(\text{$t_{\nu}$}(\mu, \tau^2)\)</span> with unknown median parameter <span class="math inline">\(\mu\)</span> and known scale parameter <span class="math inline">\(\tau^2\)</span> and given degree of freedom <span class="math inline">\(\nu\)</span>. This is not an exponential family model (unless <span class="math inline">\(\nu \rightarrow \infty\)</span> when it becomes the normal distribution). It can be shown that the expected Fisher information is <span class="math inline">\(I^{\text{Fisher}}(\mu )=\frac{\nu+1}{\nu+3} \frac{1}{\tau^2}\)</span> but the observed Fisher information <span class="math inline">\(J_n(\hat{\mu}_{ML}) \neq n \frac{\nu+1}{\nu+3} \frac{1}{\tau^2}\)</span> with a maximum likelihood estimate <span class="math inline">\(\hat{\mu}_{ML}\)</span> that can only be computed numerically with no closed form available.</li>
</ul>
</section>
</section>
<section id="observed-fisher-information-examples" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="observed-fisher-information-examples"><span class="header-section-number">9.2</span> Observed Fisher information examples</h2>
<section id="models-with-a-single-parameter" class="level3">
<h3 class="anchored" data-anchor-id="models-with-a-single-parameter">Models with a single parameter</h3>
<div id="exm-obsfisherproportion" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.1</strong></span> Observed Fisher information for the Bernoulli model <span class="math inline">\(\text{Ber}(\theta)\)</span>:</p>
<p>We continue <a href="08-likelihood2.html#exm-mleproportion" class="quarto-xref">Example&nbsp;<span>8.1</span></a>. The second derivative of the log-likelihood function is <span class="math display">\[
H_n(\theta) = \frac{d S_n(\theta)}{d\theta}=- n \left( \frac{ \bar{x} }{\theta^2} + \frac{1 - \bar{x} }{(1-\theta)^2} \right)
\]</span> The observed Fisher information is therefore <span class="math display">\[
\begin{split}
J_n(\hat{\theta}_{ML}) &amp;= -H( \hat{\theta}_{ML} )\\
&amp; = n \left(\frac{ \bar{x} }{\hat{\theta}_{ML}^2} + \frac{ 1 - \bar{x} }{  (1-\hat{\theta}_{ML})^2  } \right) \\
  &amp; = n \left(\frac{1}{\hat{\theta}_{ML}} + \frac{1}{1-\hat{\theta}_{ML}} \right) \\
  &amp;= \frac{n}{\hat{\theta}_{ML} (1-\hat{\theta}_{ML})} \\
\end{split}
\]</span></p>
<p>The inverse of the observed Fisher information is: <span class="math display">\[J_n(\hat{\theta}_{ML})^{-1}=\frac{\hat{\theta}_{ML}(1-\hat{\theta}_{ML})}{n}\]</span></p>
<p>Compare this with <span class="math inline">\(\text{Var}\left(\frac{x}{n}\right) = \frac{\theta(1-\theta)}{n}\)</span> for <span class="math inline">\(x \sim \text{Bin}(n, \theta)\)</span>.</p>
</div>
<div id="exm-obsfishernormalmean" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.2</strong></span> Observed Fisher information for the normal distribution with unknown mean and known variance:</p>
<p>This is the continuation of <a href="08-likelihood2.html#exm-mlenormalmean" class="quarto-xref">Example&nbsp;<span>8.2</span></a>. The second derivative of the log-likelihood function is <span class="math display">\[
H_n(\mu) = \frac{d S_n(\mu)}{d\mu}=- \frac{n}{\sigma^2}
\]</span> The observed Fisher information at the MLE is therefore <span class="math display">\[
J_n(\hat{\mu}_{ML}) = -H_n(\hat{\mu}_{ML}) = \frac{n}{\sigma^2}
\]</span> and the inverse of the observed Fisher information is <span class="math display">\[
J_n(\hat{\mu}_{ML})^{-1} = \frac{\sigma^2}{n}
\]</span></p>
<p>For <span class="math inline">\(x_i \sim N(\mu, \sigma^2)\)</span> we have <span class="math inline">\(\text{Var}(x_i) = \sigma^2\)</span> and hence <span class="math inline">\(\text{Var}(\bar{x}) = \sigma^2/n\)</span>, which is equal to the inverse observed Fisher information.</p>
</div>
<div id="exm-obsnormalvar" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.3</strong></span> Observed Fisher information for the normal distribution with known mean and unknown variance:</p>
<p>This is the continuation of <a href="08-likelihood2.html#exm-mlenormalvar" class="quarto-xref">Example&nbsp;<span>8.3</span></a>. The second derivative of the log-likelihood function is <span class="math display">\[
H_n(\sigma^2) = \frac{dS_n(\sigma^2)}{d\sigma^2} =
-\frac{n}{2\sigma^4} \left(\frac{2}{\sigma^2}  \overline{(x-\mu)^2} -1\right)
\]</span> Correspondingly, the observed Fisher information is <span class="math display">\[
J_n(\widehat{\sigma^2}_{ML}) = -H_n(\widehat{\sigma^2}_{ML}) = \frac{n}{2} \left(\widehat{\sigma^2}_{ML} \right)^{-2}
\]</span> and its inverse is <span class="math display">\[
J_n(\widehat{\sigma^2}_{ML})^{-1} = \frac{2}{n} \left(\widehat{\sigma^2}_{ML} \right)^{2}
\]</span></p>
<p>With <span class="math inline">\(x_i \sim N(\mu, \sigma^2)\)</span> the empirical variance <span class="math inline">\(\widehat{\sigma^2}_{ML}\)</span> follows a one-dimensional Wishart distribution <span class="math display">\[
\widehat{\sigma^2}_{\text{ML}} \sim
\text{Wis}\left(s^2 = \frac{\sigma^2}{n}, k=n-1\right)
\]</span> (see <a href="20-stats.html#sec-distmeanvarest" class="quarto-xref"><span>Section A.8</span></a>) and hence has variance <span class="math inline">\(\text{Var}(\widehat{\sigma^2}_{ML}) = \frac{n-1}{n} \, \frac{2 \sigma ^4}{n}\)</span>. For large <span class="math inline">\(n\)</span> this becomes <span class="math inline">\(\text{Var}\left(\widehat{\sigma^2}_{ML}\right)\overset{a}{=} \frac{2}{n} \left(\sigma^2\right)^2\)</span> which is (apart from the “hat”) the inverse of the observed Fisher information.</p>
</div>
</section>
<section id="models-with-multiple-parameters" class="level3">
<h3 class="anchored" data-anchor-id="models-with-multiple-parameters">Models with multiple parameters</h3>
<div id="exm-obsfishernormalmeanvar" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.4</strong></span> Observed Fisher information for the normal distribution with mean and variance parameter:</p>
<p>This is the continuation of <a href="08-likelihood2.html#exm-mlenormalmeanvar" class="quarto-xref">Example&nbsp;<span>8.5</span></a>.</p>
<p>The Hessian matrix of the log-likelihood function is <span class="math display">\[
\begin{split}
\boldsymbol H_n(\mu,\sigma^2) &amp;= \nabla \nabla^T \ell_n(\mu,\sigma^2)\\
&amp;=
\begin{pmatrix}
    - \frac{n}{\sigma^2}&amp;  -\frac{n}{\sigma^4} (\bar{x} -\mu)\\
    - \frac{n}{\sigma^4} (\bar{x} -\mu) &amp; \frac{n}{2\sigma^4}-\frac{n}{\sigma^6} \left(\overline{x^2} - 2 \mu \bar{x} + \mu^2\right) \\
    \end{pmatrix}
\end{split}
\]</span> The negative Hessian at the MLE, i.e.&nbsp;at <span class="math inline">\(\hat{\mu}_{ML} = \bar{x}\)</span> and <span class="math inline">\(\widehat{\sigma^2}_{ML} = \overline{x^2} -\bar{x}^2\)</span>, yields the <strong>observed Fisher information matrix</strong>: <span class="math display">\[
\begin{split}
\boldsymbol J_n(\hat{\mu}_{ML},\widehat{\sigma^2}_{ML})
&amp;= -\boldsymbol H( \hat{\mu}_{ML},\widehat{\sigma^2}_{ML} )  \\
&amp;=  \begin{pmatrix}
    \frac{n}{\widehat{\sigma^2}_{ML}}&amp;0 \\
    0 &amp; \frac{n}{2(\widehat{\sigma^2}_{ML})^2}
    \end{pmatrix}
\end{split}
\]</span> The observed Fisher information matrix is diagonal with positive entries. Therefore its eigenvalues are all positive as required for a maximum, because for a diagonal matrix the eigenvalues are simply the the entries on the diagonal.</p>
<p>The inverse of the observed Fisher information matrix is <span class="math display">\[
\boldsymbol J_n(\hat{\mu}_{ML},\widehat{\sigma^2}_{ML})^{-1} = \begin{pmatrix}
    \frac{\widehat{\sigma^2}_{ML}}{n}&amp; 0\\
    0 &amp; \frac{2(\widehat{\sigma^2}_{ML})^2}{n}
    \end{pmatrix}
\]</span></p>
</div>
<div id="exm-catobsfisher" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.5</strong></span> <span class="math inline">\(\color{Red} \blacktriangleright\)</span> Observed Fisher information of the categorical distribution:</p>
<p>We continue <a href="08-likelihood2.html#exm-catmle" class="quarto-xref">Example&nbsp;<span>8.7</span></a>. We first need to compute the negative Hessian matrix of the log likelihood function <span class="math inline">\(- \nabla \nabla^T \ell_n(\pi_1, \ldots, \pi_{K-1} )\)</span> and then evaluate it at the MLEs <span class="math inline">\(\hat{\pi}_1^{ML}, \ldots, \hat{\pi}_{K-1}^{ML}\)</span>.</p>
<p>The diagonal entries of the Hessian matrix (with <span class="math inline">\(i=1, \ldots, K-1\)</span>) are <span class="math display">\[
\frac{\partial^2}{\partial \pi_i^2} \ell_n(\pi_1, \ldots, \pi_{K-1} ) =
-n \left( \frac{\bar{x}_i}{\pi_i^2} +\frac{\bar{x}_K}{\pi_K^2}\right)
\]</span> and its off-diagonal entries are (with <span class="math inline">\(j=1, \ldots, K-1\)</span>) <span class="math display">\[
\frac{\partial^2}{\partial \pi_i \partial \pi_j} \ell_n(\pi_1, \ldots, \pi_{K-1} ) =
-\frac{n \bar{x}_K}{\pi_K^2}
\]</span> Thus, the observed Fisher information matrix at the MLE for a categorical distribution is the <span class="math inline">\(K-1 \times K-1\)</span> dimensional matrix <span class="math display">\[
\begin{split}
\boldsymbol J_n(\hat{\pi}_{1}^{ML}, \ldots, \hat{\pi}_{K-1}^{ML}  ) &amp;=
n
\begin{pmatrix}
\frac{1}{\hat{\pi}_1^{ML}} + \frac{1}{\hat{\pi}_K^{ML}} &amp; \cdots &amp; \frac{1}{\hat{\pi}_K^{ML}} \\
\vdots &amp; \ddots &amp; \vdots \\
\frac{1}{\hat{\pi}_K^{ML}} &amp; \cdots &amp; \frac{1}{\hat{\pi}_{K-1}^{ML}} + \frac{1}{\hat{\pi}_K^{ML}} \\
\end{pmatrix} \\
&amp; = n \text{Diag}\left( \frac{1}{\hat{\pi}_1^{ML}} , \ldots, \frac{1}{\hat{\pi}_{K-1}^{ML}}   \right) + \frac{n}{\hat{\pi}_K^{ML}}\mathbf 1\\
\end{split}
\]</span></p>
<p>Note that the observed Fisher information matrix is the sum of a positive definite matrix (the first diagonal matrix) and a positive semi-definite matrix (the second matrix which is a multiple of <span class="math inline">\(\mathbf 1\)</span>), hence it is positive definite. Hence, the Hessian at the MLE is negative definite as required for a maximum.</p>
<p>For <span class="math inline">\(K=2\)</span> (cf. <a href="#exm-obsfisherproportion" class="quarto-xref">Example&nbsp;<span>9.1</span></a>) this reduces to the observed Fisher information of a Bernoulli variable <span class="math display">\[
\begin{split}
J_n(\hat{\theta}_{ML}) &amp; = n \left(\frac{1}{\hat{\theta}_{ML}} + \frac{1}{1-\hat{\theta}_{ML}} \right) \\
  &amp;= \frac{n}{\hat{\theta}_{ML} (1-\hat{\theta}_{ML})} \\
\end{split}
\]</span></p>
<p>The inverse of the observed Fisher information is: <span class="math display">\[
\boldsymbol J_n(\hat{\pi}_{1}^{ML}, \ldots, \hat{\pi}_{K-1}^{ML}  )^{-1} =
\frac{1}{n}
\begin{pmatrix}
\hat{\pi}_1^{ML} (1- \hat{\pi}_1^{ML} )  &amp; \cdots &amp; -  \hat{\pi}_{1}^{ML} \hat{\pi}_{K-1}^{ML}   \\
\vdots &amp; \ddots &amp; \vdots \\
-  \hat{\pi}_{K-1}^{ML} \hat{\pi}_{1}^{ML} &amp; \cdots &amp; \hat{\pi}_{K-1}^{ML} (1- \hat{\pi}_{K-1}^{ML} )  \\
\end{pmatrix}
\]</span></p>
<p>To show that this is indeed the inverse we use the <a href="https://en.wikipedia.org/wiki/Woodbury_matrix_identity">Woodbury matrix identity</a></p>
<p><span class="math display">\[
(\boldsymbol A+ \boldsymbol U\boldsymbol B\boldsymbol V)^{-1} = \boldsymbol A^{-1} - \boldsymbol A^{-1} \boldsymbol U(\boldsymbol B^{-1} + \boldsymbol V\boldsymbol A^{-1} \boldsymbol U)^{-1} \boldsymbol V\boldsymbol A^{-1}
\]</span> with</p>
<ul>
<li><span class="math inline">\(B=1\)</span>,</li>
<li><span class="math inline">\(\boldsymbol u= (\pi_1, \ldots, \pi_{K-1})^T\)</span>,</li>
<li><span class="math inline">\(\boldsymbol v=-\boldsymbol u^T\)</span>,</li>
<li><span class="math inline">\(\boldsymbol A= \text{Diag}(\boldsymbol u)\)</span> and its inverse <span class="math inline">\(\boldsymbol A^{-1} = \text{Diag}(\pi_1^{-1}, \ldots, \pi_{K-1}^{-1})\)</span>.</li>
</ul>
<p>Then <span class="math inline">\(\boldsymbol A^{-1} \boldsymbol u= \mathbf 1_{K-1}\)</span> and <span class="math inline">\(1-\boldsymbol u^T \boldsymbol A^{-1} \boldsymbol u= \pi_K\)</span>. With this <span class="math display">\[
\boldsymbol J_n(\hat{\pi}_{1}^{ML}, \ldots, \hat{\pi}_{K-1}^{ML}  )^{-1} = \frac{1}{n}
\left( \boldsymbol A- \boldsymbol u\boldsymbol u^T \right)
\]</span> and <span class="math display">\[
\boldsymbol J_n(\hat{\pi}_{1}^{ML}, \ldots, \hat{\pi}_{K-1}^{ML}  ) = n \left( \boldsymbol A^{-1} + \frac{1}{\pi_K} \mathbf 1_{K-1 \times K-1}  \right)
\]</span></p>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/strimmerlab\.github\.io\/publications\/lecture-notes\/MATH27720-stats2");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./08-likelihood2.html" class="pagination-link" aria-label="Maximum likelihood estimation in practice">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Maximum likelihood estimation in practice</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./10-likelihood4.html" class="pagination-link" aria-label="Quadratic approximation and normal asymptotics">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Quadratic approximation and normal asymptotics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>