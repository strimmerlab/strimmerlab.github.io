<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Distributions – Statistics 2: Statistical Learning with Likelihood and Bayes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03-entropy1.html" rel="next">
<link href="./01-intro1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-bf90d58e07b16a5a5517af5259b97af0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-intro1.html">Entropy and likelihood</a></li><li class="breadcrumb-item"><a href="./02-intro2.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Distributions</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistics 2: Statistical Learning with Likelihood and Bayes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-prerequisites.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prerequisites</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Entropy and likelihood</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statistical learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-intro2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-entropy1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Entropy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-entropy2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Divergence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-entropy3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Fisher information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-entropy4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Principle of maximum entropy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-likelihood1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Principle of maximum likelihood</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-likelihood2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Maximum likelihood estimation in practice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-likelihood3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Observed Fisher information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-likelihood4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Quadratic approximation and normal asymptotics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-likelihood5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Likelihood-based confidence interval and likelihood ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-likelihood6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Optimality properties and conclusion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayesian statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-bayes1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Conditioning and Bayes rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-bayes2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Models with latent variables and missing data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-bayes3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Essentials of Bayesian statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-bayes4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Bayesian learning in practice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-bayes5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Bayesian model comparison</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-bayes6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Choosing priors in Bayesian analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-bayes7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Optimality properties and summary</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bibliography.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-stats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Statistics refresher</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-further-study.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Further study</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#characteristic-features" id="toc-characteristic-features" class="nav-link active" data-scroll-target="#characteristic-features"><span class="header-section-number">2.1</span> Characteristic features</a></li>
  <li><a href="#commonly-used-distribution-families" id="toc-commonly-used-distribution-families" class="nav-link" data-scroll-target="#commonly-used-distribution-families"><span class="header-section-number">2.2</span> Commonly used distribution families</a></li>
  <li><a href="#model-building" id="toc-model-building" class="nav-link" data-scroll-target="#model-building"><span class="header-section-number">2.3</span> Model building</a>
  <ul class="collapse">
  <li><a href="#choosing-the-right-distribution" id="toc-choosing-the-right-distribution" class="nav-link" data-scroll-target="#choosing-the-right-distribution">Choosing the right distribution</a></li>
  <li><a href="#complex-models" id="toc-complex-models" class="nav-link" data-scroll-target="#complex-models">Complex models</a></li>
  <li><a href="#iterative-refinement" id="toc-iterative-refinement" class="nav-link" data-scroll-target="#iterative-refinement">Iterative refinement</a></li>
  </ul></li>
  <li><a href="#sec-expfamintro" id="toc-sec-expfamintro" class="nav-link" data-scroll-target="#sec-expfamintro"><span class="header-section-number">2.4</span> <span class="math inline">\(\color{Red} \blacktriangleright\)</span> Exponential families</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#definition" id="toc-definition" class="nav-link" data-scroll-target="#definition">Definition</a></li>
  <li><a href="#canonical-statistics-and-canonical-parameters" id="toc-canonical-statistics-and-canonical-parameters" class="nav-link" data-scroll-target="#canonical-statistics-and-canonical-parameters">Canonical statistics and canonical parameters</a></li>
  <li><a href="#partition-function" id="toc-partition-function" class="nav-link" data-scroll-target="#partition-function">Partition function</a></li>
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples">Examples</a></li>
  </ul></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">2.5</span> Further reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-intro1.html">Entropy and likelihood</a></li><li class="breadcrumb-item"><a href="./02-intro2.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Distributions</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-commondist" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Distributions</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Choosing appropriate distributions for statistical modelling is a crucial aspect of probabilistic data analysis. This chapter explores various factors to consider when selecting suitable distributions and also lists frequently used families.</p>
<section id="characteristic-features" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="characteristic-features"><span class="header-section-number">2.1</span> Characteristic features</h2>
<p>Distributions can be differentiated by a number of characteristics.</p>
<p>Firstly, by the <strong>type of random variable</strong>:</p>
<ul>
<li>discrete versus continuous</li>
<li>univariate versus multivariate</li>
</ul>
<p>Secondly, by the <strong>support</strong> of the random variable, with typical ranges such as:</p>
<ul>
<li>finite discrete support, e.g.&nbsp;<span class="math inline">\(\{1, 2, \ldots, n\}\)</span></li>
<li>infinite discrete support, e.g.&nbsp;<span class="math inline">\(\{1, 2, \ldots\}\)</span></li>
<li><span class="math inline">\([0,1]\)</span></li>
<li><span class="math inline">\([-\infty, \infty]\)</span></li>
<li><span class="math inline">\([0, \infty]\)</span></li>
</ul>
<p>The choice of support will depend on the intended use of the random variable in the model. Common applications include:</p>
<ul>
<li>proportion</li>
<li>location</li>
<li>scale</li>
<li>mean</li>
<li>variance</li>
<li>spread</li>
<li>concentration</li>
<li>shape</li>
<li>rate</li>
<li>(squared) correlation</li>
</ul>
<p>These interpretations apply both to the random variable itself but also to the parameter of a distribution family. For instance, we might select a distribution whose outcomes can be interpreted as proportions (e.g.&nbsp;the beta distribution). Alternatively, we might choose a distribution family in which a parameter itself represents a proportion (e.g.&nbsp;the Bernoulli distribution).</p>
<p>A third consideration may be the general <strong>shape</strong> of the distribution:</p>
<ul>
<li>symmetric or asymmetric</li>
<li>left or right skewed</li>
<li>short tails or long tails</li>
<li>unimodal or multimodal</li>
</ul>
<p>A further characteristic of a distribution family is the <strong>number of parameters</strong>, with choices such as</p>
<ul>
<li>single parameter</li>
<li>multiple parameters</li>
<li>multiple types of parameters (e.g.&nbsp;location+scale)</li>
<li>nonparametric model (i.e.&nbsp;highly parametric model)</li>
</ul>
<p>A distribution <strong>family</strong> consists of a finite or infinite set of distributions that correspond to specific instances of parameter values.</p>
<p>Models with many parameters or nonparametric models are employed when there is an abundance of data and they typically make weak assumptions about the data-generating process. Conversely, simpler parametric models are generally preferred for smaller sample sizes, and typically make stronger assumptions about how the data were generated.</p>
<p>In data analysis, we aim to build models that are complex enough to capture the essential features of the data, but simple enough to avoiding overfitting. Consequently, when two models have similar explanatory and predictive power, the one with fewer parameters is generally preferred.</p>
</section>
<section id="commonly-used-distribution-families" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="commonly-used-distribution-families"><span class="header-section-number">2.2</span> Commonly used distribution families</h2>
<p>In this module we will often make use of the following common univariate distributions:</p>
<ol type="1">
<li><p>Binomial distribution <span class="math inline">\(\operatorname{Bin}(n, \theta)\)</span>, with support <span class="math inline">\(\{0, 1, \ldots, n\}\)</span>.</p>
<p>As special case (<span class="math inline">\(n=1)\)</span> is:</p>
<ul>
<li>Bernoulli distribution <span class="math inline">\(\operatorname{Ber}(\theta)\)</span>, with support <span class="math inline">\(\{0, 1\}\)</span>.</li>
</ul></li>
<li><p>Beta distribution <span class="math inline">\(\operatorname{Beta}(\alpha, \beta)\)</span>, with support <span class="math inline">\([0, 1]\)</span>.</p></li>
<li><p>Normal distribution <span class="math inline">\(N(\mu, \sigma^2)\)</span>, with support <span class="math inline">\([-\infty, \infty]\)</span>.</p></li>
<li><p>Gamma distribution <span class="math inline">\(\operatorname{Gam}(\alpha, \theta)\)</span>, with support <span class="math inline">\([0, \infty]\)</span>. It is also known as univariate Wishart distribution <span class="math inline">\(\operatorname{Wis}\left(s^2, k \right)\)</span>.</p>
<p>Special cases of the gamma/Wishart distribution are:</p>
<ul>
<li>scaled chi-squared distribution <span class="math inline">\(s^2 \chi^2_{k}\)</span> (discrete <span class="math inline">\(k\)</span>)</li>
<li>chi-squared distribution <span class="math inline">\(\chi^2_{k}\)</span> (discrete <span class="math inline">\(k\)</span>, <span class="math inline">\(s^2=1\)</span>)</li>
<li>exponential distribution <span class="math inline">\(\operatorname{Exp}(\theta)\)</span> (<span class="math inline">\(\alpha=1\)</span>)</li>
</ul></li>
<li><p>Inverse gamma distribution <span class="math inline">\(\operatorname{IG}(\alpha, \beta)\)</span>, with support <span class="math inline">\([0, \infty]\)</span>. Also know as univariate inverse Wishart distribution <span class="math inline">\(\operatorname{IW}(\psi, k)\)</span>.</p></li>
</ol>
<p>All of the distributions above belong to the class of <strong>exponential families</strong> (see <a href="#sec-expfamintro" class="quarto-xref"><span>Section 2.4</span></a>). These families have many properties that are highly convenient for statistical analysis.</p>
<ol start="6" type="1">
<li><p>Location-scale <span class="math inline">\(t\)</span>-distribution <span class="math inline">\(t_{\nu}(\mu, \tau^2)\)</span>, with support <span class="math inline">\([-\infty, \infty]\)</span>.</p>
<p>Special cases of the location-scale <span class="math inline">\(t\)</span>-distribution are:</p>
<ul>
<li>Student’s <span class="math inline">\(t\)</span>-distribution <span class="math inline">\(t_\nu\)</span></li>
<li>Cauchy distribution <span class="math inline">\(\operatorname{Cau}(\mu, \tau)\)</span></li>
</ul>
<p>The location-scale <span class="math inline">\(t\)</span>-distribution is generalisation of the normal distribution but with more probability mass in the tails. Depending on the choice of the degrees of freedom <span class="math inline">\(\nu\)</span>, not all moments of the distribution may exist. Furthermore, it’s not an exponential family.</p></li>
</ol>
<p>For all of the above univariate distribution there exist corresponding multivariate variants. In this module we will make use of the following multivariate distributions:</p>
<ol type="1">
<li><p>Multinomial distribution <span class="math inline">\(\operatorname{Mult}(n, \boldsymbol \pi)\)</span>, generalising the binomial distribution.</p>
<p>Special case (<span class="math inline">\(n=1)\)</span>:</p>
<ul>
<li>Categorical distribution <span class="math inline">\(\operatorname{Cat}(\boldsymbol \pi)\)</span>, generalising the Bernoulli distribution.</li>
</ul></li>
<li><p>Multivariate normal distribution <span class="math inline">\(N_d(\boldsymbol \mu, \boldsymbol \Sigma)\)</span>, generalising the univariate normal distribution.</p></li>
</ol>
<p>A distribution family can be parametrised in multiple equivalent ways. Typically, there is a standard parametrisation, and also a mean parametrisation, where one of the parameters can be interpreted as the mean of the data. Sometimes, the same distribution is referred to by different names and there are various default parametrisations.</p>
<p>Importantly, any parametrisation is a matter of choice and simply provides as an alternative means to index the elementary distributions within the family. However, certain parametrisations may be more interpretable or offer computational advantages.</p>
</section>
<section id="model-building" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="model-building"><span class="header-section-number">2.3</span> Model building</h2>
<section id="choosing-the-right-distribution" class="level3">
<h3 class="anchored" data-anchor-id="choosing-the-right-distribution">Choosing the right distribution</h3>
<p>When choosing a distribution we typically aim to to align the characteristics of the distribution with those of the observations. For instance, if the data exhibit long tails, we will need to use a long-tailed model. Additionally, there may be a mechanistic rationale, such as a physical law, suggesting that the underlying process follows a particular model.</p>
<p>In many cases, the central limit theorem justifies using a normal distribution.</p>
<p>Another approach to selecting a distribution family is to fix certain properties of the distribution, such as its mean and variance, and then selecting the family that maximises the spread of the probability mass. This method is closely linked to the principle of maximum entropy, which will be discussed in more detail in <a href="06-entropy4.html" class="quarto-xref"><span>Chapter 6</span></a>. It is also helps to explain why exponential families are often preferred in statistical modelling.</p>
</section>
<section id="complex-models" class="level3">
<h3 class="anchored" data-anchor-id="complex-models">Complex models</h3>
<p>Statistical analysis often uses models that are composed of many random variables. These models can be complex, with hierarchical or network-like structures that connect observed and latent variables, and potentially nonlinear functional relationships. Even so, the most sophisticated statistical models are constructed from simpler, more fundamental components.</p>
<p>Specifically, the large class of <em>graphical models</em> provide a principled means to form complex joint distributions for observed and unobserved random variables built from more elementary components. This include <em>regression models</em>, <em>mixture models</em> and <em>compound models</em> (continuous version of mixture models) as well as more general network-like and hierarchically structured models.</p>
<p>In these complex models some of the underlying elementary distributions will serve to model the observed output while others represent internal variables or account for the uncertainty regarding a parameter (in a Bayesian context).</p>
<p>In statistical course units in year&nbsp;3 and year&nbsp;4 you will discuss and learn about many types of advanced models, related for instance to</p>
<ul>
<li>multivariate statistics and machine learning</li>
<li>temporal and spatial modelling, and</li>
<li>generalised linear and nonparametric models.</li>
</ul>
</section>
<section id="iterative-refinement" class="level3">
<h3 class="anchored" data-anchor-id="iterative-refinement">Iterative refinement</h3>
<p>Remember that all distributions (and models in general) are best considered as approximations of the true unknown data-generating process. Hence, the goal of any data analysis is therefore to find models that capture the essential properties at an appropriate level of detail<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. This is typically done in an iterative fashion, either starting from a simple model and increase complexity as needed, or alternatively, starting from a highly parametrised model that one tries to simplify. Either way what is required are methods to compare different models, to quantify how well they fit to data and how well they predict future observations. Statistics provides principled, systematic tools for these tasks.</p>
</section>
</section>
<section id="sec-expfamintro" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="sec-expfamintro"><span class="header-section-number">2.4</span> <span class="math inline">\(\color{Red} \blacktriangleright\)</span> Exponential families</h2>
<section id="overview" class="level3">
<h3 class="anchored" data-anchor-id="overview">Overview</h3>
<p>Many commonly used distributions in statistics are exponential families, including core examples such as the Bernoulli distribution and the normal distribution.</p>
<p>Exponential families are central in probability and statistics. They support effective statistical learning using likelihood and Bayesian approaches, enable data reduction via minimal sufficiency and provide the basis for generalised linear models. Furthermore, exponential families often allow to generalise results established for specific cases, such as the normal distribution, to a broader domain.</p>
</section>
<section id="definition" class="level3">
<h3 class="anchored" data-anchor-id="definition">Definition</h3>
<p>An <strong>exponential family</strong> <span class="math inline">\(P(\boldsymbol \eta)\)</span> arises by <strong>exponential tilting</strong> of a <strong>base distribution</strong> <span class="math inline">\(B\)</span> with (typically unnormalised) <strong>base function</strong> <span class="math inline">\(h(x)\)</span> toward the linear combination <span class="math inline">\(\boldsymbol \eta^T \boldsymbol t(x)\)</span> of the <strong>canonical statistics</strong> <span class="math inline">\(\boldsymbol t(x)\)</span> and the <strong>canonical parameters</strong> <span class="math inline">\(\boldsymbol \eta\)</span>. This yields a pdmf of the form <span class="math display">\[
p(x|\boldsymbol \eta) =    \underbrace{e^{ \langle \boldsymbol \eta, \boldsymbol t(x) \rangle }}_{\text{exponential tilt}}\, h(x) \, /\, z(\boldsymbol \eta)
\]</span></p>
<p>The base pdmf is obtained at <span class="math inline">\(\boldsymbol \eta=0\)</span> yielding <span class="math inline">\(b(x) = p(x | \boldsymbol \eta=0)  =   h(x) / z(0)\)</span>. If <span class="math inline">\(h(x)\)</span> is already a normalised pdmf then <span class="math inline">\(z(0)=1\)</span> and <span class="math inline">\(b(x)=h(x)\)</span>.</p>
<p>The above presentation of exponential families assumes a univariate random variable (scalar <span class="math inline">\(x\)</span>) but also applies to multivariate random variables (vector <span class="math inline">\(\boldsymbol x\)</span> or matrix <span class="math inline">\(\boldsymbol X\)</span>) .</p>
<p>Likewise, canonical statistics and parameters are written as vectors but these may also be scalars or matrices (or a combination of both). The use of inner product notation <span class="math inline">\(\langle, \rangle\)</span> includes all these cases, vectorising matrices as required, recalling that <span class="math inline">\(\langle \boldsymbol A, \boldsymbol B\rangle = \operatorname{Tr}( \boldsymbol A^T \boldsymbol B) = \operatorname{Vec}(\boldsymbol A)^T \operatorname{Vec}(\boldsymbol B)\)</span>.</p>
</section>
<section id="canonical-statistics-and-canonical-parameters" class="level3">
<h3 class="anchored" data-anchor-id="canonical-statistics-and-canonical-parameters">Canonical statistics and canonical parameters</h3>
<p>The canonical statistics <span class="math inline">\(\boldsymbol t(x)\)</span> are transformations of <span class="math inline">\(x\)</span>, usually simple functions such the identity (<span class="math inline">\(x\)</span>), the square (<span class="math inline">\(x^2\)</span>), the inverse (<span class="math inline">\(1/x\)</span>) or the logarithm (<span class="math inline">\(\log x\)</span>). Typically, the dimension of <span class="math inline">\(\boldsymbol t(x)\)</span> is small.</p>
<p>The canonical statistics <span class="math inline">\(\boldsymbol t(x)\)</span> may be affinely dependent. If this is the case there is a vector <span class="math inline">\(\boldsymbol \eta_0\)</span> for which<br>
<span class="math display">\[
\langle \boldsymbol \eta_0, \boldsymbol t(x) \rangle  = \text{const.}
\]</span> If the elements in <span class="math inline">\(\boldsymbol t(x)\)</span> are affinely independent the representation of the exponential family is <strong>minimal</strong> or <strong>complete</strong>, otherwise the representation is <strong>non-minimal</strong> or <strong>overcomplete</strong>.</p>
<p>For each canonical statistic there is a corresponding canonical parameter so the dimensions and shape of <span class="math inline">\(\boldsymbol t(x)\)</span> and <span class="math inline">\(\boldsymbol \eta\)</span> match.</p>
<p>In a minimal representation the canonical parameters of the exponential family are <strong>identifiable</strong> and hence distinct parameter settings for <span class="math inline">\(\boldsymbol \eta\)</span> yield distinct distributions. Conversely, in a non-minimal or overcomplete representation there are redundant elements in the canonical parameters <span class="math inline">\(\boldsymbol \eta\)</span> and the distributions within the exponential family are <strong>not identifiable</strong>. Specifically, there will be multiple <span class="math inline">\(\boldsymbol \eta\)</span> yielding the same underlying distribution.</p>
<p>The canonical parameters <span class="math inline">\(\boldsymbol \eta\)</span> are typically some transformation of the conventional parameters <span class="math inline">\(\boldsymbol \theta\)</span>.</p>
</section>
<section id="partition-function" class="level3">
<h3 class="anchored" data-anchor-id="partition-function">Partition function</h3>
<p>The <strong>normaliser</strong> or <strong>partition function</strong> <span class="math inline">\(z(\boldsymbol \eta)\)</span> ensures that <span class="math inline">\(p(x|\boldsymbol \eta)\)</span> integrates to one, with <span class="math display">\[
z(\boldsymbol \eta) = \int_x \, e^{ \langle \boldsymbol \eta, \boldsymbol t(x) \rangle}\, h(x) \, dx
\]</span> For discrete x replace the integral by a sum.</p>
<p>The set of values of <span class="math inline">\(\boldsymbol \eta\)</span> for which <span class="math inline">\(z(\boldsymbol \eta)  &lt; \infty\)</span>, and hence for which <span class="math inline">\(p(x|\boldsymbol \eta)\)</span> is well defined, comprises the parameter space of the exponential family. Some choices of <span class="math inline">\(h(x)\)</span> and <span class="math inline">\(\boldsymbol t(x)\)</span> do not yield a finite normalising factor for any <span class="math inline">\(\boldsymbol \eta\)</span> and hence these cannot be used to form an exponential family.</p>
<p>The <strong>log-normaliser</strong> or <strong>log-partition function</strong> <span class="math display">\[
a(\boldsymbol \eta) = \log z(\boldsymbol \eta)
\]</span> allows to compute the cumulants of the canonical statistics. In particular, its gradient yields the mean <span class="math display">\[
\begin{split}
\operatorname{E}( \boldsymbol t(x) )  = \boldsymbol \mu_{\boldsymbol t} &amp; = \nabla a(\boldsymbol \eta)\\
&amp;= \frac{\nabla z(\boldsymbol \eta)}{z(\boldsymbol \eta)}
\end{split}
\]</span> and the Hessian matrix the variance <span class="math display">\[
\begin{split}
\operatorname{Var}( \boldsymbol t(x) )  = \boldsymbol \Sigma_{\boldsymbol t} &amp; = \nabla \nabla^T a(\boldsymbol \eta)\\
&amp;= \frac{\nabla \nabla^T z(\boldsymbol \eta)}{z(\boldsymbol \eta)} - \left(\frac{\nabla z(\boldsymbol \eta)}{z(\boldsymbol \eta)}\right) \left(\frac{\nabla z(\boldsymbol \eta)}{z(\boldsymbol \eta)}\right)^T
\end{split}
\]</span></p>
<p>For a minimal exponential family <span class="math inline">\(\boldsymbol \Sigma_{\boldsymbol t}\)</span> is a positive definite matrix and invertible, whereas for non-minimal representations the covariance matrix is positive semi-definite and not invertible.</p>
<p>The means <span class="math inline">\(\boldsymbol \mu_{\boldsymbol t}\)</span> of the canonical statistics <span class="math inline">\(\boldsymbol t(x)\)</span> provide a further parametrisation of exponential families, in addition to the canonical parameters <span class="math inline">\(\boldsymbol \eta\)</span> and the conventional parameters <span class="math inline">\(\boldsymbol \theta\)</span>, and are called the <strong>expectation parameters</strong>.</p>
</section>
<section id="examples" class="level3">
<h3 class="anchored" data-anchor-id="examples">Examples</h3>
<div id="exm-expfambernoulli" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.1</strong></span> <span class="math inline">\(\color{Red} \blacktriangleright\)</span> Bernoulli distribution <span class="math inline">\(\operatorname{Ber}(\theta)\)</span> as exponential family:</p>
<p>The Bernoulli distribution <span class="math inline">\(\operatorname{Ber}(\theta)\)</span> can be specified in exponential family form as follows:</p>
<ul>
<li><span class="math inline">\(x \in \{0, 1\}\)</span></li>
<li>canonical statistic <span class="math inline">\(t(x) = x\)</span></li>
<li>base function <span class="math inline">\(h(x) = 1\)</span></li>
<li>canonical parameter <span class="math inline">\(\eta\)</span></li>
</ul>
<p>This results in the partition function <span class="math display">\[
z(\eta) = \sum_{x \in \{0,1\}} e^{\eta x}  = 1+e^\eta
\]</span> and the log-partition function <span class="math inline">\(a(\eta) = \log z(\eta)\)</span>, both of which are defined for <span class="math inline">\(\eta \in \mathbb{R}\)</span>.</p>
<p>The first and second derivatives of the partition function <span class="math inline">\(z(\eta)\)</span> are <span class="math inline">\(z'(\eta) =  e^\eta\)</span> and <span class="math inline">\(z''(\eta) = e^\eta\)</span>.</p>
<p>The mean <span class="math inline">\(\mu_t\)</span> of the canonical statistic <span class="math inline">\(t(x)=x\)</span> is given by <span class="math display">\[
\begin{split}
\mu_t =  a'(\eta) &amp;= \frac{z'(\eta)}{z(\eta)} = \frac{ e^{\eta}}{1+e^{\eta}} \\
                  &amp; = \operatorname{logit}^{-1}(\eta) \\
                  &amp;= \theta
\end{split}
\]</span> Since <span class="math inline">\(z(x)=x\)</span> for the Bernoulli distribution the expectation parameter <span class="math inline">\(\mu_t\)</span> corresponds to the conventional mean parameter <span class="math inline">\(\operatorname{E}(x) = \theta \in [0, 1]\)</span>. In the above <span class="math inline">\(\mu_t\)</span> and <span class="math inline">\(\theta\)</span> are obtained from <span class="math inline">\(\eta\)</span> by the <strong>inverse logit</strong> function (also known as the <strong>logistic</strong> function).</p>
<p>Conversely, the canonical parameter <span class="math inline">\(\eta\)</span> can be computed from <span class="math inline">\(\theta\)</span> (or <span class="math inline">\(\mu_t\)</span>) by the <strong>logit</strong> function <span class="math display">\[
\eta = \operatorname{logit}\theta  = \log\left(\frac{\theta}{1-\theta}\right)
\]</span></p>
<p>The variance <span class="math inline">\(\sigma^2_t\)</span> of the canonical statistic <span class="math inline">\(t(x)=x\)</span> is <span class="math display">\[
\begin{split}
\sigma^2_t =a''(\eta) &amp;= \frac{z''(\eta)}{z(\eta)} - \left(\frac{z'(\eta)}{z(\eta)}\right)^2 \\
                      &amp;= \frac{ e^{\eta}}{(1+e^{\eta})^2} \\
                      &amp;= \theta (1-\theta)
\end{split}
\]</span></p>
<p>The pmf of the Bernoulli distribution is <span class="math display">\[
p(x | \eta) = \frac{ e^{\eta x} }{ z(\eta) } = \frac{ e^{\eta x} }{ 1+e^\eta }
\]</span> which in terms of the conventional parameter <span class="math inline">\(\theta\)</span> takes on the familiar form <span class="math display">\[
\begin{split}
p(x | \theta) &amp;= \theta^x \, (1-\theta)^{1-x} \\
                   &amp;= \begin{cases} \theta &amp;\text{if } x=1\\ 1-\theta &amp;\text{if } x=0 \end{cases}
\end{split}
\]</span></p>
</div>
<div id="exm-expfamnormal" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.2</strong></span> <span class="math inline">\(\color{Red} \blacktriangleright\)</span> Normal distribution <span class="math inline">\(N(\mu, \sigma^2)\)</span> as exponential family:</p>
<p>The two-parameter normal distribution <span class="math inline">\(N(\mu, \sigma^2)\)</span> can be written in exponential family form as follows:</p>
<ul>
<li><span class="math inline">\(x \in  \mathbb{R}\)</span></li>
<li>canonical statistics <span class="math inline">\(\boldsymbol t(x) = (x, x^2)^T\)</span></li>
<li>base function <span class="math inline">\(h(x) = 1\)</span></li>
<li>canonical parameters <span class="math inline">\(\boldsymbol \eta= (\eta_1, \eta_2)^T\)</span></li>
</ul>
<p>This results in the partition function <span class="math display">\[
z(\boldsymbol \eta) = \left(   -\frac{\pi}{\eta_2} \right)^{1/2} \, \exp\left(-\frac{\eta_1^2}{4\eta_2}\right)
\]</span> and the log-partition function <span class="math display">\[
a(\boldsymbol \eta) =-\frac{\eta_1^2}{4 \eta_2}  +\frac{1}{2} \log\left(-\frac{\pi}{\eta_2} \right)
\]</span> which are defined for <span class="math inline">\(\eta_1 \in \mathbb{R}\)</span> and <span class="math inline">\(\eta_2 \in \mathbb{R}^{-}\)</span>.</p>
<p>The mean <span class="math inline">\(\boldsymbol \mu_{\boldsymbol t}\)</span> of the canonical statistics <span class="math inline">\(\boldsymbol t(x) = (x, x^2)^T\)</span> is given by <span class="math display">\[
\begin{split}
\boldsymbol \mu_{\boldsymbol t} &amp;= \nabla a(\boldsymbol \eta) \\
&amp;=
\begin{pmatrix}
  -\frac{\eta_1}{2 \eta_2} \\
  \frac{\eta_1^2}{4 \eta_2^2} - \frac{1}{2\eta_2}\\
\end{pmatrix}\\
&amp;=\begin{pmatrix}\mu \\ \mu^2+ \sigma^2 \end{pmatrix}
\end{split}
\]</span> The conventional parameters <span class="math inline">\(\mu = \operatorname{E}(x)\)</span> and <span class="math inline">\(\sigma^2=\operatorname{Var}(x)\)</span> are thus directly linked to the expectation parameters <span class="math inline">\(\boldsymbol \mu_{\boldsymbol t}\)</span> and can be obtained from the canonical parameters by <span class="math inline">\(\mu = -\frac{\eta_1}{2\eta_2}\)</span> and <span class="math inline">\(\sigma^2 = -\frac{1}{2\eta_2}\)</span>. Conversely, we have <span class="math display">\[
\boldsymbol \eta= \begin{pmatrix} \eta_1 \\ \eta_2 \end{pmatrix}  = \begin{pmatrix} \frac{\mu}{\sigma^2} \\  - \frac{1}{2 \sigma^2} \end{pmatrix}
\]</span></p>
<p>The covariance matrix of the canonical statistics <span class="math inline">\(\boldsymbol t(x)\)</span> is <span class="math display">\[
\begin{split}
\boldsymbol \Sigma_{\boldsymbol t} &amp;= \begin{pmatrix}
                 \operatorname{Var}(x) &amp; \operatorname{Cov}(x, x^2) \\
                 \operatorname{Cov}(x^2, x) &amp;  \operatorname{Var}(x^2) \\
                 \end{pmatrix}\\
             &amp;= \nabla \nabla^T a(\boldsymbol \eta) \\
             &amp;= \begin{pmatrix}
                 -\frac{1}{2\eta_2} &amp; \frac{\eta_1}{2 \eta_2^2} \\
                 \frac{\eta_1}{2 \eta_2^2} &amp;  \frac{ \eta_2 -\eta_1^2 }{2 \eta_2^3} \\
                 \end{pmatrix}\\
             &amp;= \begin{pmatrix}
                 \sigma^2 &amp;  2 \mu \sigma^2 \\
                  2 \mu \sigma^2 &amp;   2 \sigma^4 +4 \mu^2 \sigma^2  \\
                 \end{pmatrix}\\
\end{split}
\]</span></p>
<p>The pdf in terms of <span class="math inline">\(\boldsymbol \eta\)</span> is <span class="math display">\[
p(x | \boldsymbol \eta) = \left(   -\frac{\pi}{\eta_2} \right)^{-1/2} \,   \exp\left( \eta_1 x + \eta_2 x^2   +\frac{\eta_1^2}{4\eta_2}\right)    \\
\]</span> which in terms of the standard parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> takes on the familiar form <span class="math display">\[
p(x | \mu, \sigma^2) =  \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( -  \frac{(x- \mu)^2}{2\sigma^2 } \right)
\]</span></p>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>A bit of history
</div>
</div>
<div class="callout-body-container callout-body">
<p>The concept of exponential families in statistics was independently developed in the 1930s by <a href="https://de.wikipedia.org/wiki/Georges_Darmois">Georges Darmois (1888–1960)</a>, <a href="https://de.wikipedia.org/wiki/Edwin_James_George_Pitman">Edwin J. G. Pitman (1897–1993)</a>, and <a href="https://de.wikipedia.org/wiki/Bernard_Koopman">Bernard Koopman (1900–1981)</a>. However, exponential families were introduced earlier in statistical mechanics in the 1870s by <a href="https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs">Josiah W. Gibbs (1839-1903)</a> and <a href="https://en.wikipedia.org/wiki/Ludwig_Boltzmann">Ludwig Boltzmann (1844-1906)</a>.</p>
<p>In statistics, exponential families were motivated by identifying distributions allowing minimal sufficient statistics whereas in physics the objective was to find distributions maximising entropy.</p>
</div>
</div>
</section>
</section>
<section id="further-reading" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">2.5</span> Further reading</h2>
<p>For details of the distributions listed above and additional background on exponential families see the supplementary <a href="https://strimmerlab.github.io/publications/lecture-notes/probability-distribution-refresher/index.html">Probability and Distribution Refresher notes</a>. A recent textbook on exponential families is <span class="citation" data-cites="EfronExpFam2022">Efron (<a href="bibliography.html#ref-EfronExpFam2022" role="doc-biblioref">2022</a>)</span>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-EfronExpFam2022" class="csl-entry" role="listitem">
Efron, B. 2022. <em>Exponential Families in Theory and Practise</em>. Cambridge University Press. <a href="https://doi.org/10.1017/9781108773157">https://doi.org/10.1017/9781108773157</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>The fact that it’s possible to model the world at one length scale independently from what’s happening at other length scales is a general phenomenon in nature known in physics as <em>decoupling of scales</em>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/strimmerlab\.github\.io\/publications\/lecture-notes\/MATH27720-stats2");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01-intro1.html" class="pagination-link" aria-label="Statistical learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statistical learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03-entropy1.html" class="pagination-link" aria-label="Entropy">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Entropy</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>